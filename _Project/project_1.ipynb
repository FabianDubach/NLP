{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **FS25 NLP Project 1: Word Embeddings/Recurrent Neural Networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fabian Dubach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task for this project was to answer common sense questions with the usage of two different architectures: Word embeddings (word2vec, GloVe or fastText) with a classifier and a 2-layer RNN architecture with a classifier (LSTM or GRU). We had to also track the trainings with Wandb (workspace URL: https://wandb.ai/fabian-dubach-hochschule-luzern/CommonsenseQA?nw=nwuserfabiandubach)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all libraries needed to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fabia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import trange\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import hf_hub_download\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import wandb\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup random seed to ensure reproducibility.\n",
    "\n",
    "_Info about the seed value: The field of natural language processing began in the 1940s, after World War II. At this time, people recognized the importance of translation from one language to another and hoped to create a machine that could do this sort of translation automatically._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1940\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download tokenizer files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\fabia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\fabia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pre-trained FastText word embeddings (300 dimensions)\n",
    "\n",
    "I first wanted to choose GloVe, because I've seen that GloVe performs well on semantic similarity and analogical reasoning. Due to the fact that GloVe can only handle uncased embeddings (lowercase), I chose to use FastText. I used 300 dimensions, because it represents word meanings more completely than smaller options (50- or 100 dimensions) while still being practical to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = hf_hub_download(repo_id=\"facebook/fasttext-en-vectors\", filename=\"model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model = gensim.models.fasttext.load_facebook_model(model_path)\n",
    "wv = fasttext_model.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at vector- and vocab size from the loaded embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector size: 300\n",
      "Vocab size: 2000000\n"
     ]
    }
   ],
   "source": [
    "print(\"Vector size:\", wv.vector_size)\n",
    "print(\"Vocab size:\", len(wv.index_to_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if known and unknown words create vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.18165089  0.11567269  0.0433396   0.07706802  0.05069138  0.03688334\n",
      "  0.07828845  0.04980808 -0.00644083  0.01029488 -0.04722646 -0.00791209\n",
      " -0.11451723  0.03025086  0.09307548  0.01062883 -0.07683911 -0.10517459\n",
      "  0.00246387  0.07702646  0.04039837  0.01229953 -0.11466632  0.05460778\n",
      "  0.08104917  0.0413662   0.01208615  0.08066231 -0.10937778  0.0893073\n",
      " -0.03935073 -0.03060348 -0.08027591  0.08209406 -0.03217232 -0.03641732\n",
      "  0.01242283  0.05759722 -0.05894108  0.02777894 -0.18341364 -0.05084793\n",
      "  0.02241275  0.00440608  0.07912826  0.04474901 -0.03937861 -0.0721626\n",
      "  0.05589562  0.02635202  0.01346619  0.0173357   0.12057565 -0.019653\n",
      " -0.01023086 -0.00223926  0.03043848  0.00747647  0.04588774  0.06308782\n",
      " -0.1178913   0.10388953 -0.03564711  0.12567218  0.1470628   0.06018791\n",
      " -0.0574099   0.01620604  0.12471652  0.04412995  0.10071367 -0.02047683\n",
      " -0.13367647 -0.07360457 -0.13447621 -0.03744629 -0.0009886   0.0684141\n",
      "  0.06370986  0.05818591 -0.04122961 -0.0223539   0.0769026   0.09776731\n",
      "  0.02858542 -0.02261026  0.02192976  0.02389368 -0.02181333 -0.05587808\n",
      " -0.10528626 -0.01707761  0.16739199 -0.07432255  0.05840709 -0.03762028\n",
      " -0.00207798  0.01510621  0.03805321  0.03398537 -0.00906375 -0.07027729\n",
      "  0.04727545  0.02308086  0.04358866 -0.01768984  0.03916318  0.06372152\n",
      " -0.02831535  0.04534719  0.02102193  0.01108286 -0.03659292  0.04093347\n",
      " -0.06203868 -0.10862799  0.00680049  0.03481388 -0.06817614  0.02137695\n",
      " -0.00345266  0.1150042  -0.04496847 -0.08819682 -0.04952236  0.01701073\n",
      "  0.02326014 -0.04779105  0.04800141 -0.07515921 -0.01634037 -0.0811061\n",
      " -0.09424134 -0.00833836 -0.04380025 -0.03635019  0.00569909  0.00082589\n",
      " -0.11013471 -0.05401219 -0.01574623  0.04228688 -0.1068991  -0.03638983\n",
      " -0.05132256 -0.00147617 -0.10611109 -0.04120749  0.14517301  0.01697615\n",
      "  0.04895845 -0.05139152 -0.07904777 -0.03195062 -0.01784976 -0.01884896\n",
      "  0.01083412 -0.04916894  0.03224476  0.07400668 -0.03882392  0.03726387\n",
      " -0.12158169 -0.02310036  0.07332714 -0.11492305  0.06320892  0.0763358\n",
      "  0.03122582 -0.07115757 -0.01897454 -0.06736365 -0.0635465   0.07702038\n",
      "  0.06505896 -0.01860097  0.01857694  0.01654613  0.07221819 -0.00398161\n",
      "  0.18419957  0.05156292  0.00093686  0.09514098  0.06906874  0.03903695\n",
      "  0.0858674   0.02365539 -0.01141509 -0.05531562 -0.04065567 -0.17426042\n",
      " -0.05206808 -0.05193314 -0.05110309 -0.0522124  -0.1663761   0.10091858\n",
      "  0.00916502  0.09908608 -0.12705521 -0.00574662  0.04638401  0.0341948\n",
      " -0.2017314  -0.01244436  0.03252782 -0.02472054 -0.05050343  0.01227911\n",
      " -0.02038734  0.0036418  -0.05424974 -0.07783546 -0.01223209  0.0302521\n",
      " -0.00328729  0.00968582 -0.00269379 -0.0475513  -0.04994595  0.01874385\n",
      "  0.07220112 -0.05906899  0.1008291   0.02528204 -0.0778743  -0.10279019\n",
      " -0.02604302  0.0789118   0.02627861  0.09560115 -0.0089255  -0.07674091\n",
      "  0.01429606  0.01313404 -0.03895061  0.11260032 -0.04728229 -0.01135568\n",
      " -0.05426588 -0.15327632 -0.01439532  0.12041174  0.18071084 -0.00982607\n",
      "  0.0427782   0.16305949 -0.04483898 -0.05071171  0.01258892 -0.05913531\n",
      "  0.07538383 -0.09350947  0.03784867  0.1473783  -0.01954721 -0.02140094\n",
      "  0.07979327  0.05211494  0.03398424 -0.03633638 -0.02617038 -0.04646286\n",
      "  0.00825945 -0.04652121 -0.10042215 -0.03944197  0.0306065  -0.07439391\n",
      "  0.02664843 -0.10097454 -0.12594806  0.06312321 -0.00922106 -0.01078579\n",
      " -0.06060401 -0.10091601 -0.04235916 -0.01697931 -0.12506312 -0.08156627\n",
      " -0.07982061  0.05424746 -0.01857662  0.07154027  0.0322356  -0.19313999\n",
      "  0.04096438 -0.05646858  0.06730992  0.08486427 -0.11022168 -0.02145613\n",
      "  0.03925505  0.00298458 -0.04771789  0.07572205 -0.05758004  0.05284115]\n",
      "[ 2.97031272e-03  3.40607017e-04  1.35063501e-02  2.93574780e-02\n",
      " -1.66248605e-02 -4.51960368e-03 -8.67080130e-03 -1.12947375e-02\n",
      "  5.02542593e-04 -2.30718181e-02  5.68294479e-03 -3.38404393e-03\n",
      " -3.09460368e-02 -1.09714689e-02 -2.44773198e-02 -3.85160223e-02\n",
      " -4.03666310e-03  9.80488118e-03  2.64563505e-02  1.16144745e-02\n",
      " -2.05351971e-02 -1.66083947e-02 -1.57732107e-02  1.37995873e-02\n",
      "  6.12373911e-02  2.04167552e-02 -2.18895636e-02  1.36729470e-02\n",
      " -7.38288276e-04  4.07587364e-02  9.82565433e-03 -5.22660743e-03\n",
      " -2.72591747e-02  2.39877030e-04  2.72601694e-02 -7.30554573e-03\n",
      " -7.46898074e-03  3.45904604e-02 -1.36964126e-02  8.17707554e-03\n",
      " -3.78858764e-04 -1.66866789e-03 -4.06378694e-03  1.16347906e-03\n",
      " -1.48788150e-02 -1.11557706e-03 -2.64112502e-02  1.93093754e-02\n",
      "  4.82143369e-05  1.11076599e-02 -5.57333278e-03 -2.02334821e-02\n",
      " -5.56224864e-03 -1.40912673e-02 -4.07067593e-03 -1.03690466e-02\n",
      "  1.03850681e-02 -1.74085610e-04  1.87323149e-03  6.40070857e-03\n",
      " -2.11857259e-02  2.32436489e-02  2.91495547e-02  1.68980546e-02\n",
      "  1.82434507e-02 -7.73929153e-03  1.24754850e-04  3.14254016e-02\n",
      " -1.45284357e-02 -3.61171342e-03  1.89932454e-02  1.73607543e-02\n",
      "  2.68886834e-02 -9.54429246e-03  3.21093481e-03  2.74840128e-02\n",
      "  2.84707323e-02 -3.91487079e-03 -3.98980305e-02  9.42743290e-03\n",
      " -5.71705354e-03  8.97879433e-03 -2.02749725e-02 -1.72194261e-02\n",
      " -1.56093184e-02  1.08502861e-02 -2.46748626e-02 -1.43537782e-02\n",
      "  1.35887396e-02 -8.45968444e-03 -1.35286013e-02 -5.01403864e-03\n",
      " -4.48085777e-02 -3.08049601e-02  3.79183553e-02  2.43808702e-02\n",
      " -3.35939345e-03 -2.70930771e-02  9.02074948e-03 -9.43065993e-03\n",
      " -8.52887053e-03  2.13081688e-02 -1.14998790e-02  3.32715586e-02\n",
      "  3.25527275e-03 -2.28147060e-02  2.05057748e-02 -6.26413152e-04\n",
      " -1.83614921e-02 -1.79118495e-02 -2.35025696e-02 -1.30714970e-02\n",
      "  2.03093532e-02  1.70697533e-02  3.10187973e-03  1.46194333e-02\n",
      "  1.90508738e-02 -4.25692531e-04  1.53421955e-02  1.19441962e-02\n",
      " -1.82501115e-02  1.81834511e-02  2.02173367e-02  1.03911823e-02\n",
      "  1.32278595e-02  3.40679288e-02 -3.91585007e-03 -1.21597517e-02\n",
      " -3.20007317e-02 -4.53492627e-02 -1.37786716e-02  2.59805052e-03\n",
      "  1.04692494e-02  7.84383155e-03  1.00294286e-02  2.98436992e-02\n",
      "  2.26405542e-03 -6.88534603e-02  5.67903509e-04  2.41571292e-02\n",
      "  3.25823277e-02  2.73115188e-03  3.12146135e-02 -2.77856737e-03\n",
      " -2.80041881e-02 -1.32836225e-02 -4.72761244e-02  8.95016082e-03\n",
      "  1.37353586e-02 -9.06289183e-03 -9.90835205e-03 -2.22451612e-02\n",
      " -4.23793234e-02  1.15017984e-02 -1.13643520e-02 -5.86752780e-03\n",
      "  1.97005048e-02 -1.65714752e-02 -3.29226032e-02 -3.40121016e-02\n",
      " -1.42437983e-02 -3.28963995e-02 -2.42249426e-02 -1.94186112e-04\n",
      "  2.79154489e-03  1.65105611e-02 -1.69017445e-03 -1.43269617e-02\n",
      "  1.87001675e-02  3.19226235e-02  1.38433184e-03  1.35733746e-03\n",
      "  6.50663953e-03  4.00839783e-02  1.95277035e-02  1.99907795e-02\n",
      "  2.27622110e-02 -2.01473311e-02 -4.46982123e-03 -1.65324099e-02\n",
      " -8.98451544e-03  5.89326955e-02  1.64911151e-04 -4.51234542e-02\n",
      " -8.38645268e-03 -2.88774259e-02  4.81655523e-02 -1.78609192e-02\n",
      "  4.33279295e-03  1.69598730e-03  2.18791002e-03 -5.14529757e-02\n",
      "  1.13792485e-02  1.45653859e-02  7.55027635e-03 -4.22895979e-03\n",
      " -1.68361403e-02 -9.19132959e-03  1.15000028e-02  7.05640689e-02\n",
      " -3.06501165e-02 -2.66216602e-02 -1.16075836e-02  9.75436182e-04\n",
      "  1.90271437e-02 -1.22778583e-03  1.93538722e-02 -1.18292756e-02\n",
      " -1.17262881e-02 -3.88801144e-03  8.71444494e-03 -8.63834564e-03\n",
      "  4.71205711e-02 -3.17980675e-03 -3.98652535e-03 -3.67477909e-02\n",
      "  5.05029224e-03 -8.52162018e-04  2.24850699e-02  1.90338120e-02\n",
      "  2.18193000e-03 -6.26519462e-03  6.64199516e-03  3.27939838e-02\n",
      " -1.07904226e-02  2.56617740e-02 -3.96525767e-03  1.32368263e-02\n",
      "  4.46370151e-03  3.89272422e-02 -4.79178177e-03  2.30782684e-02\n",
      " -9.04239714e-03 -4.27850196e-03  1.37756765e-03  2.42634136e-02\n",
      "  1.96271557e-02 -1.84338465e-02 -1.19003309e-02  2.79325228e-02\n",
      "  2.62266435e-02 -1.89277017e-03  5.57764154e-03  9.38646961e-04\n",
      "  1.00615583e-02 -5.87627385e-03 -3.74485888e-02  7.30309810e-04\n",
      "  2.61170976e-03  1.31001249e-02  5.17663807e-02 -6.09678123e-03\n",
      "  2.08204240e-03  3.05297645e-03 -6.55129086e-04  3.70363481e-02\n",
      "  2.09345110e-02  2.66017374e-02 -2.22177505e-02  6.65352121e-03\n",
      " -4.22321353e-03 -3.90813574e-02 -5.70038706e-02 -6.74200896e-03\n",
      " -3.33354156e-03  2.69167684e-02 -1.34572312e-02 -1.81922615e-02\n",
      " -2.74327490e-03  5.70894331e-02 -1.24959555e-02  1.40244532e-02\n",
      " -3.02684549e-02 -3.32553647e-02 -6.50998484e-03  4.89529921e-03\n",
      " -2.79670209e-03 -4.29512933e-04 -3.40325907e-02  1.51196644e-02\n",
      " -4.84470464e-03 -1.25906412e-02 -2.59634238e-02 -1.98244564e-02\n",
      "  4.63081989e-03 -2.00663246e-02  9.28043202e-03 -4.17923965e-02\n",
      "  4.47282568e-03 -9.66400094e-03  1.92939490e-02  1.55542558e-02\n",
      " -6.89376099e-03 -2.16794945e-02  2.61401087e-02 -2.22004335e-02\n",
      " -1.60159566e-03  1.69389732e-02  1.71379279e-03 -2.13609561e-02]\n"
     ]
    }
   ],
   "source": [
    "print(wv[\"Hello\"])\n",
    "print(wv[\"jwadAJKJDwljlkdajl\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the project, we had to use the CommonsenseQA dataset, which is a multiple-choice question answering dataset that contains 12'247 different questions and was developed to benchmark machine understanding of everyday knowledge. For each questions there are 5 given answer choices, where only one of them is correct. To be able to answer these questions, \"commonsense\" is needed. The dataset is available on HuggingFace: https://huggingface.co/datasets/tau/commonsense_qa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I split the dataset into training, validation and test sets to allow for model development and evaluation. I used the last 1'000 examples from the training set for validation and the original validation set for testing, since the real test set has no answer keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8741 1000 1221\n"
     ]
    }
   ],
   "source": [
    "train = load_dataset(\"tau/commonsense_qa\", split=\"train[:-1000]\")\n",
    "valid = load_dataset(\"tau/commonsense_qa\", split=\"train[-1000:]\")\n",
    "test = load_dataset(\"tau/commonsense_qa\", split=\"validation\")\n",
    "\n",
    "print(len(train), len(valid), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Exploration**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section I tried to get some insight to understand its structure and patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Explore dataset structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mDataset Features\u001b[0m\n",
      "id\n",
      "question\n",
      "question_concept\n",
      "choices\n",
      "answerKey\n",
      "\n",
      "\u001b[4mExample\u001b[0m\n",
      "id: 075e483d21c29a511267ef62bedc0461\n",
      "question: The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?\n",
      "question_concept: punishing\n",
      "choices: {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['ignore', 'enforce', 'authoritarian', 'yell at', 'avoid']}\n",
      "answerKey: A\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[4m\" + \"Dataset Features\" + \"\\033[0m\")\n",
    "for feature in train.features:\n",
    "    print(feature)\n",
    "print(\"\\n\" + \"\\033[4m\" + \"Example\" + \"\\033[0m\")\n",
    "for feature in train.features:\n",
    "    print(feature + \":\", train[0][str(feature)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get a general info about each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_df(dataset):\n",
    "    return pd.DataFrame(dataset)\n",
    "\n",
    "train_df = dataset_to_df(train)\n",
    "valid_df = dataset_to_df(valid)\n",
    "test_df = dataset_to_df(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mTrain Info\u001b[0m\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8741 entries, 0 to 8740\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   id                8741 non-null   object\n",
      " 1   question          8741 non-null   object\n",
      " 2   question_concept  8741 non-null   object\n",
      " 3   choices           8741 non-null   object\n",
      " 4   answerKey         8741 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 341.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[4m\" + \"Train Info\" + \"\\033[0m\")\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mValidation Info\u001b[0m\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   id                1000 non-null   object\n",
      " 1   question          1000 non-null   object\n",
      " 2   question_concept  1000 non-null   object\n",
      " 3   choices           1000 non-null   object\n",
      " 4   answerKey         1000 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 39.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[4m\" + \"Validation Info\" + \"\\033[0m\")\n",
    "print(valid_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mTest Info\u001b[0m\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1221 entries, 0 to 1220\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   id                1221 non-null   object\n",
      " 1   question          1221 non-null   object\n",
      " 2   question_concept  1221 non-null   object\n",
      " 3   choices           1221 non-null   object\n",
      " 4   answerKey         1221 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 47.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[4m\" + \"Test Info\" + \"\\033[0m\")\n",
    "print(test_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Analyze question lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mQuestion length (characters)\u001b[0m\n",
      "Min: 15\n",
      "Max: 376\n",
      "Mean: 69.31\n",
      "Median: 64.0\n",
      "\n",
      "\u001b[4mQuestion Word Count\u001b[0m\n",
      "Min: 3\n",
      "Max: 63\n",
      "Mean: 13.23\n",
      "Median: 12.0\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.concat([train_df, valid_df, test_df], ignore_index=True)\n",
    "\n",
    "combined_df['question_length'] = combined_df['question'].apply(len)\n",
    "combined_df['question_word_count'] = combined_df['question'].apply(lambda x: len(x.split()))\n",
    "\n",
    "print(\"\\033[4m\" + \"Question length (characters)\" + \"\\033[0m\")\n",
    "print(f\"Min: {combined_df['question_length'].min()}\")\n",
    "print(f\"Max: {combined_df['question_length'].max()}\")\n",
    "print(f\"Mean: {combined_df['question_length'].mean():.2f}\")\n",
    "print(f\"Median: {combined_df['question_length'].median()}\")\n",
    "\n",
    "print(\"\\n\\033[4m\" + \"Question Word Count\" + \"\\033[0m\")\n",
    "print(f\"Min: {combined_df['question_word_count'].min()}\")\n",
    "print(f\"Max: {combined_df['question_word_count'].max()}\")\n",
    "print(f\"Mean: {combined_df['question_word_count'].mean():.2f}\")\n",
    "print(f\"Median: {combined_df['question_word_count'].median()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Analyze option lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mOption length (characters)\u001b[0m\n",
      "Min: 3\n",
      "Max: 149\n",
      "Mean: 9.34\n",
      "Median: 9.0\n",
      "\u001b[4m\n",
      "Option word count\u001b[0m\n",
      "Min: 1\n",
      "Max: 26\n",
      "Mean: 1.52\n",
      "Median: 1.0\n"
     ]
    }
   ],
   "source": [
    "def get_option_lengths(choices):\n",
    "    return [len(text) for text in choices['text']]\n",
    "\n",
    "def get_option_word_counts(choices):\n",
    "    return [len(text.split()) for text in choices['text']]\n",
    "\n",
    "combined_df['option_lengths'] = combined_df['choices'].apply(get_option_lengths)\n",
    "combined_df['option_word_counts'] = combined_df['choices'].apply(get_option_word_counts)\n",
    "\n",
    "# Flatten the lists for analysis\n",
    "all_option_lengths = [length for lengths in combined_df['option_lengths'] for length in lengths]\n",
    "all_option_word_counts = [count for counts in combined_df['option_word_counts'] for count in counts]\n",
    "\n",
    "print(\"\\033[4m\" + \"Option length (characters)\" + \"\\033[0m\")\n",
    "print(f\"Min: {min(all_option_lengths)}\")\n",
    "print(f\"Max: {max(all_option_lengths)}\")\n",
    "print(f\"Mean: {np.mean(all_option_lengths):.2f}\")\n",
    "print(f\"Median: {np.median(all_option_lengths)}\")\n",
    "\n",
    "print(\"\\033[4m\" + \"\\nOption word count\" + \"\\033[0m\")\n",
    "print(f\"Min: {min(all_option_word_counts)}\")\n",
    "print(f\"Max: {max(all_option_word_counts)}\")\n",
    "print(f\"Mean: {np.mean(all_option_word_counts):.2f}\")\n",
    "print(f\"Median: {np.median(all_option_word_counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Analyze answer distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mAnswer Distribution\u001b[0m\n",
      "answer_letter\n",
      "D    2236\n",
      "B    2228\n",
      "C    2187\n",
      "E    2163\n",
      "A    2148\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "answer_letter\n",
      "D     20.4%\n",
      "B    20.32%\n",
      "C    19.95%\n",
      "E    19.73%\n",
      "A    19.59%\n",
      "Name: proportion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def extract_answer_letter(example):\n",
    "    return example['answerKey']\n",
    "\n",
    "combined_df['answer_letter'] = combined_df.apply(extract_answer_letter, axis=1)\n",
    "\n",
    "print(\"\\033[4m\" + \"Answer Distribution\" + \"\\033[0m\")\n",
    "print(combined_df['answer_letter'].value_counts(), \"\\n\")\n",
    "print(combined_df['answer_letter'].value_counts(normalize=True).mul(100).round(2).astype(str) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Extract common question words/phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mCommon Words in Questions\u001b[0m\n",
      "would: 1101\n",
      "people: 694\n",
      "might: 669\n",
      "likely: 637\n",
      "someone: 556\n",
      "find: 509\n",
      "could: 502\n",
      "person: 498\n",
      "get: 372\n",
      "one: 367\n"
     ]
    }
   ],
   "source": [
    "def get_common_words(text_series, top_n=20):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    all_words = []\n",
    "    \n",
    "    for text in text_series:\n",
    "        words = word_tokenize(text.lower())\n",
    "        filtered_words = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "        all_words.extend(filtered_words)\n",
    "    \n",
    "    return Counter(all_words).most_common(top_n)\n",
    "\n",
    "print(\"\\033[4m\" + \"Common Words in Questions\" + \"\\033[0m\")\n",
    "common_words = get_common_words(train_df['question'], 10)\n",
    "for word, count in common_words:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Visualize question length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(combined_df['question_word_count'], bins=20, kde=True)\n",
    "plt.title('Distribution of Question Word Count')\n",
    "plt.xlabel('Number of Words')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Visualize answer distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(x='answer_letter', data=combined_df, order=combined_df['answer_letter'].value_counts().index)\n",
    "plt.title('Distribution of Answers')\n",
    "plt.xlabel('Answer Option')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the preprocessing I looked at the following points:\n",
    "\n",
    "1. Tokenization\n",
    "2. Lowercasing, stemming, lemmatizing, stopword/punctuation removal \n",
    "3. Removal of unknown/other words \n",
    "4. Format cleaning (e.g. html-extracted text) \n",
    "5. Truncation \n",
    "6. Feature selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are my decisions and justifications for using or not using the above listed preprocessing methods:\n",
    "\n",
    "1. Tokenization is absolutely mandatory.\n",
    "2. I chose not to use lowercasing to keep the semantic meaning of the words. Stemming and lemmatizing are not needed, because FastText already captures semantic similarities. Stopword/Punctuation removal is generally not a needed for a RNN due to the fact that the model can then learn to ignore irrelevant words by itself.\n",
    "3. Removal of unknown/other words is also not needed, because FastText can handle them.\n",
    "4. Format cleaning is not needed, because the CommonsenseQA dataset doesn't include any markup text.\n",
    "5. Due to the fact that the longest question is 376 characters long, truncation is not needed.\n",
    "6. Feature selection is also not needed. RNNs typically work with the full sequence rather than selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Word Embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The get_embedding function transforms any text sentence into a fixed-length vector representation by averaging the word embeddings of each token in the sentence. If no tokens were found, a zero vector is being returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(sentence):\n",
    "    tokens = preprocessing(sentence)\n",
    "    word_vectors = []\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            # Correct syntax for fasttext_model\n",
    "            word_vectors.append(fasttext_model.wv[token])  # Use .wv attribute\n",
    "        except KeyError:\n",
    "            # Skip tokens not in vocabulary\n",
    "            continue\n",
    "    \n",
    "    # Return the mean of the word vectors\n",
    "    if word_vectors:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(fasttext_model.vector_size)  # Return a zero vector if no tokens were found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model to interpret the answers correctly, I converted the answer keys into numerical indices (0, 1, 2, 3, 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_key_to_index(answer_key):\n",
    "  return ord(answer_key) - ord(\"A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compute_embeddings function creates embeddings for every text data (questions and choices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 8741/8741 [00:04<00:00, 1775.60 examples/s]\n",
      "Map: 100%|██████████| 1000/1000 [00:01<00:00, 666.28 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def compute_embeddings(example):\n",
    "    question_embeddings = get_embedding(example[\"question\"])\n",
    "    choice_embeddings = [get_embedding(choice) for choice in example[\"choices\"][\"text\"]]\n",
    "    \n",
    "    # Save embeddings as lists so they can be stored in the dataset\n",
    "    example[\"question_emb\"] = question_embeddings.tolist()\n",
    "    example[\"choice_embs\"] = [embedding.tolist() for embedding in choice_embeddings]\n",
    "    return example\n",
    "\n",
    "train = train.map(compute_embeddings)\n",
    "valid = valid.map(compute_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a class which can convert a regular dataset into a PyTorch-compatible dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonsenseQADataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.data = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        example = self.data[idx]\n",
    "        question_tensor = torch.tensor(example[\"question_emb\"]).float()\n",
    "        choices_tensor = torch.tensor(example[\"choice_embs\"]).float()\n",
    "        answer_index = answer_key_to_index(example[\"answerKey\"])\n",
    "        return question_tensor, choices_tensor, torch.tensor(answer_index).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a PyTorch-compatible dataset for the train and the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CommonsenseQADataset(train)\n",
    "valid_dataset = CommonsenseQADataset(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch the dataset for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=embedding_batch_size, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=embedding_batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the structure and shapes of the data batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 300]) torch.Size([32, 5, 300]) torch.Size([32]) tensor([2, 3, 0, 1, 4, 4, 2, 1, 4, 4, 0, 0, 0, 4, 2, 3, 0, 2, 3, 2, 2, 2, 1, 4,\n",
      "        2, 1, 1, 3, 1, 4, 0, 2])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch[0].shape, batch[1].shape, batch[2].shape, batch[2])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **RNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonsenseQARNNDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, word_vectors, embedding_dim=300):\n",
    "        self.data = hf_dataset\n",
    "        self.wv = word_vectors\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.SEP_TOKEN = \"<SEP>\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        example = self.data[idx]\n",
    "        \n",
    "        # Tokenize question and choices\n",
    "        question_tokens = preprocessing(example[\"question\"])\n",
    "        choice_tokens = [preprocessing(choice) for choice in example[\"choices\"][\"text\"]]\n",
    "        \n",
    "        # Create sequences and lengths for each choice\n",
    "        sequences = []\n",
    "        lengths = []\n",
    "        for choice in choice_tokens:\n",
    "            # Combine question and choice\n",
    "            full_sequence = question_tokens + [self.SEP_TOKEN] + choice\n",
    "            \n",
    "            # Convert to embeddings\n",
    "            embeddings = []\n",
    "            for token in full_sequence:\n",
    "                try:\n",
    "                    # Use pretrained embedding\n",
    "                    if token == self.SEP_TOKEN:\n",
    "                        embeddings.append(torch.randn(self.embedding_dim) * 0.1)\n",
    "                    else:\n",
    "                        embeddings.append(torch.tensor(self.wv[token]))\n",
    "                except KeyError:\n",
    "                    # For OOV words, use random embedding\n",
    "                    embeddings.append(torch.randn(self.embedding_dim) * 0.1)\n",
    "            \n",
    "            # Convert to tensor\n",
    "            sequences.append(torch.stack(embeddings))\n",
    "            lengths.append(len(embeddings))\n",
    "        \n",
    "        # Convert answer to index\n",
    "        answer = ord(example[\"answerKey\"]) - ord(\"A\")\n",
    "        \n",
    "        return sequences, torch.tensor(lengths), torch.tensor(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_collate_batch(batch):\n",
    "    # Separate sequences, lengths, and answers\n",
    "    all_sequences = []\n",
    "    all_lengths = []\n",
    "    all_answers = []\n",
    "    \n",
    "    batch_size = len(batch)\n",
    "    num_choices = len(batch[0][0])  # Number of choices per example\n",
    "    \n",
    "    for sequences, lengths, answer in batch:\n",
    "        all_sequences.extend(sequences)\n",
    "        all_lengths.append(lengths)\n",
    "        all_answers.append(answer)\n",
    "    \n",
    "    # Combine and sort lengths\n",
    "    lengths_tensor = torch.cat(all_lengths)\n",
    "    sorted_indices = torch.argsort(lengths_tensor, descending=True)\n",
    "    \n",
    "    # Reorder sequences and lengths based on sorted indices\n",
    "    sorted_sequences = [all_sequences[i] for i in sorted_indices]\n",
    "    sorted_lengths = lengths_tensor[sorted_indices]\n",
    "    \n",
    "    # Pad sequences\n",
    "    padded_sequences = pad_sequence(sorted_sequences, batch_first=True)\n",
    "    \n",
    "    # Create indices to reconstruct original batch order\n",
    "    indices = torch.arange(len(sorted_indices)).view(batch_size, num_choices)\n",
    "    \n",
    "    # Stack answers\n",
    "    answers_tensor = torch.stack(all_answers)\n",
    "    \n",
    "    return padded_sequences, sorted_lengths, indices, answers_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 5\n",
      "Sequence 0 shape: torch.Size([26, 300])\n",
      "Sequence 1 shape: torch.Size([26, 300])\n",
      "Sequence 2 shape: torch.Size([26, 300])\n",
      "Sequence 3 shape: torch.Size([27, 300])\n",
      "Sequence 4 shape: torch.Size([26, 300])\n",
      "Sequence lengths: tensor([26, 26, 26, 27, 26])\n",
      "Correct answer: 0\n"
     ]
    }
   ],
   "source": [
    "train_rnn_dataset = CommonsenseQARNNDataset(\n",
    "    train, \n",
    "    wv,\n",
    "    embedding_dim=300\n",
    ")\n",
    "\n",
    "valid_rnn_dataset = CommonsenseQARNNDataset(\n",
    "    valid, \n",
    "    wv,\n",
    "    embedding_dim=300\n",
    ")\n",
    "\n",
    "# Check dataset sample\n",
    "sample_idx = 0\n",
    "sequences, lengths, answer = train_rnn_dataset[sample_idx]\n",
    "print(f\"Number of sequences: {len(sequences)}\")\n",
    "for i, sequence in enumerate(sequences):\n",
    "    print(f\"Sequence {i} shape: {sequence.shape}\")\n",
    "print(f\"Sequence lengths: {lengths}\")\n",
    "print(f\"Correct answer: {answer.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created train loader with 69 batches\n",
      "Created validation loader with 4 batches\n"
     ]
    }
   ],
   "source": [
    "train_rnn_loader = DataLoader(\n",
    "    train_rnn_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    collate_fn=rnn_collate_batch,\n",
    "    num_workers=0,  # Set to 0 for debugging\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "valid_rnn_loader = DataLoader(\n",
    "    valid_rnn_dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    collate_fn=rnn_collate_batch,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "print(f\"Created train loader with {len(train_rnn_loader)} batches\")\n",
    "print(f\"Created validation loader with {len(valid_rnn_loader)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbeddingQAClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, dropout_rate):\n",
    "        super(WordEmbeddingQAClassifier, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # First layer: concatenated embedding dimension\n",
    "        self.fc1 = nn.Linear(2 * embedding_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Output layer for classification\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, question, choices):\n",
    "        # Expand question to match choices dimension\n",
    "        question_expanded = question.unsqueeze(1).expand(-1, choices.size(1), -1)\n",
    "        \n",
    "        # Concatenate question and choice embeddings\n",
    "        combined = torch.cat((question_expanded, choices), dim=2)\n",
    "\n",
    "        # First layer with ReLU and Dropout\n",
    "        x = self.fc1(combined)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Final layer\n",
    "        x = self.fc2(x)\n",
    "        return x.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "hidden_dim = 64\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordEmbeddingQAClassifier(\n",
      "  (fc1): Linear(in_features=600, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = WordEmbeddingQAClassifier(embedding_dim, hidden_dim, dropout_rate)\n",
    "model = model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QARNNModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim=128, num_choices=5, dropout_rate=0.2):\n",
    "        super(QARNNModel, self).__init__()\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_choices = num_choices\n",
    "        \n",
    "        # 2-layer bidirectional LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=dropout_rate,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # Classification head\n",
    "        lstm_output_dim = hidden_dim * 2  # bidirectional = *2\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(lstm_output_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, padded_sequences, sequence_lengths, indices):\n",
    "        \"\"\"Process all sequences together and then reshape for classification\"\"\"\n",
    "        batch_size = indices.size(0)\n",
    "        \n",
    "        # Pack padded sequences with enforce_sorted=False\n",
    "        packed = pack_padded_sequence(\n",
    "            padded_sequences, \n",
    "            sequence_lengths.cpu(), \n",
    "            batch_first=True,\n",
    "            enforce_sorted=False\n",
    "        )\n",
    "        \n",
    "        # Run through LSTM\n",
    "        _, (hidden, _) = self.lstm(packed)\n",
    "        \n",
    "        # Get final hidden states from both directions\n",
    "        final_hidden = torch.cat([hidden[-2], hidden[-1]], dim=1)\n",
    "        \n",
    "        # Process through classifier\n",
    "        logits = self.classifier(final_hidden).squeeze(-1)\n",
    "        \n",
    "        # Rearrange back to original order\n",
    "        all_logits = torch.zeros(batch_size, self.num_choices, device=padded_sequences.device)\n",
    "        for batch_idx in range(batch_size):\n",
    "            for choice_idx in range(self.num_choices):\n",
    "                all_logits[batch_idx, choice_idx] = logits[indices[batch_idx, choice_idx]]\n",
    "        \n",
    "        return all_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_run = wandb.init(\n",
    "  project=\"CommonsenseQA\",\n",
    "  name=f\"word_embedding-{datetime.now().strftime('%Y-%m-%dT%H:%M:%S')}\",\n",
    "  config={\n",
    "    \"model\": \"word_embedding\",\n",
    "    \"embedding_dim\": embedding_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"batch_size\": 256,  # Smaller batch size\n",
    "    \"epoch\": 100,\n",
    "    \"dropout_rate\": dropout_rate,\n",
    "    \"weight_decay\": 1e-5,  # Very light weight decay\n",
    "    \"label_smoothing\": 0.0,  # No label smoothing initially\n",
    "    \"gradient_clipping\": 1.0,\n",
    "    \"max_lr\": 0.001,\n",
    "  },\n",
    "  reinit=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, save_path, best_val_accuracy):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'best_val_accuracy': best_val_accuracy\n",
    "    }\n",
    "    torch.save(checkpoint, save_path)\n",
    "    try:\n",
    "        if 'best_model' in save_path:\n",
    "            wandb.log({\n",
    "                \"best_model_checkpoint\": {\n",
    "                    \"path\": save_path,\n",
    "                    \"epoch\": epoch,\n",
    "                    \"val_accuracy\": best_val_accuracy\n",
    "                }\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error logging checkpoint to wandb: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_word_embedding(\n",
    "    model, \n",
    "    train_loader, \n",
    "    valid_loader, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    num_epochs, \n",
    "    device, \n",
    "    checkpoint_dir='checkpoints', \n",
    "    save_interval=10,\n",
    "):\n",
    "    # Create checkpoint directory if it doesn't exist\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    # Initialize best validation accuracy\n",
    "    best_val_accuracy = 0\n",
    "    start_epoch = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in (pbar := trange(start_epoch, num_epochs)):\n",
    "        pbar.set_description(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        model.train()\n",
    "        train_total_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for question_batch, choices_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            question_batch = question_batch.to(device)\n",
    "            choices_batch = choices_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(question_batch, choices_batch)\n",
    "\n",
    "            # Compute loss\n",
    "            train_batch_loss = criterion(outputs, y_batch)\n",
    "            train_total_loss += train_batch_loss.item()\n",
    "\n",
    "            # Compute accuracy\n",
    "            train_predictions = torch.argmax(outputs, dim=1)\n",
    "            train_correct += (train_predictions == y_batch).sum().item()\n",
    "            train_total += y_batch.size(0)\n",
    "\n",
    "            # Backward pass\n",
    "            train_batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Calculate train statistics\n",
    "        avg_train_loss = train_total_loss / len(train_loader)\n",
    "        train_accuracy = train_correct / train_total\n",
    "\n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_total_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for question_batch, choices_batch, y_batch in valid_loader:\n",
    "                question_batch = question_batch.to(device)\n",
    "                choices_batch = choices_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "\n",
    "                val_outputs = model(question_batch, choices_batch)\n",
    "\n",
    "                # Calculate validation loss\n",
    "                val_batch_loss = criterion(val_outputs, y_batch)\n",
    "                val_total_loss += val_batch_loss.item()\n",
    "\n",
    "                val_predictions = torch.argmax(val_outputs, dim=1)\n",
    "                val_correct += (val_predictions == y_batch).sum().item()\n",
    "                val_total += y_batch.size(0)\n",
    "\n",
    "        # Calculate validation statistics\n",
    "        avg_val_loss = val_total_loss / len(valid_loader)\n",
    "        val_accuracy = val_correct / val_total\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            \"train_loss\": avg_train_loss, \n",
    "            \"train_acc\": train_accuracy, \n",
    "            \"val_acc\": val_accuracy\n",
    "        })\n",
    "\n",
    "        # Log metrics to wandb\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": avg_train_loss,\n",
    "            \"train_accuracy\": train_accuracy,\n",
    "            \"val_loss\": avg_val_loss,\n",
    "            \"val_accuracy\": val_accuracy,\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "        })\n",
    "\n",
    "        # Save checkpoint periodically\n",
    "        if (epoch + 1) % save_interval == 0:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch+1}.pt')\n",
    "            save_checkpoint(model, optimizer, epoch+1, checkpoint_path, best_val_accuracy)\n",
    "\n",
    "        # Save best model based on validation accuracy\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model_path = os.path.join(checkpoint_dir, 'best_model.pt')\n",
    "            save_checkpoint(model, optimizer, epoch+1, best_model_path, best_val_accuracy)\n",
    "\n",
    "    # Final save\n",
    "    final_model_path = os.path.join(checkpoint_dir, 'final_model.pt')\n",
    "    save_checkpoint(model, optimizer, num_epochs, final_model_path, best_val_accuracy)\n",
    "    \n",
    "    wandb.finish()\n",
    "    \n",
    "    return model, best_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define checkpoint directory\n",
    "checkpoint_dir = './checkpoints/embedding'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Optional: Resume from a previous checkpoint\n",
    "resume_checkpoint = None  # Set to checkpoint path if resuming\n",
    "\n",
    "# Replace your existing training loop with this\n",
    "model, best_val_accuracy = train_word_embedding(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=embedding_run.config.epoch,\n",
    "    device=device,\n",
    "    checkpoint_dir=checkpoint_dir,\n",
    "    save_interval=1  # Save a checkpoint every 5 epochs\n",
    ")\n",
    "\n",
    "print(best_val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **RNN Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "QARNNModel(\n",
      "  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 300  # Same as word vectors\n",
    "hidden_dim = 128     # Hidden dimension for LSTM\n",
    "dropout_rate=0.2\n",
    "num_epochs = 100\n",
    "\n",
    "# Create the RNN model\n",
    "rnn_model = QARNNModel(  # Updated name\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    dropout_rate=dropout_rate\n",
    ")\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "rnn_model = rnn_model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "print(rnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the training function to use the updated save_checkpoint\n",
    "def train_rnn_model(model, criterion, optimizer, scheduler, train_loader, valid_loader, num_epochs, device, checkpoints_path=None, log_wandb=True, gradient_clip_val=1.0):\n",
    "    best_val_accuracy = 0.0\n",
    "    training_start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        with tqdm(train_loader, desc=\"Training\") as progress_bar:\n",
    "            for batch_data in progress_bar:\n",
    "                # Unpack the batch data\n",
    "                padded_sequences, sequence_lengths, indices, answers = batch_data\n",
    "                \n",
    "                # Move to device\n",
    "                padded_sequences = padded_sequences.to(device)\n",
    "                sequence_lengths = sequence_lengths.to(device)\n",
    "                indices = indices.to(device)\n",
    "                answers = answers.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(padded_sequences, sequence_lengths, indices)\n",
    "                loss = criterion(outputs, answers)\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                if gradient_clip_val > 0:\n",
    "                    nn.utils.clip_grad_norm_(model.parameters(), gradient_clip_val)\n",
    "                optimizer.step()\n",
    "                if scheduler is not None:\n",
    "                    scheduler.step()\n",
    "                \n",
    "                # Statistics\n",
    "                train_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += answers.size(0)\n",
    "                train_correct += (predicted == answers).sum().item()\n",
    "                \n",
    "                # Update progress bar\n",
    "                progress_bar.set_postfix({\n",
    "                    'loss': f\"{loss.item():.4f}\",\n",
    "                    'acc': f\"{train_correct/train_total:.4f}\"\n",
    "                })\n",
    "        \n",
    "        train_accuracy = train_correct / train_total\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_data in tqdm(valid_loader, desc=\"Validation\"):\n",
    "                # Unpack the batch data\n",
    "                padded_sequences, sequence_lengths, indices, answers = batch_data\n",
    "                \n",
    "                # Move to device\n",
    "                padded_sequences = padded_sequences.to(device)\n",
    "                sequence_lengths = sequence_lengths.to(device)\n",
    "                indices = indices.to(device)\n",
    "                answers = answers.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(padded_sequences, sequence_lengths, indices)\n",
    "                loss = criterion(outputs, answers)\n",
    "                \n",
    "                # Statistics\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += answers.size(0)\n",
    "                val_correct += (predicted == answers).sum().item()\n",
    "        \n",
    "        val_accuracy = val_correct / val_total\n",
    "        avg_val_loss = val_loss / len(valid_loader)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            print(f\"Validation accuracy improved from {best_val_accuracy:.4f} to {val_accuracy:.4f}\")\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model_path = os.path.join(checkpoints_path, 'best_rnn_model.pt')\n",
    "            save_checkpoint(model, optimizer, epoch+1, best_val_accuracy, best_model_path)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.4f}\")\n",
    "        print(f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "        \n",
    "        # Log to wandb\n",
    "        if log_wandb:\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch,\n",
    "                \"train_loss\": avg_train_loss,\n",
    "                \"train_accuracy\": train_accuracy,\n",
    "                \"val_loss\": avg_val_loss,\n",
    "                \"val_accuracy\": val_accuracy,\n",
    "                \"learning_rate\": optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "    \n",
    "    print(f\"Training completed in {(time.time() - training_start_time)/60:.2f} minutes\")\n",
    "    print(f\"Best validation accuracy: {best_val_accuracy:.4f}\")\n",
    "    \n",
    "    # Final metrics for wandb\n",
    "    if log_wandb:\n",
    "        wandb.run.summary[\"best_val_accuracy\"] = best_val_accuracy\n",
    "        wandb.finish()\n",
    "    \n",
    "    return model, best_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Dateien\\Github_FabianDubach\\NLP\\_Project\\wandb\\run-20250405_181616-x1ic3q0l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fabian-dubach-hochschule-luzern/CommonsenseQA/runs/x1ic3q0l' target=\"_blank\">rnn-2025-04-05T18:16:16</a></strong> to <a href='https://wandb.ai/fabian-dubach-hochschule-luzern/CommonsenseQA' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fabian-dubach-hochschule-luzern/CommonsenseQA' target=\"_blank\">https://wandb.ai/fabian-dubach-hochschule-luzern/CommonsenseQA</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fabian-dubach-hochschule-luzern/CommonsenseQA/runs/x1ic3q0l' target=\"_blank\">https://wandb.ai/fabian-dubach-hochschule-luzern/CommonsenseQA/runs/x1ic3q0l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnn_run = wandb.init(\n",
    "  project=\"CommonsenseQA\",\n",
    "  name=f\"rnn-{datetime.now().strftime('%Y-%m-%dT%H:%M:%S')}\",\n",
    "  config={\n",
    "    \"model\": \"rnn\",\n",
    "    \"embedding_dim\": embedding_dim,\n",
    "    \"hidden_dim\": hidden_dim,\n",
    "    \"batch_size\": 256,  # Smaller batch size\n",
    "    \"epoch\": 100,\n",
    "    \"dropout_rate\": dropout_rate,\n",
    "    \"weight_decay\": 1e-5,  # Very light weight decay\n",
    "    \"label_smoothing\": 0.0,  # No label smoothing initially\n",
    "    \"gradient_clipping\": 1.0,\n",
    "    \"max_lr\": 0.001,\n",
    "  },\n",
    "  reinit=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_path = \"./checkpoints/rnn_model\"\n",
    "os.makedirs(checkpoints_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  3.93it/s, loss=1.6100, acc=0.1960]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy improved from 0.0000 to 0.1960\n",
      "Train Loss: 1.6096, Train Acc: 0.1960\n",
      "Val Loss: 1.6094, Val Acc: 0.1960\n",
      "\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:16<00:00,  4.09it/s, loss=1.6111, acc=0.2050]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.2050\n",
      "Val Loss: 1.6094, Val Acc: 0.1940\n",
      "\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  4.01it/s, loss=1.6087, acc=0.1953]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy improved from 0.1960 to 0.2030\n",
      "Train Loss: 1.6094, Train Acc: 0.1953\n",
      "Val Loss: 1.6094, Val Acc: 0.2030\n",
      "\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:16<00:00,  4.06it/s, loss=1.6126, acc=0.1968]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.1968\n",
      "Val Loss: 1.6094, Val Acc: 0.1740\n",
      "\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  4.03it/s, loss=1.6104, acc=0.1973]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy improved from 0.2030 to 0.2140\n",
      "Train Loss: 1.6093, Train Acc: 0.1973\n",
      "Val Loss: 1.6094, Val Acc: 0.2140\n",
      "\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  3.96it/s, loss=1.6109, acc=0.1936]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6097, Train Acc: 0.1936\n",
      "Val Loss: 1.6094, Val Acc: 0.1870\n",
      "\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  3.90it/s, loss=1.6110, acc=0.1946]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6097, Train Acc: 0.1946\n",
      "Val Loss: 1.6094, Val Acc: 0.1810\n",
      "\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:16<00:00,  4.06it/s, loss=1.6104, acc=0.1991]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.1991\n",
      "Val Loss: 1.6094, Val Acc: 0.1900\n",
      "\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  3.87it/s, loss=1.6109, acc=0.2043]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2043\n",
      "Val Loss: 1.6094, Val Acc: 0.2020\n",
      "\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  3.90it/s, loss=1.6106, acc=0.2033]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy improved from 0.2140 to 0.2180\n",
      "Train Loss: 1.6095, Train Acc: 0.2033\n",
      "Val Loss: 1.6094, Val Acc: 0.2180\n",
      "\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:18<00:00,  3.75it/s, loss=1.6100, acc=0.1969]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.1969\n",
      "Val Loss: 1.6094, Val Acc: 0.1980\n",
      "\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:18<00:00,  3.72it/s, loss=1.6088, acc=0.1928]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6097, Train Acc: 0.1928\n",
      "Val Loss: 1.6095, Val Acc: 0.1880\n",
      "\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:18<00:00,  3.81it/s, loss=1.6098, acc=0.1972]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.1972\n",
      "Val Loss: 1.6095, Val Acc: 0.2040\n",
      "\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  3.86it/s, loss=1.6087, acc=0.2004]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy improved from 0.2180 to 0.2280\n",
      "Train Loss: 1.6094, Train Acc: 0.2004\n",
      "Val Loss: 1.6094, Val Acc: 0.2280\n",
      "\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:18<00:00,  3.83it/s, loss=1.6080, acc=0.2028]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.2028\n",
      "Val Loss: 1.6094, Val Acc: 0.2010\n",
      "\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  3.95it/s, loss=1.6092, acc=0.1960]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.1960\n",
      "Val Loss: 1.6094, Val Acc: 0.2080\n",
      "\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:18<00:00,  3.80it/s, loss=1.6106, acc=0.2055]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2055\n",
      "Val Loss: 1.6094, Val Acc: 0.1870\n",
      "\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:18<00:00,  3.75it/s, loss=1.6112, acc=0.2049]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6093, Train Acc: 0.2049\n",
      "Val Loss: 1.6094, Val Acc: 0.2070\n",
      "\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  3.89it/s, loss=1.6082, acc=0.2071]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6093, Train Acc: 0.2071\n",
      "Val Loss: 1.6094, Val Acc: 0.2110\n",
      "\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  3.84it/s, loss=1.6092, acc=0.1945]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.1945\n",
      "Val Loss: 1.6095, Val Acc: 0.1870\n",
      "\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:18<00:00,  3.64it/s, loss=1.6106, acc=0.1933]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6096, Train Acc: 0.1933\n",
      "Val Loss: 1.6095, Val Acc: 0.1860\n",
      "\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:18<00:00,  3.81it/s, loss=1.6124, acc=0.2057]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6093, Train Acc: 0.2057\n",
      "Val Loss: 1.6094, Val Acc: 0.1960\n",
      "\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  4.00it/s, loss=1.6095, acc=0.2078]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6093, Train Acc: 0.2078\n",
      "Val Loss: 1.6094, Val Acc: 0.2100\n",
      "\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  3.99it/s, loss=1.6050, acc=0.2015]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.2015\n",
      "Val Loss: 1.6094, Val Acc: 0.2130\n",
      "\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:16<00:00,  4.10it/s, loss=1.6076, acc=0.1993]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.1993\n",
      "Val Loss: 1.6095, Val Acc: 0.1910\n",
      "\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:16<00:00,  4.16it/s, loss=1.6087, acc=0.1979]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.1979\n",
      "Val Loss: 1.6094, Val Acc: 0.1950\n",
      "\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  4.04it/s, loss=1.6094, acc=0.2056]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2056\n",
      "Val Loss: 1.6094, Val Acc: 0.2070\n",
      "\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:16<00:00,  4.14it/s, loss=1.6068, acc=0.1933]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6097, Train Acc: 0.1933\n",
      "Val Loss: 1.6094, Val Acc: 0.1780\n",
      "\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:16<00:00,  4.10it/s, loss=1.6081, acc=0.1957]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.1957\n",
      "Val Loss: 1.6094, Val Acc: 0.1940\n",
      "\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  3.99it/s, loss=1.6077, acc=0.2057]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2057\n",
      "Val Loss: 1.6094, Val Acc: 0.2080\n",
      "\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  3.92it/s, loss=1.6090, acc=0.1977]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6097, Train Acc: 0.1977\n",
      "Val Loss: 1.6094, Val Acc: 0.2020\n",
      "\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:16<00:00,  4.06it/s, loss=1.6123, acc=0.2016]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.2016\n",
      "Val Loss: 1.6094, Val Acc: 0.1960\n",
      "\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  3.88it/s, loss=1.6109, acc=0.2035]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2035\n",
      "Val Loss: 1.6094, Val Acc: 0.2190\n",
      "\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  4.03it/s, loss=1.6106, acc=0.2018]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2018\n",
      "Val Loss: 1.6094, Val Acc: 0.2110\n",
      "\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:16<00:00,  4.07it/s, loss=1.6088, acc=0.2028]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2028\n",
      "Val Loss: 1.6094, Val Acc: 0.2030\n",
      "\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  3.90it/s, loss=1.6082, acc=0.2060]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2060\n",
      "Val Loss: 1.6094, Val Acc: 0.2140\n",
      "\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  3.93it/s, loss=1.6112, acc=0.1994]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6096, Train Acc: 0.1994\n",
      "Val Loss: 1.6094, Val Acc: 0.2010\n",
      "\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:16<00:00,  4.08it/s, loss=1.6082, acc=0.1977]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.1977\n",
      "Val Loss: 1.6094, Val Acc: 0.1990\n",
      "\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  3.98it/s, loss=1.6097, acc=0.2004]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2004\n",
      "Val Loss: 1.6094, Val Acc: 0.2010\n",
      "\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  4.02it/s, loss=1.6106, acc=0.2072]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2072\n",
      "Val Loss: 1.6094, Val Acc: 0.1980\n",
      "\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  3.93it/s, loss=1.6095, acc=0.1952]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6097, Train Acc: 0.1952\n",
      "Val Loss: 1.6095, Val Acc: 0.1850\n",
      "\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  4.03it/s, loss=1.6083, acc=0.1973]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.1973\n",
      "Val Loss: 1.6094, Val Acc: 0.1920\n",
      "\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  3.85it/s, loss=1.6111, acc=0.1921]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6097, Train Acc: 0.1921\n",
      "Val Loss: 1.6094, Val Acc: 0.2050\n",
      "\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:18<00:00,  3.75it/s, loss=1.6071, acc=0.2063]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6093, Train Acc: 0.2063\n",
      "Val Loss: 1.6094, Val Acc: 0.2060\n",
      "\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:17<00:00,  3.88it/s, loss=1.6100, acc=0.2010]\n",
      "Validation: 100%|██████████| 4/4 [00:02<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6093, Train Acc: 0.2010\n",
      "Val Loss: 1.6094, Val Acc: 0.1990\n",
      "\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:18<00:00,  3.70it/s, loss=1.6092, acc=0.2012]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.2012\n",
      "Val Loss: 1.6094, Val Acc: 0.2180\n",
      "\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:19<00:00,  3.60it/s, loss=1.6103, acc=0.1977]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.1977\n",
      "Val Loss: 1.6094, Val Acc: 0.2060\n",
      "\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:18<00:00,  3.71it/s, loss=1.6080, acc=0.2062]\n",
      "Validation: 100%|██████████| 4/4 [00:02<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2062\n",
      "Val Loss: 1.6094, Val Acc: 0.2010\n",
      "\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:19<00:00,  3.60it/s, loss=1.6100, acc=0.2010]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2010\n",
      "Val Loss: 1.6094, Val Acc: 0.2020\n",
      "\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:20<00:00,  3.41it/s, loss=1.6080, acc=0.1922]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6096, Train Acc: 0.1922\n",
      "Val Loss: 1.6094, Val Acc: 0.2060\n",
      "\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:19<00:00,  3.49it/s, loss=1.6094, acc=0.2070]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2070\n",
      "Val Loss: 1.6094, Val Acc: 0.2080\n",
      "\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:19<00:00,  3.56it/s, loss=1.6104, acc=0.1960]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6096, Train Acc: 0.1960\n",
      "Val Loss: 1.6094, Val Acc: 0.1970\n",
      "\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:20<00:00,  3.29it/s, loss=1.6073, acc=0.1975]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.1975\n",
      "Val Loss: 1.6094, Val Acc: 0.2040\n",
      "\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:19<00:00,  3.47it/s, loss=1.6093, acc=0.2007]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.2007\n",
      "Val Loss: 1.6094, Val Acc: 0.1810\n",
      "\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:22<00:00,  3.08it/s, loss=1.6087, acc=0.2018]\n",
      "Validation: 100%|██████████| 4/4 [00:02<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.2018\n",
      "Val Loss: 1.6094, Val Acc: 0.2010\n",
      "\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:21<00:00,  3.24it/s, loss=1.6097, acc=0.1945]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6096, Train Acc: 0.1945\n",
      "Val Loss: 1.6094, Val Acc: 0.1980\n",
      "\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:18<00:00,  3.66it/s, loss=1.6093, acc=0.2002]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6096, Train Acc: 0.2002\n",
      "Val Loss: 1.6094, Val Acc: 0.1770\n",
      "\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:20<00:00,  3.37it/s, loss=1.6094, acc=0.2032]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6093, Train Acc: 0.2032\n",
      "Val Loss: 1.6094, Val Acc: 0.2010\n",
      "\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:20<00:00,  3.38it/s, loss=1.6105, acc=0.1981]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.1981\n",
      "Val Loss: 1.6094, Val Acc: 0.1810\n",
      "\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:19<00:00,  3.45it/s, loss=1.6107, acc=0.2038]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2038\n",
      "Val Loss: 1.6094, Val Acc: 0.1880\n",
      "\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:19<00:00,  3.47it/s, loss=1.6119, acc=0.2056]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.2056\n",
      "Val Loss: 1.6094, Val Acc: 0.1780\n",
      "\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:20<00:00,  3.43it/s, loss=1.6096, acc=0.1946]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.1946\n",
      "Val Loss: 1.6094, Val Acc: 0.2010\n",
      "\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:20<00:00,  3.36it/s, loss=1.6070, acc=0.1959]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.1959\n",
      "Val Loss: 1.6094, Val Acc: 0.1940\n",
      "\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:20<00:00,  3.40it/s, loss=1.6105, acc=0.2003]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.2003\n",
      "Val Loss: 1.6094, Val Acc: 0.1920\n",
      "\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:20<00:00,  3.43it/s, loss=1.6104, acc=0.1992]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.1992\n",
      "Val Loss: 1.6094, Val Acc: 0.1880\n",
      "\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:20<00:00,  3.36it/s, loss=1.6112, acc=0.1999]\n",
      "Validation: 100%|██████████| 4/4 [00:02<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.1999\n",
      "Val Loss: 1.6094, Val Acc: 0.1820\n",
      "\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:21<00:00,  3.20it/s, loss=1.6057, acc=0.1964]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.1964\n",
      "Val Loss: 1.6094, Val Acc: 0.2080\n",
      "\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:18<00:00,  3.66it/s, loss=1.6088, acc=0.1983]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.1983\n",
      "Val Loss: 1.6094, Val Acc: 0.2110\n",
      "\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:19<00:00,  3.54it/s, loss=1.6073, acc=0.1979]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6096, Train Acc: 0.1979\n",
      "Val Loss: 1.6094, Val Acc: 0.2110\n",
      "\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:20<00:00,  3.38it/s, loss=1.6101, acc=0.2009]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6093, Train Acc: 0.2009\n",
      "Val Loss: 1.6094, Val Acc: 0.2050\n",
      "\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:19<00:00,  3.62it/s, loss=1.6097, acc=0.2027]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6096, Train Acc: 0.2027\n",
      "Val Loss: 1.6094, Val Acc: 0.2020\n",
      "\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:21<00:00,  3.24it/s, loss=1.6078, acc=0.2099]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.2099\n",
      "Val Loss: 1.6094, Val Acc: 0.1950\n",
      "\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:21<00:00,  3.24it/s, loss=1.6109, acc=0.1960]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.1960\n",
      "Val Loss: 1.6094, Val Acc: 0.1980\n",
      "\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:20<00:00,  3.35it/s, loss=1.6086, acc=0.1987]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.1987\n",
      "Val Loss: 1.6094, Val Acc: 0.1990\n",
      "\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:21<00:00,  3.20it/s, loss=1.6088, acc=0.2002]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2002\n",
      "Val Loss: 1.6094, Val Acc: 0.2140\n",
      "\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:20<00:00,  3.35it/s, loss=1.6110, acc=0.1927]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.1927\n",
      "Val Loss: 1.6094, Val Acc: 0.2010\n",
      "\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:20<00:00,  3.34it/s, loss=1.6098, acc=0.2040]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.2040\n",
      "Val Loss: 1.6094, Val Acc: 0.2060\n",
      "\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:19<00:00,  3.48it/s, loss=1.6075, acc=0.2030]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2030\n",
      "Val Loss: 1.6094, Val Acc: 0.2010\n",
      "\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:20<00:00,  3.35it/s, loss=1.6095, acc=0.1988]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.1988\n",
      "Val Loss: 1.6094, Val Acc: 0.2010\n",
      "\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:20<00:00,  3.30it/s, loss=1.6111, acc=0.2004]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2004\n",
      "Val Loss: 1.6094, Val Acc: 0.1980\n",
      "\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:18<00:00,  3.69it/s, loss=1.6101, acc=0.1985]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.1985\n",
      "Val Loss: 1.6094, Val Acc: 0.2060\n",
      "\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:20<00:00,  3.35it/s, loss=1.6097, acc=0.2030]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2030\n",
      "Val Loss: 1.6094, Val Acc: 0.1910\n",
      "\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:20<00:00,  3.29it/s, loss=1.6091, acc=0.2016]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6093, Train Acc: 0.2016\n",
      "Val Loss: 1.6095, Val Acc: 0.1980\n",
      "\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:21<00:00,  3.18it/s, loss=1.6100, acc=0.1920]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6096, Train Acc: 0.1920\n",
      "Val Loss: 1.6094, Val Acc: 0.2160\n",
      "\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:20<00:00,  3.31it/s, loss=1.6098, acc=0.2058]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2058\n",
      "Val Loss: 1.6094, Val Acc: 0.2030\n",
      "\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:19<00:00,  3.58it/s, loss=1.6094, acc=0.1991]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.1991\n",
      "Val Loss: 1.6094, Val Acc: 0.1900\n",
      "\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:18<00:00,  3.71it/s, loss=1.6090, acc=0.2019]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2019\n",
      "Val Loss: 1.6094, Val Acc: 0.2030\n",
      "\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:19<00:00,  3.59it/s, loss=1.6086, acc=0.2017]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.2017\n",
      "Val Loss: 1.6094, Val Acc: 0.1990\n",
      "\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:18<00:00,  3.68it/s, loss=1.6077, acc=0.2059]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2059\n",
      "Val Loss: 1.6095, Val Acc: 0.1980\n",
      "\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:18<00:00,  3.68it/s, loss=1.6087, acc=0.2027]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2027\n",
      "Val Loss: 1.6094, Val Acc: 0.2150\n",
      "\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:19<00:00,  3.61it/s, loss=1.6086, acc=0.2025]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2025\n",
      "Val Loss: 1.6094, Val Acc: 0.2020\n",
      "\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:18<00:00,  3.68it/s, loss=1.6087, acc=0.1991]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6096, Train Acc: 0.1991\n",
      "Val Loss: 1.6094, Val Acc: 0.2040\n",
      "\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:18<00:00,  3.72it/s, loss=1.6102, acc=0.2032]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2032\n",
      "Val Loss: 1.6094, Val Acc: 0.2180\n",
      "\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:19<00:00,  3.56it/s, loss=1.6098, acc=0.1930]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.1930\n",
      "Val Loss: 1.6094, Val Acc: 0.1990\n",
      "\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:18<00:00,  3.66it/s, loss=1.6092, acc=0.1993]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.1993\n",
      "Val Loss: 1.6094, Val Acc: 0.2030\n",
      "\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:18<00:00,  3.68it/s, loss=1.6097, acc=0.1962]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.1962\n",
      "Val Loss: 1.6094, Val Acc: 0.2080\n",
      "\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:19<00:00,  3.56it/s, loss=1.6092, acc=0.2040]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6095, Train Acc: 0.2040\n",
      "Val Loss: 1.6094, Val Acc: 0.2060\n",
      "\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:18<00:00,  3.69it/s, loss=1.6086, acc=0.2049]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2049\n",
      "Val Loss: 1.6094, Val Acc: 0.1960\n",
      "\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:18<00:00,  3.73it/s, loss=1.6102, acc=0.2002]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6094, Train Acc: 0.2002\n",
      "Val Loss: 1.6094, Val Acc: 0.2100\n",
      "\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 69/69 [00:18<00:00,  3.76it/s, loss=1.6106, acc=0.2000]\n",
      "Validation: 100%|██████████| 4/4 [00:01<00:00,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6096, Train Acc: 0.2000\n",
      "Val Loss: 1.6094, Val Acc: 0.1990\n",
      "Training completed in 34.09 minutes\n",
      "Best validation accuracy: 0.2280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▃▂▃▁▂▁▅▆▇▁▄▇▁▂▇▃█▂█▃▃▃▅▂▅▅▄▄▄▅▅▁▆▅▆▇▅▄▆▅</td></tr><tr><td>train_loss</td><td>▇▄▂▇▅█▄▅▄▃▅▄▃▃▅█▂▃▃▆▆▅▄▆▁▅▅▃▄▆▃▅▅▅▃▆▄▄▃▄</td></tr><tr><td>val_accuracy</td><td>▃▂▁▃█▂▇▂▄▆▄▆▃▅▄▇▄▂▆▄▆▄▁▅▄▃▃▂▁▇▄▇▄▆█▄▅▄▆▄</td></tr><tr><td>val_loss</td><td>▅▂▅▄▄▃▅▅▃▆▄▃▄▂▅▅▂▄▁▄▄▄▅▄▄▅▅▄▂▃▄▄▂▆▅█▅▃▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_accuracy</td><td>0.228</td></tr><tr><td>epoch</td><td>99</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>train_accuracy</td><td>0.19998</td></tr><tr><td>train_loss</td><td>1.6096</td></tr><tr><td>val_accuracy</td><td>0.199</td></tr><tr><td>val_loss</td><td>1.60941</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rnn-2025-04-05T18:16:16</strong> at: <a href='https://wandb.ai/fabian-dubach-hochschule-luzern/CommonsenseQA/runs/x1ic3q0l' target=\"_blank\">https://wandb.ai/fabian-dubach-hochschule-luzern/CommonsenseQA/runs/x1ic3q0l</a><br> View project at: <a href='https://wandb.ai/fabian-dubach-hochschule-luzern/CommonsenseQA' target=\"_blank\">https://wandb.ai/fabian-dubach-hochschule-luzern/CommonsenseQA</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250405_181616-x1ic3q0l\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN Training complete! Best validation accuracy: 0.2280\n"
     ]
    }
   ],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, best_val_accuracy, save_path):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'best_val_accuracy': best_val_accuracy\n",
    "    }\n",
    "    torch.save(checkpoint, save_path)\n",
    "    try:\n",
    "        if 'best_model' in save_path:\n",
    "            wandb.log({\n",
    "                \"best_model_checkpoint\": {\n",
    "                    \"path\": save_path,\n",
    "                    \"epoch\": epoch,\n",
    "                    \"val_accuracy\": best_val_accuracy\n",
    "                }\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error logging checkpoint to wandb: {e}\")\n",
    "\n",
    "def train_rnn_model(model, criterion, optimizer, train_loader, valid_loader, num_epochs, device, checkpoints_path=None, log_wandb=True, gradient_clip_val=1.0):\n",
    "    best_val_accuracy = 0.0\n",
    "    training_start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        with tqdm(train_loader, desc=\"Training\") as progress_bar:\n",
    "            for batch_data in progress_bar:\n",
    "                # Unpack the batch data\n",
    "                padded_sequences, sequence_lengths, indices, answers = batch_data\n",
    "                \n",
    "                # Move to device\n",
    "                padded_sequences = padded_sequences.to(device)\n",
    "                sequence_lengths = sequence_lengths.to(device)\n",
    "                indices = indices.to(device)\n",
    "                answers = answers.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(padded_sequences, sequence_lengths, indices)\n",
    "                loss = criterion(outputs, answers)\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                if gradient_clip_val > 0:\n",
    "                    nn.utils.clip_grad_norm_(model.parameters(), gradient_clip_val)\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Statistics\n",
    "                train_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += answers.size(0)\n",
    "                train_correct += (predicted == answers).sum().item()\n",
    "                \n",
    "                # Update progress bar\n",
    "                progress_bar.set_postfix({\n",
    "                    'loss': f\"{loss.item():.4f}\",\n",
    "                    'acc': f\"{train_correct/train_total:.4f}\"\n",
    "                })\n",
    "        \n",
    "        train_accuracy = train_correct / train_total\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_data in tqdm(valid_loader, desc=\"Validation\"):\n",
    "                # Unpack the batch data\n",
    "                padded_sequences, sequence_lengths, indices, answers = batch_data\n",
    "                \n",
    "                # Move to device\n",
    "                padded_sequences = padded_sequences.to(device)\n",
    "                sequence_lengths = sequence_lengths.to(device)\n",
    "                indices = indices.to(device)\n",
    "                answers = answers.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(padded_sequences, sequence_lengths, indices)\n",
    "                loss = criterion(outputs, answers)\n",
    "                \n",
    "                # Statistics\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += answers.size(0)\n",
    "                val_correct += (predicted == answers).sum().item()\n",
    "        \n",
    "        val_accuracy = val_correct / val_total\n",
    "        avg_val_loss = val_loss / len(valid_loader)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            print(f\"Validation accuracy improved from {best_val_accuracy:.4f} to {val_accuracy:.4f}\")\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model_path = os.path.join(checkpoints_path, 'best_rnn_model.pt')\n",
    "            save_checkpoint(model, optimizer, epoch+1, best_val_accuracy, best_model_path)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.4f}\")\n",
    "        print(f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "        \n",
    "        # Log to wandb\n",
    "        if log_wandb:\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch,\n",
    "                \"train_loss\": avg_train_loss,\n",
    "                \"train_accuracy\": train_accuracy,\n",
    "                \"val_loss\": avg_val_loss,\n",
    "                \"val_accuracy\": val_accuracy,\n",
    "                \"learning_rate\": optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "    \n",
    "    print(f\"Training completed in {(time.time() - training_start_time)/60:.2f} minutes\")\n",
    "    print(f\"Best validation accuracy: {best_val_accuracy:.4f}\")\n",
    "    \n",
    "    # Final metrics for wandb\n",
    "    if log_wandb:\n",
    "        wandb.run.summary[\"best_val_accuracy\"] = best_val_accuracy\n",
    "        wandb.finish()\n",
    "    \n",
    "    return model, best_val_accuracy\n",
    "\n",
    "# Modify the training setup to remove scheduler from checkpoint saving\n",
    "try:\n",
    "    trained_rnn_model, best_rnn_accuracy = train_rnn_model(\n",
    "        model=rnn_model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        train_loader=train_rnn_loader,\n",
    "        valid_loader=valid_rnn_loader,\n",
    "        num_epochs=num_epochs,\n",
    "        device=device,\n",
    "        checkpoints_path=checkpoints_path,\n",
    "        log_wandb=True,\n",
    "        gradient_clip_val=rnn_run.config.gradient_clipping\n",
    "    )\n",
    "    print(f\"RNN Training complete! Best validation accuracy: {best_rnn_accuracy:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Training failed with error: {e}\")\n",
    "    import traceback\n",
    "    import sys\n",
    "    \n",
    "    # Print detailed traceback\n",
    "    print(\"Detailed error traceback:\")\n",
    "    traceback.print_exc()\n",
    "    \n",
    "    # Try to save the model\n",
    "    try:\n",
    "        torch.save(rnn_model.state_dict(), os.path.join(checkpoints_path, \"emergency_save.pt\"))\n",
    "        print(\"Model saved in emergency mode\")\n",
    "    except Exception as save_error:\n",
    "        print(f\"Failed to save model: {save_error}\")\n",
    "    \n",
    "    # Re-raise the original exception\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**run1**\n",
    "batch_size = 32\n",
    "embedding_dim = 300\n",
    "hidden_dim = 64\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Interpretation**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
