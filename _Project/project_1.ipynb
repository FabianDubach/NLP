{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **FS25 NLP Project 1: Word Embeddings/Recurrent Neural Networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fabian Dubach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task for this project was to answer common sense questions with the usage of two different architectures: Word embeddings (word2vec, GloVe or fastText) with a classifier and a 2-layer RNN architecture with a classifier (LSTM or GRU). We had to also track the trainings with Wandb (workspace URL: https://wandb.ai/fabian-dubach-hochschule-luzern/CommonsenseQA?nw=nwuserfabiandubach)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all libraries needed to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim\n",
    "\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup random seed to ensure reproducibility.\n",
    "\n",
    "_Info about the seed value: The field of natural language processing began in the 1940s, after World War II. At this time, people recognized the importance of translation from one language to another and hoped to create a machine that could do this sort of translation automatically._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1940\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download tokenizer files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pre-trained FastText word embeddings (300 dimensions)\n",
    "\n",
    "I first wanted to choose GloVe, because I've seen that GloVe performs well on semantic similarity and analogical reasoning. Due to the fact that GloVe can only handle uncased embeddings (lowercase), I chose to use FastText. I used 300 dimensions, because it represents word meanings more completely than smaller options (50- or 100 dimensions) while still being practical to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = hf_hub_download(repo_id=\"facebook/fasttext-en-vectors\", filename=\"model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model = gensim.models.fasttext.load_facebook_model(model_path)\n",
    "wv = fasttext_model.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at vector- and vocab size from the loaded embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vector size:\", wv.vector_size)\n",
    "print(\"Vocab size:\", len(wv.index_to_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if known and unknown words create vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wv[\"Hello\"])\n",
    "print(wv[\"jwadAJKJDwljlkdajl\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the project, we had to use the CommonsenseQA dataset, which is a multiple-choice question answering dataset that contains 12'247 different questions and was developed to benchmark machine understanding of everyday knowledge. For each questions there are 5 given answer choices, where only one of them is correct. To be able to answer these questions, \"commonsense\" is needed. The dataset is available on HuggingFace: https://huggingface.co/datasets/tau/commonsense_qa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I split the dataset into training, validation and test sets to allow for model development and evaluation. I used the last 1'000 examples from the training set for validation and the original validation set for testing, since the real test set has no answer keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_dataset(\"tau/commonsense_qa\", split=\"train[:-1000]\")\n",
    "valid = load_dataset(\"tau/commonsense_qa\", split=\"train[-1000:]\")\n",
    "test = load_dataset(\"tau/commonsense_qa\", split=\"validation\")\n",
    "\n",
    "print(len(train), len(valid), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Login for the experiment tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Exploration**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section I tried to get some insight to understand its structure and patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Explore dataset structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\033[4m\" + \"Dataset Features\" + \"\\033[0m\")\n",
    "for feature in train.features:\n",
    "    print(feature)\n",
    "print(\"\\n\" + \"\\033[4m\" + \"Example\" + \"\\033[0m\")\n",
    "for feature in train.features:\n",
    "    print(feature + \":\", train[0][str(feature)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get a general info about each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_df(dataset):\n",
    "    return pd.DataFrame(dataset)\n",
    "\n",
    "train_df = dataset_to_df(train)\n",
    "valid_df = dataset_to_df(valid)\n",
    "test_df = dataset_to_df(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\033[4m\" + \"Train Info\" + \"\\033[0m\")\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\033[4m\" + \"Validation Info\" + \"\\033[0m\")\n",
    "print(valid_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\033[4m\" + \"Test Info\" + \"\\033[0m\")\n",
    "print(test_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Analyze question lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([train_df, valid_df, test_df], ignore_index=True)\n",
    "\n",
    "combined_df['question_length'] = combined_df['question'].apply(len)\n",
    "combined_df['question_word_count'] = combined_df['question'].apply(lambda x: len(x.split()))\n",
    "\n",
    "print(\"\\033[4m\" + \"Question length (characters)\" + \"\\033[0m\")\n",
    "print(f\"Min: {combined_df['question_length'].min()}\")\n",
    "print(f\"Max: {combined_df['question_length'].max()}\")\n",
    "print(f\"Mean: {combined_df['question_length'].mean():.2f}\")\n",
    "print(f\"Median: {combined_df['question_length'].median()}\")\n",
    "\n",
    "print(\"\\n\\033[4m\" + \"Question Word Count\" + \"\\033[0m\")\n",
    "print(f\"Min: {combined_df['question_word_count'].min()}\")\n",
    "print(f\"Max: {combined_df['question_word_count'].max()}\")\n",
    "print(f\"Mean: {combined_df['question_word_count'].mean():.2f}\")\n",
    "print(f\"Median: {combined_df['question_word_count'].median()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Analyze option lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_option_lengths(choices):\n",
    "    return [len(text) for text in choices['text']]\n",
    "\n",
    "def get_option_word_counts(choices):\n",
    "    return [len(text.split()) for text in choices['text']]\n",
    "\n",
    "combined_df['option_lengths'] = combined_df['choices'].apply(get_option_lengths)\n",
    "combined_df['option_word_counts'] = combined_df['choices'].apply(get_option_word_counts)\n",
    "\n",
    "# Flatten the lists for analysis\n",
    "all_option_lengths = [length for lengths in combined_df['option_lengths'] for length in lengths]\n",
    "all_option_word_counts = [count for counts in combined_df['option_word_counts'] for count in counts]\n",
    "\n",
    "print(\"\\033[4m\" + \"Option length (characters)\" + \"\\033[0m\")\n",
    "print(f\"Min: {min(all_option_lengths)}\")\n",
    "print(f\"Max: {max(all_option_lengths)}\")\n",
    "print(f\"Mean: {np.mean(all_option_lengths):.2f}\")\n",
    "print(f\"Median: {np.median(all_option_lengths)}\")\n",
    "\n",
    "print(\"\\033[4m\" + \"\\nOption word count\" + \"\\033[0m\")\n",
    "print(f\"Min: {min(all_option_word_counts)}\")\n",
    "print(f\"Max: {max(all_option_word_counts)}\")\n",
    "print(f\"Mean: {np.mean(all_option_word_counts):.2f}\")\n",
    "print(f\"Median: {np.median(all_option_word_counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Analyze answer distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer_letter(example):\n",
    "    return example['answerKey']\n",
    "\n",
    "combined_df['answer_letter'] = combined_df.apply(extract_answer_letter, axis=1)\n",
    "\n",
    "print(\"\\033[4m\" + \"Answer Distribution\" + \"\\033[0m\")\n",
    "print(combined_df['answer_letter'].value_counts(), \"\\n\")\n",
    "print(combined_df['answer_letter'].value_counts(normalize=True).mul(100).round(2).astype(str) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Extract common question words/phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_words(text_series, top_n=20):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    all_words = []\n",
    "    \n",
    "    for text in text_series:\n",
    "        words = word_tokenize(text.lower())\n",
    "        filtered_words = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "        all_words.extend(filtered_words)\n",
    "    \n",
    "    return Counter(all_words).most_common(top_n)\n",
    "\n",
    "print(\"\\033[4m\" + \"Common Words in Questions\" + \"\\033[0m\")\n",
    "common_words = get_common_words(train_df['question'], 10)\n",
    "for word, count in common_words:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Visualize question length distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(combined_df['question_word_count'], bins=20, kde=True)\n",
    "plt.title('Distribution of Question Word Count')\n",
    "plt.xlabel('Number of Words')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Visualize answer distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "sns.countplot(x='answer_letter', data=combined_df, order=combined_df['answer_letter'].value_counts().index)\n",
    "plt.title('Distribution of Answers')\n",
    "plt.xlabel('Answer Option')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the preprocessing I looked at the following points:\n",
    "\n",
    "1. Tokenization\n",
    "2. Lowercasing, stemming, lemmatizing, stopword/punctuation removal \n",
    "3. Removal of unknown/other words \n",
    "4. Format cleaning (e.g. html-extracted text) \n",
    "5. Truncation \n",
    "6. Feature selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are my decisions and justifications for using or not using the above listed preprocessing methods:\n",
    "\n",
    "1. Tokenization is absolutely mandatory.\n",
    "2. I chose not to use lowercasing to keep the semantic meaning of the words. Stemming and lemmatizing are not needed, because FastText already captures semantic similarities. Stopword/Punctuation removal is generally not a needed for a RNN due to the fact that the model can then learn to ignore irrelevant words by itself.\n",
    "3. Removal of unknown/other words is also not needed, because FastText can handle them.\n",
    "4. Format cleaning is not needed, because the CommonsenseQA dataset doesn't include any markup text.\n",
    "5. Due to the fact that the longest question is 376 characters long, truncation is not needed.\n",
    "6. Feature selection is also not needed. RNNs typically work with the full sequence rather than selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    tokens = nltk.tokenize.word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The get_embedding function transforms any text sentence into a fixed-length vector representation by averaging the word embeddings of each token in the sentence. If no tokens were found, a zero vector is being returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(sentence):\n",
    "    tokens = preprocessing(sentence)\n",
    "    word_vectors = []\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            word_vectors.append(fasttext_model.wv[token])\n",
    "        except KeyError:\n",
    "            # Skip tokens not in vocabulary\n",
    "            continue\n",
    "    \n",
    "    # Return the mean of the word vectors\n",
    "    if word_vectors:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(fasttext_model.vector_size)  # Return a zero vector if no tokens were found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model to interpret the answers correctly, I converted the answer keys into numerical indices (0, 1, 2, 3, 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_key_to_index(answer_key):\n",
    "  return ord(answer_key) - ord(\"A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compute_embeddings function creates embeddings for every text data (questions and choices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings(example):\n",
    "    question_embeddings = get_embedding(example[\"question\"])\n",
    "    choice_embeddings = [get_embedding(choice) for choice in example[\"choices\"][\"text\"]]\n",
    "    \n",
    "    example[\"question_emb\"] = question_embeddings.tolist()\n",
    "    example[\"choice_embs\"] = [embedding.tolist() for embedding in choice_embeddings]\n",
    "    return example\n",
    "\n",
    "train = train.map(compute_embeddings)\n",
    "valid = valid.map(compute_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Word Embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a class which can convert a regular dataset into a PyTorch-compatible dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonsenseQADataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.data = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        example = self.data[idx]\n",
    "        question_tensor = torch.tensor(example[\"question_emb\"]).float()\n",
    "        choices_tensor = torch.tensor(example[\"choice_embs\"]).float()\n",
    "        answer_index = answer_key_to_index(example[\"answerKey\"])\n",
    "        return question_tensor, choices_tensor, torch.tensor(answer_index).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **RNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement class that creates a PyTorch-compatible dataset for processing question-answering pairs through an RNN model. It tokenizes text, combines each question with each possible answer (separated by a special token), converts tokens to embedding vectors and returns these sequences along with their lengths and the correct answer index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonsenseQARNNDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, word_vectors, embedding_dim=300):\n",
    "        self.data = hf_dataset\n",
    "        self.wv = word_vectors\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.SEP_TOKEN = \"<SEP>\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        example = self.data[idx]\n",
    "        \n",
    "        # Tokenize question and choices\n",
    "        question_tokens = preprocessing(example[\"question\"])\n",
    "        choice_tokens = [preprocessing(choice) for choice in example[\"choices\"][\"text\"]]\n",
    "        \n",
    "        # Create sequences and lengths for each choice\n",
    "        sequences = []\n",
    "        lengths = []\n",
    "        for choice in choice_tokens:\n",
    "            # Combine question and choice\n",
    "            full_sequence = question_tokens + [self.SEP_TOKEN] + choice\n",
    "            \n",
    "            # Convert to embeddings\n",
    "            embeddings = []\n",
    "            for token in full_sequence:\n",
    "                try:\n",
    "                    # Use pretrained embedding\n",
    "                    if token == self.SEP_TOKEN:\n",
    "                        embeddings.append(torch.randn(self.embedding_dim) * 0.1)\n",
    "                    else:\n",
    "                        embeddings.append(torch.tensor(self.wv[token]))\n",
    "                except KeyError:\n",
    "                    # For OOV words, use random embedding\n",
    "                    embeddings.append(torch.randn(self.embedding_dim) * 0.1)\n",
    "            \n",
    "            # Convert to tensor\n",
    "            sequences.append(torch.stack(embeddings))\n",
    "            lengths.append(len(embeddings))\n",
    "        \n",
    "        # Convert answer to index\n",
    "        answer = ord(example[\"answerKey\"]) - ord(\"A\")\n",
    "        \n",
    "        return sequences, torch.tensor(lengths), torch.tensor(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function prepares batches of sequence data for efficient RNN processing.\n",
    "\n",
    "1. Collect and flatten all sequences, lengths and answers from the batch\n",
    "2. Sort sequences by length in descending order (optimizing RNN computation)\n",
    "3. Pad shorter sequences to match the longest one\n",
    "4. Create a mapping index to help reconstruct the original batch organization\n",
    "5. Return the padded sequences, their sorted lengths, reconstruction indices and answer labels\n",
    "\n",
    "The sorting step is important for using packed sequences in RNNs, which improves efficiency by processing only valid parts of each sequence, while the indices allow the model to match processed sequences back to their original question-answer pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_collate_batch(batch):\n",
    "    # Separate sequences, lengths, and answers\n",
    "    all_sequences = []\n",
    "    all_lengths = []\n",
    "    all_answers = []\n",
    "    \n",
    "    batch_size = len(batch)\n",
    "    num_choices = len(batch[0][0])  # Number of choices per example\n",
    "    \n",
    "    for sequences, lengths, answer in batch:\n",
    "        all_sequences.extend(sequences)\n",
    "        all_lengths.append(lengths)\n",
    "        all_answers.append(answer)\n",
    "    \n",
    "    # Combine and sort lengths\n",
    "    lengths_tensor = torch.cat(all_lengths)\n",
    "    sorted_indices = torch.argsort(lengths_tensor, descending=True)\n",
    "    \n",
    "    # Reorder sequences and lengths based on sorted indices\n",
    "    sorted_sequences = [all_sequences[i] for i in sorted_indices]\n",
    "    sorted_lengths = lengths_tensor[sorted_indices]\n",
    "    \n",
    "    # Pad sequences\n",
    "    padded_sequences = pad_sequence(sorted_sequences, batch_first=True)\n",
    "    \n",
    "    # Create indices to reconstruct original batch order\n",
    "    indices = torch.arange(len(sorted_indices)).view(batch_size, num_choices)\n",
    "    \n",
    "    # Stack answers\n",
    "    answers_tensor = torch.stack(all_answers)\n",
    "    \n",
    "    return padded_sequences, sorted_lengths, indices, answers_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This WordEmbeddingQAClassifier is a neural network model for multiple-choice question answering using pre-computed word embeddings.\n",
    "\n",
    "1. Take already-embedded question and choice vectors as input\n",
    "2. Expand the question embedding to pair with each answer choice\n",
    "3. Concatenate each question-choice pair along the feature dimension\n",
    "4. Processe these concatenated vectors through a simple feed-forward network:\n",
    "    - A hidden layer with ReLU activation and dropout for regularization\n",
    "    - An output layer that produces a single score for each question-choice pair\n",
    "\n",
    "\n",
    "\n",
    "The model essentially measures compatibility between questions and potential answers, with higher scores indicating better matches. During training, these scores are compared against the correct answer to tune the model's parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbeddingQAClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, dropout_rate):\n",
    "        super(WordEmbeddingQAClassifier, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # First layer: concatenated embedding dimension\n",
    "        self.fc1 = nn.Linear(2 * embedding_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Output layer for classification\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, question, choices):\n",
    "        # Expand question to match choices dimension\n",
    "        question_expanded = question.unsqueeze(1).expand(-1, choices.size(1), -1)\n",
    "        \n",
    "        # Concatenate question and choice embeddings\n",
    "        combined = torch.cat((question_expanded, choices), dim=2)\n",
    "\n",
    "        # First layer with ReLU and Dropout\n",
    "        x = self.fc1(combined)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Final layer\n",
    "        x = self.fc2(x)\n",
    "        return x.squeeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This QARNNModel class implements a neural network for question answering using an LSTM (Long Short-Term Memory) network. The reason why I chose the LSTM network is, that I think the LSTM's memory cell structure might better preserve information across the combined question-answer sequences, especially when there are key contextual elements that need to be remembered from earlier parts of the sequence to evaluate answer choices properly.\n",
    "\n",
    "1. Process sequences of word embeddings through a bidirectional LSTM with 2 layers\n",
    "2. The LSTM handles variable-length sequences efficiently by using packed sequences\n",
    "3. After processing through the LSTM, it extracts the final hidden states from both directions (forward and backward) and concatenates them\n",
    "4. These concatenated hidden states are passed through a classification head (a simple feed-forward network)\n",
    "5. The classification head outputs a score for each sequence\n",
    "6. The scores are then rearranged to match each question with its multiple answer choices using the indices parameter\n",
    "\n",
    "The bidirectional nature of the LSTM allows the model to incorporate context from both before and after each word in the sequence. The model combines the question and each potential answer into a single sequence, processes them through the LSTM, and outputs scores indicating which answer is most likely correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QARNNModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim=128, num_choices=5, dropout_rate=0.2):\n",
    "        super(QARNNModel, self).__init__()\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_choices = num_choices\n",
    "        \n",
    "        # 2-layer bidirectional LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=dropout_rate,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # Classification head\n",
    "        lstm_output_dim = hidden_dim * 2  # bidirectional = *2\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(lstm_output_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, padded_sequences, sequence_lengths, indices):\n",
    "        \"\"\"Process all sequences together and then reshape for classification\"\"\"\n",
    "        batch_size = indices.size(0)\n",
    "        \n",
    "        # Pack padded sequences with enforce_sorted=False\n",
    "        packed = pack_padded_sequence(\n",
    "            padded_sequences, \n",
    "            sequence_lengths.cpu(), \n",
    "            batch_first=True,\n",
    "            enforce_sorted=False\n",
    "        )\n",
    "        \n",
    "        # Run through LSTM\n",
    "        _, (hidden, _) = self.lstm(packed)\n",
    "        \n",
    "        # Get final hidden states from both directions\n",
    "        final_hidden = torch.cat([hidden[-2], hidden[-1]], dim=1)\n",
    "        \n",
    "        # Process through classifier\n",
    "        logits = self.classifier(final_hidden).squeeze(-1)\n",
    "        \n",
    "        # Rearrange back to original order\n",
    "        all_logits = torch.zeros(batch_size, self.num_choices, device=padded_sequences.device)\n",
    "        for batch_idx in range(batch_size):\n",
    "            for choice_idx in range(self.num_choices):\n",
    "                all_logits[batch_idx, choice_idx] = logits[indices[batch_idx, choice_idx]]\n",
    "        \n",
    "        return all_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Check if a CUDA-compatible GPU is available and set the device for tensor computations accordingly, otherwise use CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This save_chekpoint function saves model checkpoints during training by storing the model's state, optimizer state, current epoch and best validation accuracy to a file path. When saving the best-performing model, it also logs this information to Weights & Biases (wandb) for tracking, with error handling in case the logging fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, best_val_accuracy, save_path):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'best_val_accuracy': best_val_accuracy\n",
    "    }\n",
    "    torch.save(checkpoint, save_path)\n",
    "    try:\n",
    "        if 'best_model' in save_path:\n",
    "            wandb.log({\n",
    "                \"best_model_checkpoint\": {\n",
    "                    \"path\": save_path,\n",
    "                    \"epoch\": epoch,\n",
    "                    \"val_accuracy\": best_val_accuracy\n",
    "                }\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error logging checkpoint to wandb: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Word Embedding Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set hyperparameters for the word embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim_word_embedding = 300 # FastText -> 300d\n",
    "hidden_dim_word_embedding = 64\n",
    "dropout_rate_word_embedding = 0.2\n",
    "learning_rate_word_embedding = 1e-4\n",
    "weight_decay_word_embedding = 1e-5\n",
    "batch_size_word_embedding = 32\n",
    "num_epochs_word_embedding = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a PyTorch-compatible dataset for the train and the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_word_embedding = CommonsenseQADataset(train)\n",
    "valid_dataset_word_embedding = CommonsenseQADataset(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two PyTorch DataLoader objects to efficiently batch and load data during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset_word_embedding, \n",
    "    batch_size=batch_size_word_embedding, \n",
    "    shuffle=True, \n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset_word_embedding, \n",
    "    batch_size=batch_size_word_embedding, \n",
    "    shuffle=False,  # No need to shuffle validation data\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the word embedding model and move it to the appropriate computing device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_model = WordEmbeddingQAClassifier(embedding_dim=embedding_dim_word_embedding, hidden_dim=hidden_dim_word_embedding, dropout_rate=dropout_rate_word_embedding)\n",
    "word_embedding_model = word_embedding_model.to(device)\n",
    "\n",
    "print(word_embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the loss function and optimizer for training the word embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_word_embedding = nn.CrossEntropyLoss()\n",
    "optimizer_word_embedding = torch.optim.AdamW(word_embedding_model.parameters(), lr=learning_rate_word_embedding, weight_decay=weight_decay_word_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializes wandb tracking run for experiment monitoring of the word embedding model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_run = wandb.init(\n",
    "  project=\"CommonsenseQA\",\n",
    "  name=f\"word_embedding-{datetime.now().strftime('%Y-%m-%dT%H:%M:%S')}\",\n",
    "  config={\n",
    "    \"model\": \"word_embedding\",\n",
    "    \"embedding_dim\": embedding_dim_word_embedding,\n",
    "    \"hidden_dim\": hidden_dim_word_embedding,\n",
    "    \"batch_size\": batch_size_word_embedding,\n",
    "    \"epoch\": num_epochs_word_embedding,\n",
    "    \"dropout_rate\": dropout_rate_word_embedding,\n",
    "    \"weight_decay\": weight_decay_word_embedding,\n",
    "  },\n",
    "  reinit=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train_word_embedding() function is the training loop function for a the word embedding model. It handles training, validation, logging and model checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_word_embedding(\n",
    "    model, \n",
    "    train_loader, \n",
    "    valid_loader, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    num_epochs, \n",
    "    device, \n",
    "    checkpoint_dir='checkpoints', \n",
    "    save_interval=1,\n",
    "):\n",
    "    # Create checkpoint directory if it doesn't exist\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    # Initialize best validation accuracy\n",
    "    best_word_embedding_accuracy = 0\n",
    "    start_epoch = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in (pbar := trange(start_epoch, num_epochs)):\n",
    "        pbar.set_description(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        model.train()\n",
    "        train_total_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for question_batch, choices_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            question_batch = question_batch.to(device)\n",
    "            choices_batch = choices_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(question_batch, choices_batch)\n",
    "\n",
    "            # Compute loss\n",
    "            train_batch_loss = criterion(outputs, y_batch)\n",
    "            train_total_loss += train_batch_loss.item()\n",
    "\n",
    "            # Compute accuracy\n",
    "            train_predictions = torch.argmax(outputs, dim=1)\n",
    "            train_correct += (train_predictions == y_batch).sum().item()\n",
    "            train_total += y_batch.size(0)\n",
    "\n",
    "            # Backward pass\n",
    "            train_batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Calculate train statistics\n",
    "        avg_train_loss = train_total_loss / len(train_loader)\n",
    "        train_accuracy = train_correct / train_total\n",
    "\n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_total_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for question_batch, choices_batch, y_batch in valid_loader:\n",
    "                question_batch = question_batch.to(device)\n",
    "                choices_batch = choices_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "\n",
    "                val_outputs = model(question_batch, choices_batch)\n",
    "\n",
    "                # Calculate validation loss\n",
    "                val_batch_loss = criterion(val_outputs, y_batch)\n",
    "                val_total_loss += val_batch_loss.item()\n",
    "\n",
    "                val_predictions = torch.argmax(val_outputs, dim=1)\n",
    "                val_correct += (val_predictions == y_batch).sum().item()\n",
    "                val_total += y_batch.size(0)\n",
    "\n",
    "        # Calculate validation statistics\n",
    "        avg_val_loss = val_total_loss / len(valid_loader)\n",
    "        val_accuracy = val_correct / val_total\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            \"train_loss\": avg_train_loss, \n",
    "            \"train_acc\": train_accuracy, \n",
    "            \"val_acc\": val_accuracy\n",
    "        })\n",
    "\n",
    "        # Log metrics to wandb\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": avg_train_loss,\n",
    "            \"train_accuracy\": train_accuracy,\n",
    "            \"val_loss\": avg_val_loss,\n",
    "            \"val_accuracy\": val_accuracy,\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
    "        })\n",
    "\n",
    "        # Save checkpoint periodically\n",
    "        if (epoch + 1) % save_interval == 0:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch+1}.pt')\n",
    "            save_checkpoint(model, optimizer, epoch+1, checkpoint_path, best_word_embedding_accuracy)\n",
    "\n",
    "        # Save best model based on validation accuracy\n",
    "        if val_accuracy > best_word_embedding_accuracy:\n",
    "            best_word_embedding_accuracy = val_accuracy\n",
    "            best_model_path = os.path.join(checkpoint_dir, 'best_model.pt')\n",
    "            save_checkpoint(model, optimizer, epoch+1, best_model_path, best_word_embedding_accuracy)\n",
    "\n",
    "    # Final save\n",
    "    final_model_path = os.path.join(checkpoint_dir, 'final_model.pt')\n",
    "    save_checkpoint(model, optimizer, num_epochs, final_model_path, best_word_embedding_accuracy)\n",
    "    \n",
    "    wandb.finish()\n",
    "    \n",
    "    return model, best_word_embedding_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define checkpoint directory for the word embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir_embedding_model = f\"./checkpoints/embedding-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "os.makedirs(checkpoint_dir_embedding_model, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training for the word embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, best_word_embedding_accuracy = train_word_embedding(\n",
    "    model=word_embedding_model,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    criterion=criterion_word_embedding,\n",
    "    optimizer=optimizer_word_embedding,\n",
    "    num_epochs=num_epochs_word_embedding,\n",
    "    device=device,\n",
    "    checkpoint_dir=checkpoint_dir_embedding_model,\n",
    "    save_interval=1  # Save a checkpoint every epoch\n",
    ")\n",
    "\n",
    "print(f\"Word embedding training complete! Best validation accuracy: {best_word_embedding_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **RNN Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set hyperparameters for the word embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim_rnn = 300 # FastText -> 300d\n",
    "hidden_dim_rnn = 128\n",
    "dropout_rate_rnn =0.2\n",
    "learning_rate_rnn = 1e-4\n",
    "weight_decay_rnn = 1e-5\n",
    "batch_size_rnn = 128\n",
    "num_epochs_rnn = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a PyTorch-compatible dataset for the train and the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rnn_dataset = CommonsenseQARNNDataset(train, wv,embedding_dim=embedding_dim_rnn)\n",
    "valid_rnn_dataset = CommonsenseQARNNDataset(valid, wv, embedding_dim=embedding_dim_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two PyTorch DataLoader objects to efficiently batch and load data during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rnn_loader = DataLoader(\n",
    "    train_rnn_dataset,\n",
    "    batch_size=batch_size_rnn,\n",
    "    shuffle=True,\n",
    "    collate_fn=rnn_collate_batch,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "valid_rnn_loader = DataLoader(\n",
    "    valid_rnn_dataset,\n",
    "    batch_size=batch_size_rnn,\n",
    "    shuffle=False,\n",
    "    collate_fn=rnn_collate_batch,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the RNN model and move it to the appropriate computing device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = QARNNModel(embedding_dim=embedding_dim_rnn, hidden_dim=hidden_dim_rnn, dropout_rate=dropout_rate_rnn)\n",
    "rnn_model = rnn_model.to(device)\n",
    "\n",
    "print(rnn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the loss function and optimizer for training the word embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(rnn_model.parameters(), lr=learning_rate_rnn, weight_decay=weight_decay_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializes wandb tracking run for experiment monitoring of the RNN training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_run = wandb.init(\n",
    "  project=\"CommonsenseQA\",\n",
    "  name=f\"rnn-{datetime.now().strftime('%Y-%m-%dT%H:%M:%S')}\",\n",
    "  config={\n",
    "    \"model\": \"rnn\",\n",
    "    \"embedding_dim\": embedding_dim_rnn,\n",
    "    \"hidden_dim\": hidden_dim_rnn,\n",
    "    \"batch_size\": batch_size_rnn,\n",
    "    \"epoch\": num_epochs_rnn,\n",
    "    \"dropout_rate\": dropout_rate_rnn,\n",
    "    \"weight_decay\": weight_decay_word_embedding,\n",
    "  },\n",
    "  reinit=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train_rnn_model() function is the training loop function for a the RNN. It handles training, validation, logging and model checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnn_model(model, criterion, optimizer, train_loader, valid_loader, num_epochs, device, checkpoints_path=None, log_wandb=True, gradient_clip_val=1.0):\n",
    "    best_val_accuracy = 0.0\n",
    "    training_start_time = time.time()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        with tqdm(train_loader, desc=\"Training\") as progress_bar:\n",
    "            for batch_data in progress_bar:\n",
    "                # Unpack the batch data\n",
    "                padded_sequences, sequence_lengths, indices, answers = batch_data\n",
    "                \n",
    "                # Move to device\n",
    "                padded_sequences = padded_sequences.to(device)\n",
    "                sequence_lengths = sequence_lengths.to(device)\n",
    "                indices = indices.to(device)\n",
    "                answers = answers.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(padded_sequences, sequence_lengths, indices)\n",
    "                loss = criterion(outputs, answers)\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                if gradient_clip_val > 0:\n",
    "                    nn.utils.clip_grad_norm_(model.parameters(), gradient_clip_val)\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Statistics\n",
    "                train_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += answers.size(0)\n",
    "                train_correct += (predicted == answers).sum().item()\n",
    "                \n",
    "                # Update progress bar\n",
    "                progress_bar.set_postfix({\n",
    "                    'loss': f\"{loss.item():.4f}\",\n",
    "                    'acc': f\"{train_correct/train_total:.4f}\"\n",
    "                })\n",
    "        \n",
    "        train_accuracy = train_correct / train_total\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_data in tqdm(valid_loader, desc=\"Validation\"):\n",
    "                # Unpack the batch data\n",
    "                padded_sequences, sequence_lengths, indices, answers = batch_data\n",
    "                \n",
    "                # Move to device\n",
    "                padded_sequences = padded_sequences.to(device)\n",
    "                sequence_lengths = sequence_lengths.to(device)\n",
    "                indices = indices.to(device)\n",
    "                answers = answers.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(padded_sequences, sequence_lengths, indices)\n",
    "                loss = criterion(outputs, answers)\n",
    "                \n",
    "                # Statistics\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += answers.size(0)\n",
    "                val_correct += (predicted == answers).sum().item()\n",
    "        \n",
    "        val_accuracy = val_correct / val_total\n",
    "        avg_val_loss = val_loss / len(valid_loader)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            print(f\"Validation accuracy improved from {best_val_accuracy:.4f} to {val_accuracy:.4f}\")\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_model_path = os.path.join(checkpoints_path, 'best_rnn_model.pt')\n",
    "            save_checkpoint(model, optimizer, epoch+1, best_val_accuracy, best_model_path)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.4f}\")\n",
    "        print(f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "        \n",
    "        # Log to wandb\n",
    "        if log_wandb:\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch,\n",
    "                \"train_loss\": avg_train_loss,\n",
    "                \"train_accuracy\": train_accuracy,\n",
    "                \"val_loss\": avg_val_loss,\n",
    "                \"val_accuracy\": val_accuracy,\n",
    "                \"learning_rate\": optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "    \n",
    "    print(f\"Training completed in {(time.time() - training_start_time)/60:.2f} minutes\")\n",
    "    print(f\"Best validation accuracy: {best_val_accuracy:.4f}\")\n",
    "    \n",
    "    # Final metrics for wandb\n",
    "    if log_wandb:\n",
    "        wandb.run.summary[\"best_val_accuracy\"] = best_val_accuracy\n",
    "        wandb.finish()\n",
    "    \n",
    "    return model, best_val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define checkpoint directory for the RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir_rnn = f\"./checkpoints/rnn-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "os.makedirs(checkpoint_dir_rnn, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training for the word embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_rnn_model, best_rnn_accuracy = train_rnn_model(\n",
    "        model=rnn_model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        train_loader=train_rnn_loader,\n",
    "        valid_loader=valid_rnn_loader,\n",
    "        num_epochs=num_epochs_rnn,\n",
    "        device=device,\n",
    "        checkpoints_path=checkpoint_dir_rnn,\n",
    "        log_wandb=True,\n",
    "        gradient_clip_val=rnn_run.config.gradient_clipping\n",
    "    )\n",
    "\n",
    "print(f\"RNN training complete! Best validation accuracy: {best_rnn_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**run1**\n",
    "batch_size = 32\n",
    "embedding_dim = 300\n",
    "hidden_dim = 64\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Interpretation**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
