{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4357e38e",
   "metadata": {},
   "source": [
    "## Step 1: Set Up the CommonsenseQA Dataset\n",
    "\n",
    "Download and prepare the CommonsenseQA dataset\n",
    "Split the data into train/validation/test sets if not already done\n",
    "Understand the format (questions, multiple-choice answers)\n",
    "\n",
    "## Step 2: Set Up Three Models\n",
    "\n",
    "Randomly Initialized Transformer\n",
    "\n",
    "Build a transformer architecture from scratch\n",
    "Initialize weights randomly\n",
    "This will serve as your baseline\n",
    "\n",
    "\n",
    "Pretrained Transformer\n",
    "\n",
    "Use the same transformer architecture as Model 1\n",
    "Initialize with pretrained weights (e.g., BERT, RoBERTa)\n",
    "Make sure this model wasn't specifically trained on CommonsenseQA\n",
    "\n",
    "\n",
    "Large Language Model (1B+ parameters)\n",
    "\n",
    "Choose an LLM (e.g., GPT-2, LLaMA, OPT, BLOOM)\n",
    "No finetuning for this model - just prompt engineering\n",
    "\n",
    "\n",
    "\n",
    "## Step 3: Training/Finetuning\n",
    "\n",
    "Finetune Models 1 & 2 on CommonsenseQA train set\n",
    "\n",
    "Use the same hyperparameters for both\n",
    "Train for multiple epochs\n",
    "Save checkpoints and track validation performance\n",
    "\n",
    "\n",
    "For Model 3 (LLM), develop effective prompts instead of finetuning\n",
    "\n",
    "## Step 4: Prompt Engineering (for LLM)\n",
    "\n",
    "Design different prompt formats\n",
    "Test various instruction styles\n",
    "Try few-shot examples in prompts\n",
    "Experiment with temperature and other generation parameters\n",
    "\n",
    "## Step 5: Evaluation\n",
    "\n",
    "Evaluate all three models on the test set\n",
    "Calculate accuracy, F1 score, or other relevant metrics\n",
    "Compare performance across models\n",
    "\n",
    "## Step 6: Analysis\n",
    "\n",
    "Analyze which types of questions each model handles well/poorly\n",
    "Look at error patterns\n",
    "Discuss why certain approaches work better\n",
    "\n",
    "## Step 7: Create Presentation\n",
    "\n",
    "Summarize methodology\n",
    "Present results with visualizations\n",
    "Include discussion of findings\n",
    "Provide limitations and potential improvements\n",
    "\n",
    "Technical Requirements:\n",
    "\n",
    "Programming language: Python recommended\n",
    "Libraries: PyTorch/TensorFlow, Transformers (Hugging Face), etc.\n",
    "Computational resources: You'll need GPU access for training\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "TODO: Checkpointing, Early stopping works?, Log to Wandb, sweeps or other auto tool (optional), llm\n",
    "\n",
    "**Delete steps generated by Claude later**\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5cc4f4",
   "metadata": {},
   "source": [
    "# **FS25 NLP Project 1: Word Embeddings/Recurrent Neural Networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52707bad",
   "metadata": {},
   "source": [
    "Fabian Dubach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee79ba7",
   "metadata": {},
   "source": [
    "# **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df05906a",
   "metadata": {},
   "source": [
    "<style>\n",
    "  .container {\n",
    "    display: flex;\n",
    "    align-items: flex-start;\n",
    "    gap: 20px; /* spacing between text and ASCII art */\n",
    "    font-family: monospace;\n",
    "  }\n",
    "  .text {\n",
    "    flex: 2;\n",
    "  }\n",
    "  .ascii {\n",
    "    white-space: pre;\n",
    "    font-size: 4.5px;\n",
    "    line-height: 1.2;\n",
    "    flex: 1;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "<div class=\"container\">\n",
    "  <div class=\"text\">\n",
    "    <p>The task for my project was to perform common sense question answering using the CommonsenseQA dataset.</p><br>\n",
    "    <p>I evaluated the performance of three different Transformer-based models:</p>\n",
    "    <p>1. A randomly initialized Transformer</p>\n",
    "    <p>2. A pretrained Transformer (with the same architecture as the first Transformer)</p>\n",
    "    <p>3. A large language model (LLM) with over 1 billion parameters</p><br>\n",
    "    <p>While the first two models were finetuned on the dataset using the same hyperparameters for a fair comparison, the LLM was evaluated through prompt engineering without additional training. This setup allowed me to explore how different levels of pretraining and model scale impact common sense reasoning performance.</p>\n",
    "    <p>We had to also track the trainings with Wandb (workspace URL: <a href=\"https://wandb.ai/fabian-dubach-hochschule-luzern/CommonsenseQA/workspace?nw=nwuserfabiandubach\" target=\"_blank\">https://wandb.ai/fabian-dubach-hochschule-luzern/CommonsenseQA/workspace?nw=nwuserfabiandubach</a>).</p>\n",
    "  </div>\n",
    "\n",
    "  <div class=\"ascii\">\n",
    "<pre>\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣶⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢰⠀⠀⠀⠀⠀⣤⣤⣤⠀⠀⠀⠀⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⡇⠀⣠⡶⢿⡇⢿⣿⡏⢳⣦⠀⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣾⡛⣆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣧⣼⣿⣴⣋⡽⠮⠿⢭⣟⣏⣷⣿⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢻⣧⠘⡆⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⡼⣇⣿⡿⠶⣶⣿⣟⡛⣷⣿⢠⠙⣧⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣀⡈⣏⠇⢹⡀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⡟⢹⠁⣿⠋⠉⢹⠉⠙⣿⡇⣾⣀⣾⠀⢀⣤⡀⢀⡀⠀⠀⢀⣠⣴⣾⠛⢻⡛⢻⡄⢀⣳⡀⢀⣠⠄⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣾⣷⣾⢀⣿⡇⠀⠸⠀⠀⣿⣧⡽⠿⣟⣺⣭⠴⢿⡏⣩⣷⡾⢛⣭⣴⣿⣇⠘⣿⣷⣿⡛⠉⢻⣟⣷⠄⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⠿⢿⣟⣿⣿⡦⣶⣪⡭⠿⣚⣫⣭⣽⣶⡄⠀⢸⡇⣿⡙⣿⣿⣿⣿⣿⣿⣆⠹⣿⣿⣷⡀⠀⢿⡉⠁⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣀⣀⣤⣶⣿⠿⠛⣉⣭⣶⣾⣿⠿⠟⠛⠉⠉⢻⠀⢸⣷⣿⣇⢻⡿⣿⣿⣿⣿⠟⠀⠹⣿⣿⠃⠀⠘⣷⡀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣤⣦⣼⣿⠿⠛⣋⡁⣼⢠⣿⡿⠛⠉⠁⠀⠀⢀⡀⢀⣴⣾⠀⢸⣿⡇⢻⡄⠙⠿⠻⠛⠁⠀⢀⣠⣽⣿⣇⡀⠀⠸⣧⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢠⣾⠿⣛⣭⣴⡾⠟⠛⣧⣿⢸⡿⠀⠀⠀⠀⣰⣿⣿⣷⣾⣿⣿⠀⢸⡏⣇⢸⣷⡀⠀⢀⣠⣴⣾⠿⠛⣿⢻⣿⣹⡀⠀⢻⣆⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣴⡟⣦⠀⠀⠀⢀⡿⣵⡿⠛⠉⣡⣶⣤⣄⣿⣯⢸⣇⠀⠀⢠⣾⣿⡿⣿⣿⣿⣿⡿⠀⢸⡇⢻⡼⣿⣷⣶⠿⠛⠉⠀⠀⠀⠸⡇⣿⣿⣧⠀⠘⣿⡀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⡇⢹⠀⢀⣠⣼⣿⣿⠀⢀⣼⣿⣿⣿⣿⡇⣿⢸⣿⣀⣀⣿⡿⠿⠶⠚⠛⠉⠉⠀⠀⢸⡇⠀⢻⣾⣝⣿⡆⠀⢀⣠⡴⠖⠛⢻⡾⣿⣿⣆⠀⢹⡇⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣇⣼⡾⠟⠋⣿⢻⣇⣤⣌⠻⢿⣿⣿⣿⠃⢿⠀⠉⠉⠁⠀⠀⠀⣀⣤⡤⠶⠶⠒⠚⣻⣷⣄⠈⣿⣿⣿⣿⡞⠉⠀⠀⠀⠀⠀⣿⢿⣿⣾⣋⣽⠇⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣹⠏⠀⠀⠀⣿⢿⣿⣿⣯⡴⠾⠛⢋⣡⠶⠛⠛⠋⣉⣉⣉⣙⢻⣿⠀⠀⠀⠀⠀⢠⡟⠀⠈⠻⢦⣈⣿⣿⣧⠀⠀⢀⣠⣴⡾⢿⣿⣿⣿⣿⣿⡀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢠⡟⣿⡟⠀⠀⠀⣿⠈⠋⠉⢀⣠⠴⣛⣩⣤⣶⣞⣭⣿⢿⣿⣿⣻⣼⣿⣆⣀⣤⣤⣴⣿⣄⣠⣶⣦⣀⣙⣿⣿⣿⡶⣿⠟⠋⣁⣶⠟⢻⣽⣿⣿⣿⠇⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⢠⣿⣇⠀⠀⠀⢹⣠⡴⠖⢻⣷⢫⣿⣿⣿⣯⣿⣟⣿⣿⣭⣽⣿⡿⣿⣿⣿⠿⠿⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿⣿⠋⠉⣿⠀⢸⣿⣿⣿⣿⣷⡀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣼⣿⣿⣤⣴⣾⢿⡅⠀⣀⣾⢿⣿⣿⣿⣿⣿⣿⡿⣿⣷⣿⣿⣿⡇⣿⣿⡇⠀⠀⢸⣿⣿⡟⢿⣿⣿⣿⣿⣿⣣⣿⠁⣿⣀⣤⡿⠀⢀⣿⣿⣿⣿⣿⡇⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⡇⠻⣿⠛⠉⠀⠈⣿⠛⢽⣿⢻⣿⣿⢿⣿⣿⣿⡇⣿⠿⣶⣶⣚⣧⣿⣿⡇⠀⠀⣸⣿⣿⣿⣄⣈⢿⣿⢿⣷⣿⣿⠀⠉⠉⠀⠀⠀⠘⡇⣿⣿⣿⣿⡇⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⡇⡀⣷⡆⠀⠀⠀⠸⣧⣻⣿⢸⣿⣿⡿⢿⣾⣻⡇⣿⣿⣿⣿⣿⣿⣿⠿⠷⠾⠛⠛⠿⢿⣿⣿⣿⣄⣿⠿⠋⢸⣿⠀⠀⠀⠀⠀⠀⠀⡇⣿⣿⣿⣿⣿⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣷⡇⣿⡇⠀⠀⠀⠀⣿⣿⣿⡾⢿⣿⣿⣿⣿⡶⠷⠾⠛⠛⠉⠁⢀⣠⠤⠴⠒⡆⢠⠀⢰⡉⠻⣿⣽⡏⠀⠀⢸⡇⠀⠀⠀⠀⠀⠀⠀⡇⣿⡿⣿⣿⣿⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣧⣿⠿⢀⣀⣤⣴⣿⣿⣿⡷⠾⠛⠋⠉⢀⣀⣠⠤⠴⠒⠻⡆⢸⠀⠀⢀⡠⠇⠸⡄⠈⣇⠀⠈⡻⢦⡀⠀⢸⡇⠀⠀⠀⠀⠀⠀⠀⡇⣿⣧⡘⠿⢻⡆\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠻⣆⣿⣿⣿⣿⣿⡿⠛⣉⣀⡀⣠⠴⠒⠋⠉⠁⠀⠀⠀⠀⠀⡇⢸⣠⠴⣫⡄⠀⠀⡇⠀⢹⠀⠀⣿⠦⢿⡀⢸⡇⠀⠀⣀⣤⣤⣿⠀⡇⣿⣿⣿⣆⢸⡇\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣿⢿⡟⣽⣿⠀⣏⠁⠀⡇⡟⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣇⠀⡖⣻⠋⠀⠀⠈⢻⠀⢈⡇⠀⠸⡄⠘⣧⢸⡇⠀⢸⣷⣾⣿⠏⠀⡇⣿⣿⣿⣿⢸⡇\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣾⠏⠛⠋⢡⣿⠀⠸⣿⣟⡃⣇⠀⠀⠀⠀⠀⣀⣠⡤⠶⠒⠋⠀⠛⠁⠀⣀⣤⣶⣿⣿⣿⣿⣷⣤⡈⠁⢻⡞⣿⠀⠈⠻⣴⠏⠀⠀⠿⢹⣿⣎⢻⣿⡇\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣾⡟⠀⠀⢀⡿⣿⠀⠀⠈⠳⡇⠻⠤⠶⠚⠋⠉⠁⠀⠀⠀⠀⠀⣀⣤⣶⣿⣿⣿⣿⣿⠿⠛⠻⣿⣿⣿⣷⣜⣷⣿⠀⠀⢀⣀⣤⣤⣶⣾⣶⣿⣿⠃⢸⡇\n",
    "⠀⠀⠀⠀⠀⠀⣀⣤⡶⠶⠖⠚⢛⠛⠳⢶⣼⡟⠀⠀⢀⣼⣹⣿⢀⠀⠀⠀⠀⡀⠀⠀⠀⠀⠀⢀⣀⣠⡤⢤⣾⣿⣿⣿⡿⠿⠛⠉⠹⡇⠀⠀⣿⣿⣟⢿⣿⣿⠹⣶⣿⡿⠛⠻⣏⠀⠉⠉⡛⣿⡿⣾⡇\n",
    "⠀⠀⠀⢀⣴⠞⠋⢰⡇⢰⣿⢻⢻⢻⢶⣦⠙⣷⡀⠀⣸⢧⠟⢿⣿⣿⣿⣷⣶⣶⣤⣴⣲⡾⠿⠟⠒⠒⠛⡇⠙⣿⠉⠀⢧⠀⠀⠀⠀⣧⠀⠀⢸⣿⣿⡎⣿⠁⢀⣼⣏⢀⣠⣤⣸⣶⠀⠀⣿⣿⣿⠛⠁\n",
    "⠀⠀⠀⣾⠃⠀⣠⡬⣤⣼⣛⠾⣼⣞⡾⡟⠀⠘⣧⣠⣏⡞⠀⠈⠻⣿⡏⢹⡟⠛⠻⣿⠁⠀⠀⠀⠀⠀⠀⣇⠀⣿⠀⠀⢸⡄⠀⠀⠀⢸⠀⠀⠘⣿⣿⣇⣿⣴⡞⢣⣽⣿⣿⣿⣿⣿⠀⠀⣿⣿⡟⠀⠀\n",
    "⠀⠀⠀⣿⡶⣿⣿⣸⣿⣿⣿⠿⠷⠾⢽⣅⡲⠶⢻⣿⣼⢁⣠⣤⣶⣿⣿⠘⡇⠀⠀⢻⡆⠀⠀⠀⠀⠀⢀⣸⡀⢹⡇⠀⠈⡇⠀⠀⠀⠈⡇⠀⠀⢿⣿⣿⢹⣿⣤⣿⣿⣿⣿⡿⢿⣟⡀⠀⣿⣿⡇⠀⠀\n",
    "⠀⠀⠀⠈⠛⠿⢯⣜⣿⠏⠀⠀⠀⢀⡿⣨⣿⣶⣤⣿⣷⣯⣿⣿⣿⣿⣿⠀⡇⠀⠀⠐⡿⣦⣰⣒⣶⣿⣿⣿⣷⣾⣇⠀⠀⢻⠀⠀⠀⠀⢷⠀⠀⢸⣿⣿⣾⣿⣸⣿⡏⢠⠟⣠⣿⣿⣿⣦⡈⢹⡇⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⢸⡟⣾⠄⠀⠀⣸⡇⣿⣿⣿⠟⠋⠛⢿⣿⣿⣿⣿⣿⡄⢻⠀⠀⠀⡇⠈⠙⣿⣿⣿⣿⣿⣿⣿⣿⠀⠀⢸⡆⠀⠀⠀⢸⡄⠀⠀⣿⣿⣇⣿⠛⠛⠻⣿⣺⣿⣿⣿⣿⣿⣿⡿⠃⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⣼⢧⡇⠀⠀⠀⣿⢸⣿⣿⡿⢦⣴⣿⣿⣷⡿⣿⡿⣿⡇⢸⡄⠀⠀⢹⠀⠀⣿⣿⣿⣿⣿⣿⣿⣿⡆⠀⠀⣇⠀⠀⠀⠀⣇⠀⠀⢸⣿⣟⢿⡀⠀⠀⠈⠉⠀⠉⠉⠉⠁⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⣿⣨⡧⠤⠤⢤⣇⡾⣿⣿⣠⣿⣿⣿⣿⣿⣿⣽⣿⣿⣷⠀⣇⠀⠀⢸⠀⠀⢸⢻⣿⣿⣿⣿⡇⣿⣿⠀⠀⢹⡄⠀⠀⢀⣸⠀⠀⠸⣿⣿⣼⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⢀⡿⣧⣤⠶⠦⣼⣿⣿⣿⡏⠈⣿⣿⢿⣿⣿⣿⣏⠉⢹⣿⡀⢻⠀⠀⠘⡇⠀⠸⡄⠙⢿⣿⣿⠇⣿⣿⡄⠀⠈⠓⠒⠋⠉⠀⠀⠀⠀⢿⠹⣯⣇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⣸⣿⢃⡏⠀⠀⢻⣿⣿⣽⣿⣦⠘⣿⣿⣿⣿⣿⢻⣿⣾⣿⡇⠘⡇⠀⠀⣇⠀⠀⣇⠀⠀⠙⢿⡇⣿⢸⣧⠀⠀⠀⠀⡴⠒⢶⠀⠀⠀⠘⣆⠀⢻⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⡿⡅⣸⢁⣄⡄⣾⣿⢿⣿⠿⣿⣿⢻⣿⣿⣟⣿⣸⣻⡿⣿⣧⠀⠙⠒⠛⠛⠀⠀⢿⣿⣄⠀⠀⠀⣿⠈⣿⡄⠀⠀⠀⡇⠀⠘⡇⠀⠀⠀⢿⣦⢸⡆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⢸⣧⡇⣿⣼⣿⠃⣿⣿⣾⣿⣷⣤⡿⠿⢿⣿⣿⣇⣿⡟⠋⠀⣿⡀⠀⣴⠲⡆⠀⠀⠸⣿⣿⣦⠀⠀⢸⡀⢹⣧⠀⠀⠀⣇⠀⠀⢹⠀⠀⠀⠸⣿⡟⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⢽⡿⣷⠏⠛⠿⢠⣿⣿⣿⣿⢿⣯⡇⠀⠀⠈⠁⠀⠀⠀⠀⠀⢸⣇⠀⢻⠀⢳⠀⠀⠀⣿⣿⣿⣷⣾⢸⡇⠈⣿⡀⠀⠀⢸⠀⠀⠈⡇⠀⠀⢀⣿⣿⣷⣀⣀⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠘⣧⡙⣀⣀⣀⣸⣿⣽⣿⣿⠀⠈⠙⣶⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⡀⢸⡀⠸⡄⠀⠀⢻⣿⣿⣿⣿⡼⡇⠀⢘⣧⣤⡴⠾⠷⠶⠖⠛⠛⢛⠋⠉⢿⢹⠉⣭⡿⠿⠷⠶⢦⡄⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠹⣟⣁⣸⣿⣿⣧⡿⠿⣿⣀⡀⠀⡟⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣇⣈⣧⣘⣷⣤⣤⣼⠿⠿⣿⣿⣧⣧⡀⣸⢹⡏⠀⠀⠀⠀⠀⠀⠀⠈⡇⠀⢸⢸⡄⡿⠖⠚⠉⡉⠓⢿⡀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⣠⡴⣾⠋⠉⢙⣻⣷⠛⠛⠳⠶⠶⠽⠿⠃⠀⠀⠀⠀⠀⣀⡤⣼⡿⠋⠉⠁⠀⠀⣠⠀⣿⣿⠀⠀⠀⠀⠈⠉⠻⣿⢸⣷⠀⠀⠀⠀⠀⠀⠀⠀⡇⠀⠸⡏⡇⣿⠀⠀⠀⢻⣷⢸⡇⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⡟⠀⡟⠀⠀⢸⣿⣿⣇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢠⣾⡥⢺⠏⡆⠀⠀⠀⠀⠀⡏⠀⡟⡇⠀⠀⠀⠀⠀⠀⢀⡇⢸⣿⠀⠀⠀⠀⠀⠀⠀⠀⡇⠀⠀⡇⡇⢿⠀⠀⠀⢸⣿⡌⣷⠀⠀⠀⠀\n",
    "⠀⠀⠀⢸⠇⢠⡇⠀⠀⢰⣿⣯⣏⣻⡆⠀⠀⠀⠀⠀⠀⠀⠀⣸⠃⢀⡿⢸⡇⠀⠀⠀⠀⢠⡇⠀⡇⡇⠀⠀⠀⠀⠀⠀⢸⡇⢸⣿⡆⠀⠀⠀⠀⠀⠀⠀⣧⠀⠀⡇⢿⢸⠀⠀⠀⠈⣿⡇⢹⡀⠀⠀⠀\n",
    "⠀⠀⠀⡟⡄⣼⠀⠀⢀⣿⣿⣿⣿⣿⣷⠀⠀⠀⠀⠀⠀⠀⠀⣿⠀⢸⡇⣸⡇⠀⠀⠀⠀⢸⠁⢸⣷⡇⠀⠀⠀⠀⠀⠀⢸⡇⢸⣿⡇⠀⠀⠀⠀⠀⠀⠀⢻⠀⠀⢹⢸⣼⡀⠀⣀⣀⣿⣧⣸⡇⠀⠀⠀\n",
    "⠀⠀⢰⢧⣇⡏⠀⠀⣸⣿⠿⢭⣿⣿⡏⠀⠀⠀⠀⠀⠀⠀⢰⡏⠀⣿⠀⣿⡇⠀⠀⠀⠀⢸⠀⢸⢸⠁⠀⠀⠀⠀⠀⠀⢸⡇⢸⣿⣿⠀⠀⠀⠀⠀⠀⠀⢸⠀⠀⢸⢸⣿⡏⢉⣁⣤⣤⣄⢈⡇⠀⠀⠀\n",
    "⠀⠀⣼⢼⣿⠃⠀⠀⣿⣿⠀⢸⣿⣿⡇⠀⠀⠀⠀⠀⠀⠀⢸⡇⢠⡿⢰⣿⠃⠀⠀⠀⠀⣼⠀⢸⢸⠀⠀⠀⠀⠀⠀⠀⢸⡇⢸⢹⣸⣦⣤⣤⣤⣶⣶⣶⡿⠀⠀⢸⡄⡇⣧⣽⣿⣿⣿⡽⠟⠁⠀⠀⠀\n",
    "⠀⠀⢿⢻⡏⠀⠀⢰⣿⣿⣟⠛⢿⣿⡇⠀⠀⠀⠀⠀⠀⠀⢸⠗⣻⡇⢸⢹⣆⣀⣀⣀⣤⡏⠀⢸⢸⠀⠀⠀⠀⠀⠀⠀⢸⡇⢸⠈⠉⠉⠉⠉⠉⠉⠀⠀⠀⠀⠀⠈⡇⣿⠘⣿⣿⣿⣇⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⢸⠛⠤⢤⣤⣘⢺⣿⣿⣿⣿⡿⠃⠀⠀⠀⠀⠀⠀⠀⠸⢧⣿⠃⠘⠓⠛⠛⠛⠋⠉⠁⠀⢼⢸⠀⢰⡾⠿⠛⠛⠿⢿⡇⣇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⢸⠀⠙⣿⣿⣿⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⢘⣶⡶⠚⠿⢿⣿⣩⢿⢿⡏⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣸⠀⢸⡇⠀⠀⠀⠀⣿⡇⡏⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢷⢸⡀⠀⠈⠁⢸⡇⠀⠀⠀⠀⠀\n",
    "⠀⠀⣼⣹⠃⠀⢰⣷⢻⠁⠈⠛⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⡿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡟⣹⠀⢸⠃⠀⠀⠀⠀⣿⠇⠜⠀⣤⠶⠖⠛⠛⠋⠉⠉⢩⣿⡇⠀⢸⠸⡇⠀⠀⠀⠘⡇⠀⠀⠀⠀⠀\n",
    "⠀⢠⡟⠏⠀⠀⣾⣿⣼⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣾⡇⠀⢀⣴⠶⠞⠛⠛⣻⣷⠀⡏⣿⠀⢸⢀⣴⣷⣦⡀⣿⠇⡇⠀⡟⠀⣀⣀⣀⣀⣀⣀⣸⣿⡇⠀⢸⡆⡇⠀⠀⠀⠀⣷⠀⠀⠀⠀⠀\n",
    "⠀⣸⠇⠀⠀⢸⣿⡇⡟⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⡇⠀⣾⣀⣀⣤⣤⣶⣿⡿⠀⡇⣿⠀⢸⣿⣿⣿⣫⣾⣿⠀⡇⢠⣟⣿⣿⣿⡿⠿⠿⠿⠿⠁⡇⠀⠈⡇⣷⢀⡀⠀⠀⢻⠀⠀⠀⠀⠀\n",
    "⠀⣿⡼⠀⠀⡟⣿⣷⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢰⣿⠀⢀⡟⡿⠿⠟⠛⠛⣃⡇⠀⡇⣿⠀⢸⣿⣿⣿⣿⣿⣿⡄⡇⢸⡇⠀⠀⠀⠀⠀⠀⠀⢰⣶⡇⠀⠀⣇⢹⣾⣿⠀⣰⢾⡆⠀⠀⠀⠀\n",
    "⢠⣿⡇⠀⢸⣷⣿⣹⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⠀⢸⡇⠀⠀⠀⠀⢰⣿⡇⠀⡇⣿⠀⣾⣿⣿⣿⣿⣿⣿⡃⡇⢸⣧⣤⣤⣴⣶⣶⣶⣶⣾⣿⡇⠀⠀⢿⢸⣿⣿⣾⣿⣸⡇⠀⠀⠀⠀\n",
    "⢸⢭⠥⠦⣬⣽⣧⡟⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣸⣿⠀⢸⢵⣶⣾⣿⣿⣿⡿⡇⠀⡇⣿⠀⣿⣿⣿⣿⣿⣿⣿⡇⡇⢸⡏⠿⠟⠛⠛⠛⠛⠛⠛⣧⣷⠀⠀⢸⠀⣿⣿⣿⣿⠛⣇⠀⠀⠀⠀\n",
    "⢸⣸⠁⢠⣿⣿⣹⠃⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⡇⠀⢸⠉⠉⠉⠁⠀⢠⣾⡇⠀⡇⣿⠀⣿⣿⣿⣿⣿⣿⣿⠇⡇⢸⡇⠀⣀⣀⣀⣀⣀⣀⣰⣿⣿⠀⠀⠸⠀⣿⣿⣿⣵⡇⣿⠀⠀⠀⠀\n",
    "⠘⣧⣰⠞⣞⣷⠏⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⡇⠀⢸⣀⣀⣠⣤⣤⣼⣿⡇⠀⡇⣿⠀⢈⣭⣭⠭⠽⠭⣿⡇⡇⢸⣟⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡀⠀⠀⠀⢻⣟⣾⣿⣿⢻⠀⠀⠀⠀\n",
    "⠀⠈⠛⠛⠛⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⡇⠀⣿⠿⠿⠿⠿⠟⢛⣻⡇⠀⡇⢻⠀⢸⠁⠀⠀⠀⠀⣿⡇⡇⠸⡏⠉⠀⠀⠀⠀⠀⠀⠀⣼⣿⡇⠀⠀⠀⢸⣿⣿⣿⣿⢸⡆⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣇⠀⣿⣀⣤⣤⣤⣤⣼⣿⡇⠀⡇⢸⠀⢸⠀⣠⣶⣄⠀⣿⡇⣇⠀⡇⣴⣶⣶⣾⣿⣿⣿⣿⣿⣿⣇⣀⣂⠀⢸⣿⣿⣿⣿⣿⡇⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣿⡿⠴⠿⠿⠿⠿⠿⠿⠿⠿⠷⣦⡄⢸⠀⢸⣾⣿⣿⢟⣴⣿⣷⣼⠶⠗⠛⠛⠛⠛⠛⠛⠛⠋⠉⠉⠉⢉⡟⣧⠈⣿⣿⣿⣿⡿⣧⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣴⣿⠟⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⣴⣿⡇⢸⣴⢾⣿⡿⣻⣿⣿⣿⣿⠏⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⣿⠀⣿⣿⣿⣿⣿⣿⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢠⣾⠟⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣼⣿⣿⡇⢸⣿⢸⣿⣿⣿⣿⣿⣿⠋⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣼⣿⣿⡀⣿⣿⣿⣿⣿⣿⡄⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣰⣿⠃⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣾⣿⣿⣿⡇⢸⣿⢸⣿⣿⣿⣿⣿⠃⠀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣿⣿⣿⡇⢸⣿⣿⣿⣿⢻⡇⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣰⣿⣷⣶⣶⣶⣶⣶⣶⣶⡶⠶⠦⠤⣾⣿⣿⣿⣿⣷⢘⣿⢸⣿⣿⣿⣿⡏⣭⠭⠭⠭⠤⠤⠤⠴⠶⠶⠶⠶⠶⠶⠶⠱⣌⢻⣿⣧⢸⣿⣿⣿⣿⣾⣇⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣴⡾⠟⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⣉⣽⣿⣾⣿⣿⣿⣿⣿⠀⣿⢸⣿⣿⣿⡟⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⡞⣿⢻⠈⣿⣿⣿⣿⣿⣿⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣠⣶⠟⠋⠀⠀⠀⠀⠀⠀⠀⠀⢀⣠⣴⣾⣿⣿⣿⣿⣿⣿⣿⠛⢹⠀⣿⣾⣿⣿⡟⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢰⣿⣿⣿⢻⣿⡀⣿⣿⣿⣿⣿⣿⡄⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⣠⣾⣿⣀⣤⣄⣤⣤⣄⣀⣀⣀⣀⣶⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣅⢸⠀⣿⡿⣿⣿⣤⣤⣤⡤⠤⠤⠶⠶⠶⠖⠒⠒⠒⠚⠛⠛⠛⠺⣿⣿⣿⡇⠹⡇⣿⣿⣿⣿⣿⣿⡇⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⣸⣿⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢿⣿⣿⣿⣿⡟⠉⢹⣿⣿⣿⣿⡿⠿⡾⠀⣿⡇⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⣿⣿⠰⠇⣿⣿⣿⣿⡿⣿⡇⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⢿⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⡟⠛⠉⠁⠀⠀⠀⠙⠛⠉⠁⠀⠀⠁⠀⣛⣁⣿⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⢿⠟⣹⡇⢀⣙⣿⣯⡷⠿⠛⠁⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠈⠛⠛⠛⠛⠛⠛⠛⠛⠛⠛⠛⠛⠛⠛⠛⠛⠛⠛⠛⠛⠛⠛⠛⠛⠉⠉⠉⠉⠉⠉⠹⠷⣦⣤⣤⣤⣤⣤⣤⣤⣤⣤⣶⣶⣶⡶⠶⠶⠶⠶⠾⠿⠛⠛⠋⠉⠉⠁⠀⠀\n",
    "</pre>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d48b5c1",
   "metadata": {},
   "source": [
    "# **Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d849338",
   "metadata": {},
   "source": [
    "Import all libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5a12ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import random\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import ceil\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import (\n",
    "    BertConfig,\n",
    "    BertForMultipleChoice,\n",
    "    BertTokenizer,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    GenerationConfig,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d266c9",
   "metadata": {},
   "source": [
    "Setup random seed function to ensure reproducibility.\n",
    "\n",
    "_Info about the seed value: The field of natural language processing began in the 1940s, after World War II. At this time, people recognized the importance of translation from one language to another and hoped to create a machine that could do this sort of translation automatically. → Seed value is mostly set to 42_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4a7ceac",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1940\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a438be37",
   "metadata": {},
   "source": [
    "In the next step I import and split the dataset. For the split I take off the last 1000 entries from the train-split and use it as validation, the rest of this is of course used for the training. Then I use the validation-part as the test, since the real test-split has no answer keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c7f692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8741 1000 1221\n"
     ]
    }
   ],
   "source": [
    "train = load_dataset(\"tau/commonsense_qa\", split=\"train[:-1000]\")\n",
    "valid = load_dataset(\"tau/commonsense_qa\", split=\"train[-1000:]\")\n",
    "test = load_dataset(\"tau/commonsense_qa\", split=\"validation\")\n",
    "\n",
    "print(len(train), len(valid), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ff2820",
   "metadata": {},
   "source": [
    "Login for the experiment tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "492738f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfabian-dubach\u001b[0m (\u001b[33mfabian-dubach-hochschule-luzern\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f8b6b6",
   "metadata": {},
   "source": [
    "# **Data Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3d5dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\033[4m\" + \"Dataset Features\" + \"\\033[0m\")\n",
    "for feature in train.features:\n",
    "    print(feature)\n",
    "print(\"\\n\" + \"\\033[4m\" + \"Example\" + \"\\033[0m\")\n",
    "for feature in train.features:\n",
    "    print(feature + \":\", train[2][str(feature)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec5d2d0",
   "metadata": {},
   "source": [
    "# **Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d03e9f7",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01c9643",
   "metadata": {},
   "source": [
    "During the preprocessing phase of my NLP project, I carefully considered several common text-cleaning and preparation techniques. Below is a breakdown of each step, whether I used it, and the reasoning behind my decision.\n",
    "\n",
    "1. **Tokenization**  \n",
    "   ✅ *Used*  \n",
    "   I used the `BertTokenizer` from Hugging Face to tokenize all text inputs. This tokenizer breaks text into subword units and adds special tokens, ensuring compatibility with the BERT model architecture.\n",
    "\n",
    "2. **Lowercasing, Stemming, Lemmatizing, Stopword/Punctuation Removal**  \n",
    "   ❌ *Not used*  \n",
    "   These steps are common in traditional NLP pipelines but not necessary when using a pre-trained transformer like BERT. I specifically used the `'bert-base-cased'` model, which is sensitive to letter casing. Applying lowercasing or stripping punctuation could disrupt the model's understanding of context. Similarly, stemming or lemmatizing would interfere with subword tokenization, which already handles morphological variations effectively.\n",
    "\n",
    "3. **Removal of Unknown/Other Words**  \n",
    "   ❌ *Not explicitly used*  \n",
    "   Instead of manually removing unknown words, I relied on the tokenizer to handle them. Words not in the vocabulary are broken into subword tokens or mapped to the `[UNK]` token if completely unrecognized. BERT is designed to handle such cases gracefully.\n",
    "\n",
    "4. **Format Cleaning (e.g., HTML-extracted text)**  \n",
    "   ✅ *Used when necessary*  \n",
    "   While my dataset (CommonsenseQA) was fairly clean, I included basic text normalization steps to remove potential noise (e.g., HTML entities) as a precaution in other stages of the pipeline.\n",
    "\n",
    "5. **Truncation**  \n",
    "   ✅ *Used*  \n",
    "   To fit input sequences into BERT's maximum input size constraint, I applied truncation during tokenization. This ensures that long question-choice pairs are trimmed to 128 tokens, which balances performance and memory usage.\n",
    "\n",
    "6. **Feature Selection**  \n",
    "   ✅ *Used implicitly*  \n",
    "   Rather than traditional feature engineering, I relied on the tokenized outputs (`input_ids`, `attention_mask`, `token_type_ids`) generated by the tokenizer. These features are optimized for transformer models and encapsulate the essential linguistic structure needed for training.\n",
    "\n",
    "By tailoring preprocessing to suit BERT’s architecture, I avoided redundant or harmful steps while retaining the ones critical for accurate and efficient model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bed1da",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76239e3c",
   "metadata": {},
   "source": [
    "The BertTokenizer is a class from the Hugging Face `transformers` library that handles the conversion of raw text into tokens that BERT can understand. Specifically, it tokenizes the input text into subword tokens (e.g., \"playing\" becomes [\"play\", \"##ing\"]). This subword tokenization allows the model to process both common and out-of-vocabulary words more effectively. The `from_pretrained('bert-base-cased')` method loads a pre-trained tokenizer that corresponds to the BERT model. The `'bert-base-cased'` model refers to a base-sized BERT model (with 12 layers and 768 hidden units) that has been trained on cased text, meaning it differentiates between uppercase and lowercase letters which is important for distinguishing meaning in proper nouns or acronyms (e.g., “US” vs “us”).\n",
    "\n",
    "**Why I use BertTokenizer:** I use the BertTokenizer to ensure that the text is processed in the exact way BERT was originally trained. \n",
    "\n",
    "**The tokenizer will:** \n",
    "- Split the text into subword tokens. \n",
    "- Add special tokens such as `[CLS]` and `[SEP]` that BERT requires. \n",
    "- Handle padding and truncation to ensure the input is the correct length for the model.\n",
    "\n",
    "I use the following line of code to initialize the BERT tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18589408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fabia\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer_bert = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0449f7",
   "metadata": {},
   "source": [
    "The `preprocess_commonsenseqa` function is designed to preprocess the CommonsenseQA dataset for input into a BERT-based model. The goal is to tokenize the questions and their corresponding multiple-choice answers into a format compatible with BERT, and then convert the correct answer's label into a numerical value.\n",
    "\n",
    "1. **Extracting Questions and Choices:** The function starts by extracting the questions and their multiple-choice options from the `examples` object.\n",
    "\n",
    "2. **Initialize Data Structures:** It then initializes empty lists to hold the tokenized inputs, attention masks, and token type IDs (used for differentiating between sentence pairs in models like BERT).\n",
    "\n",
    "3. **Convert Answer Labels to Indices:** The answer choices are labeled with letters (A, B, C, D, E), but the model requires numerical labels. This step converts the letters into indices (A → 0, B → 1, etc.).\n",
    "\n",
    "4. **Processing Each Question-Choice Pair:** For each question and its corresponding choices: Each choice is paired with the question. Both the question and the choice are tokenized using the BERT tokenizer (`tokenizer_bert`), which converts the text into `input_ids`, `attention_mask` and `token_type_ids` tensors that BERT can understand.\n",
    "\n",
    "5. **Stacking Tokens for Each Choice:** After tokenizing each choice for a question, the function stacks the resulting tensors (for all choices) into single tensors for input to the model.\n",
    "\n",
    "6. **Returning Tokenized Data:** Finally, the function returns a dictionary containing the tokenized inputs (`input_ids`, `attention_mask` and `token_type_ids`) along with the numerical labels corresponding to the correct answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd469731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_commonsenseqa(examples):\n",
    "\n",
    "    questions = [q for q in examples['question']]\n",
    "    \n",
    "    all_input_ids = []\n",
    "    all_attention_mask = []\n",
    "    all_token_type_ids = []\n",
    "    \n",
    "    answerkeys = examples['answerKey']\n",
    "    labels = []\n",
    "    \n",
    "    for key in answerkeys:\n",
    "        labels.append(ord(key) - ord('A'))\n",
    "    \n",
    "    for i, (question, choices) in enumerate(zip(questions, examples['choices'])):\n",
    "        inputs = []\n",
    "\n",
    "        for choice in choices['text']:\n",
    "            text_a = question\n",
    "            text_b = choice\n",
    "            \n",
    "            encoded = tokenizer_bert(\n",
    "                text_a, text_b,\n",
    "                add_special_tokens=True,\n",
    "                max_length=128,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "            inputs.append({\n",
    "                'input_ids': encoded['input_ids'],\n",
    "                'attention_mask': encoded['attention_mask'],\n",
    "                'token_type_ids': encoded['token_type_ids']\n",
    "            })\n",
    "        \n",
    "        input_ids = torch.cat([x['input_ids'] for x in inputs])\n",
    "        attention_mask = torch.cat([x['attention_mask'] for x in inputs])\n",
    "        token_type_ids = torch.cat([x['token_type_ids'] for x in inputs])\n",
    "        \n",
    "        all_input_ids.append(input_ids)\n",
    "        all_attention_mask.append(attention_mask)\n",
    "        all_token_type_ids.append(token_type_ids)\n",
    "\n",
    "    return {\n",
    "        'input_ids': all_input_ids,\n",
    "        'attention_mask': all_attention_mask,\n",
    "        'token_type_ids': all_token_type_ids,\n",
    "        'labels': labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01af1037",
   "metadata": {},
   "source": [
    "Next, I apply the preprocessing to the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a49eb21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = preprocess_commonsenseqa(train)\n",
    "validation_dataset = preprocess_commonsenseqa(valid)\n",
    "test_dataset = preprocess_commonsenseqa(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b832460a",
   "metadata": {},
   "source": [
    "After preprocessing the CommonsenseQA dataset into tokenized inputs and labels, I convert the data into PyTorch `TensorDataset` objects. I do this because this groups all of the input tensors, so they can be iterated over together. It seamlessly integrates with PyTorch’s `DataLoader` for tasks like batching, shuffling and parallel data loading, ensuring that the data pipeline runs efficiently. Additionally, it provides synchronized indexing, ensuring that each input tensor corresponds correctly to its label, making the dataset ready for model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9181ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = TensorDataset(\n",
    "    torch.stack(train_dataset['input_ids']),\n",
    "    torch.stack(train_dataset['attention_mask']),\n",
    "    torch.stack(train_dataset['token_type_ids']),\n",
    "    torch.tensor(train_dataset['labels'])\n",
    ")\n",
    "\n",
    "val_features = TensorDataset(\n",
    "    torch.stack(validation_dataset['input_ids']),\n",
    "    torch.stack(validation_dataset['attention_mask']),\n",
    "    torch.stack(validation_dataset['token_type_ids']),\n",
    "    torch.tensor(validation_dataset['labels'])\n",
    ")\n",
    "\n",
    "test_features = TensorDataset(\n",
    "    torch.stack(test_dataset['input_ids']),\n",
    "    torch.stack(test_dataset['attention_mask']),\n",
    "    torch.stack(test_dataset['token_type_ids']),\n",
    "    torch.tensor(test_dataset['labels'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20912123",
   "metadata": {},
   "source": [
    "### DeepSeek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2f857d",
   "metadata": {},
   "source": [
    "For tokenizing my LLM I used the AutoTokenizer from Hugging Face to load the tokenizer for the DeepSeek-V2-Lite model. This tokenizer is specifically designed to be compatible with the DeepSeek model architecture. Since DeepSeek is a large language model (LLM), it expects input in a specific tokenized format, including proper handling of special tokens, padding and prompt formatting. By using the `AutoTokenizer` and loading the tokenizer directly from the model’s Hugging Face repository, I ensure that the text is processed exactly as the model was trained on.\n",
    "\n",
    "The `trust_remote_code=True` argument is necessary because DeepSeek uses custom model/tokenizer code not yet fully integrated into the standard Transformers library. This option allows the tokenizer to load correctly and function as intended.\n",
    "\n",
    "In short, I use this tokenizer to guarantee consistency between my input prompts and the expectations of the DeepSeek model, which is crucial for generating accurate and meaningful responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96ffc6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer_deepseek = AutoTokenizer.from_pretrained('deepseek-ai/DeepSeek-V2-Lite', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7399fe1e",
   "metadata": {},
   "source": [
    "# **Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04cdf8d",
   "metadata": {},
   "source": [
    "To see the number of parameters for my models a bit better, I first implemented a function which adds an apostrophe after every three digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e29092cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_number(num):\n",
    "    return f\"{num:,}\".replace(\",\", \"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bfa7cb",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f5dbfa",
   "metadata": {},
   "source": [
    "For the random initialized and the pretrained transformer architechture, I used BERT (Bidirectional Encoder Representations from Transformers) with a classification head specifically designed for multiple-choice inputs called `BertForMultipleChoice`. I used the Hugging Face checkpoint `bert-base-cased`, which is a pretrained transformer model developed by Google with **108'311'041 parameters**. This variant is trained on large English corpora (BooksCorpus and English Wikipedia) and maintains case sensitivity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b8d948",
   "metadata": {},
   "source": [
    "BERT is well-suited for classification tasks like CommonsenseQA due to its deep bidirectional attention, which helps capture the nuanced relationships between the question and each answer option. The pretrained bert-base-cased weights provide strong language understanding out of the box, significantly improving performance over training from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f0c030",
   "metadata": {},
   "source": [
    "The BERT model is composed of an embedding layer, encoder, pooling layer, dropout layer and of course a classifier:\n",
    "\n",
    "1. **Embedding Layer (`BertEmbeddings`):**\n",
    "- Word Embeddings: `Embedding(28996, 768)` → Maps each token to a 768-dimensional vector. The vocabulary size is 28,996 tokens.\n",
    "- Position Embeddings: `Embedding(512, 768)` → Adds position information to each token, allowing the model to distinguish word order up to 512 tokens.\n",
    "- Token Type Embeddings: `Embedding(2, 768)` → Distinguishes between sentence pairs (e.g., question vs. answer).\n",
    "- Layer Normalization + Dropout: Normalizes embeddings and applies dropout (`p=0.1`) for regularization.\n",
    "\n",
    "2. **Encoder (`BertEncoder`):**\n",
    "- 12 Transformer Layers (stacked) → Each layer includes:\n",
    "    - Multi-Head Self-Attention (BertSelfAttention)\n",
    "        - Projects inputs into queries, keys and values using linear layers.\n",
    "        - Attention mechanism allows each token to attend to all others.\n",
    "        - Output passed through a linear layer, then dropout + layer norm.\n",
    "    - Feed-Forward Network\n",
    "        - First Linear: `768 → 3072`\n",
    "        - GELU activation\n",
    "        - Second Linear: `3072 → 768`\n",
    "        - Followed by LayerNorm and Dropout.\n",
    "- Each of these layers processes the tokenized question-choice pair, allowing the model to capture deep contextual relationships.\n",
    "\n",
    "3. **Pooling Layer (`BertPooler`):**\n",
    "- Extracts the `[CLS]` token output from the final encoder layer.\n",
    "- Applies a linear layer + `tanh` activation to produce a fixed-size sentence representation.\n",
    "\n",
    "4. **Dropout Layer:**\n",
    "- Applied before classification to reduce overfitting (`p=0.1`).\n",
    "\n",
    "5. **Classifier (`Linear(768 → 1)`):**\n",
    "- For each choice, outputs a single logit.\n",
    "- During training/evaluation, logits for all choices are grouped and passed through softmax to compute the predicted answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6b1756",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361fb529",
   "metadata": {},
   "source": [
    "In the following code block I load the configuration of the `'bert-base-cased'` model, but without the model weights. I just load the architecture details like number of layers, hidden size and so on. After I create a `BertForMultipleChoice` model using that configuration. This model is randomly initialized, meaining it hasn't learned anything yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84eac71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_bert = BertConfig.from_pretrained('bert-base-cased')\n",
    "random_bert_model = BertForMultipleChoice(config_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2012b6e5",
   "metadata": {},
   "source": [
    "Next, I calculate and print the total number of parameters of the `random_bert_model` and then print its architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7d9b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of parameters: {format_number(sum(p.numel() for p in random_bert_model.parameters()))}\\n\")\n",
    "print(random_bert_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec07ade",
   "metadata": {},
   "source": [
    "In the next cell I create a `BertForMultipleChoice` model with already pretrained weights. These pretrained weights allow my model to already understand some word meanings, grammar and general language patterns. This helps the model perform better and converge faster when fine-tuned on my specific downstream task, such as multiple-choice question answering with CommonsenseQA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f741a679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "pretrained_bert_model = BertForMultipleChoice.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14c4b83",
   "metadata": {},
   "source": [
    "I calculate and print the total number of parameters of the `pretrained_bert_model` and then print its architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f91a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of parameters: {format_number(sum(p.numel() for p in pretrained_bert_model.parameters()))}\\n\")\n",
    "print(pretrained_bert_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac8c42a",
   "metadata": {},
   "source": [
    "### DeepSeek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febbc8ca",
   "metadata": {},
   "source": [
    "The DeepSeek-V2-Lite is a cutting-edge decoder-only transformer model optimized for causal language modeling, so for generating or completing text. With **15'706'484'224 parameters**, it is orders of magnitude larger than BERT and is specifically designed for autoregressive generation tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82a1b9b",
   "metadata": {},
   "source": [
    "For the DeepSeek-V2-Lite model, the architecture is composed of an embedding layer, a stack of decoder layers (transformer blocks), normalization layers and a final language modeling head for token prediction:\n",
    "\n",
    "1. **Token Embedding Layer:**\n",
    "- `Embedding(102400, 2048)` → Maps tokens from a very large vocabulary (102,400 tokens) to 2048-dimensional embeddings.\n",
    "\n",
    "2. **Stack of 27 Decoder Layers (`DeepseekV2DecoderLayer`):**\n",
    "- Each decoder layer includes:\n",
    "    - Self-Attention Mechanism (`DeepseekV2Attention`)\n",
    "        - Query projection: `Linear(2048 → 3072)`\n",
    "        - KV projections:\n",
    "            - `kv_a_proj_with_mqa`: `Linear(2048 → 576)` — Multi-query attention (MQA), a memory-efficient variant.\n",
    "            - `kv_b_proj`: `Linear(512 → 4096)` — Advanced attention processing.\n",
    "        - RMSNorm on KV inputs: Normalizes activations to improve stability.\n",
    "        - Rotary Embeddings (`DeepseekV2YarnRotaryEmbedding`) → Positional encoding mechanism that enables extrapolation to longer sequences.\n",
    "        - Output projection: `Linear(2048 → 2048)`\n",
    "    - Feed-Forward Layer\n",
    "        - Layer 0 uses:\n",
    "            - Standard MLP (`DeepseekV2MLP`)\n",
    "                - `gate_proj`, `up_proj`: `2048 → 10944`\n",
    "                - `down_proj`: `10944 → 2048`\n",
    "                - Activation: SiLU (a smooth, non-monotonic function similar to Swish)\n",
    "        - Layers 1–26 use:\n",
    "            - Mixture-of-Experts (MoE) Layer (`DeepseekV2MoE`)\n",
    "                - 64 expert MLPs (`DeepseekV2MLP`) with `2048 → 1408 → 2048`\n",
    "                - Gating mechanism: `MoEGate()` dynamically selects top-k experts per token.\n",
    "                - Shared expert also included: `2048 → 2816 → 2048`\n",
    "                - This makes computation sparse but increases capacity massively.\n",
    "    - Normalization\n",
    "        - RMSNorm instead of LayerNorm, used both before attention and before MLP. RMSNorm scales activations based on root mean square, which is more numerically stable in large-scale training.\n",
    "\n",
    "3. **Final LayerNorm + Output Head:**\n",
    "- Final RMSNorm applied to the output of the last decoder layer.\n",
    "- LM Head: `Linear(2048 → 102400)`\n",
    "    - Maps model outputs back into the token vocabulary for prediction.\n",
    "    - Weight sharing is likely applied with the token embedding layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d01066",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82674b6c",
   "metadata": {},
   "source": [
    "With the following code cell I load the `DeepSeek-V2-Lite` large language model (https://huggingface.co/deepseek-ai/DeepSeek-V2-Lite). This model is designed for causal language modeling tasks such as text generation. The loading configuration includes:\n",
    "- `AutoModelForCausalLM.from_pretrained(...)`: Loads the pretrained DeepSeek model.\n",
    "- `trust_remote_code=True`: Allows loading custom model code from the model's repository.\n",
    "- `torch_dtype=torch.bfloat16`: Uses the more efficient `bfloat16` precision for faster inference.\n",
    "- `device_map=\"cpu\"`: Loads the model onto the CPU.\n",
    "- `GenerationConfig.from_pretrained(...)`: Loads the model's default generation configuration (e.g., max tokens, sampling strategy).\n",
    "- `pad_token_id = eos_token_id`: Sets the padding token to be the same as the end-of-sequence token for compatibility during generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "177d6325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56fde439ef4458ab1915b06881b1d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deepseek_model = AutoModelForCausalLM.from_pretrained('deepseek-ai/DeepSeek-V2-Lite', trust_remote_code=True, torch_dtype=torch.bfloat16, device_map=\"cpu\", low_cpu_mem_usage=True)\n",
    "deepseek_model.generation_config = GenerationConfig.from_pretrained('deepseek-ai/DeepSeek-V2-Lite')\n",
    "deepseek_model.generation_config.pad_token_id = deepseek_model.generation_config.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3b70bd",
   "metadata": {},
   "source": [
    "I calculate and print the total number of parameters of the `deepseek_model` and then print its architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96093558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 15'706'484'224\n",
      "\n",
      "DeepseekV2ForCausalLM(\n",
      "  (model): DeepseekV2Model(\n",
      "    (embed_tokens): Embedding(102400, 2048)\n",
      "    (layers): ModuleList(\n",
      "      (0): DeepseekV2DecoderLayer(\n",
      "        (self_attn): DeepseekV2Attention(\n",
      "          (q_proj): Linear(in_features=2048, out_features=3072, bias=False)\n",
      "          (kv_a_proj_with_mqa): Linear(in_features=2048, out_features=576, bias=False)\n",
      "          (kv_a_layernorm): DeepseekV2RMSNorm()\n",
      "          (kv_b_proj): Linear(in_features=512, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): DeepseekV2YarnRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): DeepseekV2MLP(\n",
      "          (gate_proj): Linear(in_features=2048, out_features=10944, bias=False)\n",
      "          (up_proj): Linear(in_features=2048, out_features=10944, bias=False)\n",
      "          (down_proj): Linear(in_features=10944, out_features=2048, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): DeepseekV2RMSNorm()\n",
      "        (post_attention_layernorm): DeepseekV2RMSNorm()\n",
      "      )\n",
      "      (1-26): 26 x DeepseekV2DecoderLayer(\n",
      "        (self_attn): DeepseekV2Attention(\n",
      "          (q_proj): Linear(in_features=2048, out_features=3072, bias=False)\n",
      "          (kv_a_proj_with_mqa): Linear(in_features=2048, out_features=576, bias=False)\n",
      "          (kv_a_layernorm): DeepseekV2RMSNorm()\n",
      "          (kv_b_proj): Linear(in_features=512, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): DeepseekV2YarnRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): DeepseekV2MoE(\n",
      "          (experts): ModuleList(\n",
      "            (0-63): 64 x DeepseekV2MLP(\n",
      "              (gate_proj): Linear(in_features=2048, out_features=1408, bias=False)\n",
      "              (up_proj): Linear(in_features=2048, out_features=1408, bias=False)\n",
      "              (down_proj): Linear(in_features=1408, out_features=2048, bias=False)\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "          )\n",
      "          (gate): MoEGate()\n",
      "          (shared_experts): DeepseekV2MLP(\n",
      "            (gate_proj): Linear(in_features=2048, out_features=2816, bias=False)\n",
      "            (up_proj): Linear(in_features=2048, out_features=2816, bias=False)\n",
      "            (down_proj): Linear(in_features=2816, out_features=2048, bias=False)\n",
      "            (act_fn): SiLU()\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): DeepseekV2RMSNorm()\n",
      "        (post_attention_layernorm): DeepseekV2RMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): DeepseekV2RMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=102400, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of parameters: {format_number(sum(p.numel() for p in deepseek_model.parameters()))}\\n\")\n",
    "print(deepseek_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaf3928",
   "metadata": {},
   "source": [
    "The function `process_commonsense_qa_for_deepseek(...)` in the next code cell is designed to process and evaluate the performance from the LLM on the CommonsenseQA dataset. Rather than using the dataset in a traditional classification setup (with logits over classes), this function reformulates each question into a text prompt that simulates a real-world use case: prompting a language model to directly generate the correct answer letter (e.g., \"A\", \"B\", \"C\"). This approach enables zero-shot evaluation of decoder-based language models (like DeepSeek, GPT-style models, etc.) by leveraging natural language prompts.\n",
    "\n",
    "Key features of the function include:\n",
    "- Prompt Construction: Each question is converted into a formatted prompt including the question, concept (if available) and multiple choice options labeled A–E.\n",
    "- Text Generation: The model is prompted to generate a single token representing the answer choice, using `max_new_tokens=1` to constrain output.\n",
    "- Answer Decoding: The raw model output is post-processed to extract the predicted answer letter.\n",
    "- Result Logging: The function collects questions, prompts, generated answers, and ground truth labels for easy evaluation and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "05105fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_commonsense_qa_for_deepseek(dataset, model, tokenizer, num_examples, max_new_tokens=1, batch_size=8):\n",
    "    results = {\n",
    "        'questions': [],\n",
    "        'prompts': [],\n",
    "        'responses': [],\n",
    "        'correct_answers': []\n",
    "    }\n",
    "\n",
    "    if num_examples is not None:\n",
    "        limited_dataset = dataset.select(range(min(num_examples, len(dataset))))\n",
    "    else:\n",
    "        limited_dataset = dataset\n",
    "\n",
    "    has_question_concept = 'question_concept' in limited_dataset.column_names\n",
    "    total = len(limited_dataset)\n",
    "\n",
    "    pbar = tqdm(total=total, desc=\"Generating answers\")\n",
    "\n",
    "    for batch_start in range(0, total, batch_size):\n",
    "        batch_end = min(batch_start + batch_size, total)\n",
    "\n",
    "        batch_questions = []\n",
    "        batch_prompts = []\n",
    "        batch_answer_keys = []\n",
    "\n",
    "        for i in range(batch_start, batch_end):\n",
    "            question = limited_dataset['question'][i]\n",
    "            question_concept = limited_dataset['question_concept'][i] if has_question_concept else ''\n",
    "            choices = limited_dataset['choices'][i]\n",
    "            choice_labels = choices['label']\n",
    "            choice_texts = choices['text']\n",
    "            choices_text = \", \".join([f\"{label}. {text}\" for label, text in zip(choice_labels, choice_texts)])\n",
    "            answer_key = limited_dataset['answerKey'][i] if 'answerKey' in limited_dataset.column_names else \"N/A\"\n",
    "\n",
    "            prompt = (\n",
    "                f\"Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\n\"\n",
    "                f\"Question: {question}\\n\"\n",
    "                f\"Concept: {question_concept}\\n\"\n",
    "                f\"Choices: {choices_text}\\n\"\n",
    "                f\"Answer:\"\n",
    "            )\n",
    "\n",
    "            batch_questions.append(question)\n",
    "            batch_prompts.append(prompt)\n",
    "            batch_answer_keys.append(answer_key)\n",
    "\n",
    "        inputs = tokenizer(batch_prompts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                outputs = model.generate(\n",
    "                    **inputs, \n",
    "                    max_new_tokens=max_new_tokens,\n",
    "                    eos_token_id=tokenizer.eos_token_id,\n",
    "                )\n",
    "\n",
    "            decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "            responses = [\n",
    "                out[len(prompt):].strip() if out.startswith(prompt) else out.strip()\n",
    "                for prompt, out in zip(batch_prompts, decoded)\n",
    "            ]\n",
    "        except Exception as e:\n",
    "            responses = [f\"Error: {str(e)}\"] * len(batch_prompts)\n",
    "\n",
    "        results['questions'].extend(batch_questions)\n",
    "        results['prompts'].extend(batch_prompts)\n",
    "        results['responses'].extend(responses)\n",
    "        results['correct_answers'].extend(batch_answer_keys)\n",
    "\n",
    "        del inputs, outputs\n",
    "        gc.collect()\n",
    "\n",
    "        pbar.update(len(batch_prompts))\n",
    "\n",
    "    pbar.close()\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41073d29",
   "metadata": {},
   "source": [
    "# **Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596c651e",
   "metadata": {},
   "source": [
    "First, I define my GPU as the device to increase the speed of my training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b4add2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9183cd80",
   "metadata": {},
   "source": [
    "Next, I define all the needed hyperparameters for my <u>manual</u> training. Heres a description for all of the hyperparameters used:\n",
    "\n",
    "**epochs:** Number of times the model goes through the entire training dataset.<br>\n",
    "**learning_rate:** Controls how much the model updates its weights with each step.<br>\n",
    "**batch_size:** Number of samples processed together before updating model weights.<br>\n",
    "**warmup_steps:** Gradually increases learning rate over the first training steps to avoid instability.<br>\n",
    "**gradient_clip_val:** Limits the maximum gradient norm to prevent exploding gradients.<br>\n",
    "**save_interval:** Saves the model after every epoch.<br>\n",
    "**gradient_accumulation_steps:** Accumulates gradients over multiple steps before updating weights, effectively increasing the batch size.<br>\n",
    "**patience:** Stops training early if validation performance doesn’t improve for the set amount of epochs.<br>\n",
    "**weight_decay:** Applies L2 regularization to discourage overly large weights and reduce overfitting.<br>\n",
    "\n",
    "For the warmup steps I found, that the value is often set to 5-10% of the total training steps (https://medium.com/better-ml/the-art-of-setting-learning-rate-eff11ac0a737). To get for example the 10%, I would use this code:  `warmup_steps = 0.1 * len(train_dataloader)`. Due to the fact, that I wanted to have all my hyperparameters in one block (including the batch size, which is needed for the dataloader after) I had to find a different way to calculate those 10%. A different way to calculate this would be: `warmup_steps = int(0.1 * len(train_features) / batch_size)`. With this approach I could create the dataloaders later, while having all necessary hyperparameters in one block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34b06ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "learning_rate = 1e-5\n",
    "batch_size = 16\n",
    "warmup_steps = int(0.1 * len(train_features) / batch_size) # 0.1 = 10% of training data\n",
    "gradient_clip_val = 5.0\n",
    "save_interval = 1\n",
    "gradient_accumulation_steps = 4 # Effectively creates a batch size of 128 (batch_size * gradient_accumulation_steps)\n",
    "patience = 3\n",
    "weight_decay = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351cbc22",
   "metadata": {},
   "source": [
    "In the next code cell, I define the data loaders for training, validation and testing. A DataLoader is responsible for efficiently loading batches of data during training or evaluation. Here's a breakdown of the configuration used for each dataset:\n",
    "- `train_features` / `val_features` / `test_features`: These are the preprocessed datasets for training, validation, and testing, respectively.\n",
    "- `batch_size`: Controls how many samples are passed through the model at once; defined earlier to ensure consistency.\n",
    "- `shuffle`:\n",
    "    - Set to `True` for the training set to ensure that the model sees a different order of examples each epoch (helps generalization).\n",
    "    - Set to `False` for validation and test sets to maintain deterministic behavior (important for consistent evaluation).\n",
    "- `num_workers=4`: Enables parallel data loading using 4 subprocesses. This speeds up data fetching, especially when I/O or preprocessing is involved.\n",
    "- `pin_memory=True`: Allows faster transfer of data from CPU to GPU by allocating the data in page-locked (pinned) memory — useful when training on a CUDA-enabled device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ff26a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_features, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_dataloader = DataLoader(val_features, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_features, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1dee63",
   "metadata": {},
   "source": [
    "As stated in the markdown for the hyperparameters, I used a bit of a different calculation to declare the warmup steps. In the following code block, I look at the output value of both calculations to make sure that they're the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef952a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "print(warmup_steps)\n",
    "print(int(0.1 * len(train_dataloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9053b80d",
   "metadata": {},
   "source": [
    "The following `train_transformer` function runs the full training process for a transformer model using PyTorch. It includes helpful features like saving progress (checkpoints), stopping early if the model stops improving, adjusting the learning rate during training, combining gradients across batches to save memory, and optionally tracking results using Weights & Biases (WandB).\n",
    "\n",
    "**Inputs:**\n",
    "- `model`: A transformer model compatible with HuggingFace Transformers API.\n",
    "- `train_dataloader`, `val_dataloader`: DataLoaders for training and validation sets.\n",
    "- `device`: The device to train on (e.g., `\"cuda\"` or `\"cpu\"`).\n",
    "- `epochs`: Number of training epochs.\n",
    "- `learning_rate`: Learning rate for the optimizer.\n",
    "- `warmup_steps`: Warm-up steps for the scheduler. If `None`, defaults to one epoch's worth of steps.\n",
    "- `log_wandb`: Whether to log metrics and configs to WandB.\n",
    "- `gradient_clip_val`: Value for gradient clipping.\n",
    "- `save_interval`: How often (in epochs) to save model checkpoints.\n",
    "- `gradient_accumulation_steps`: Number of steps to accumulate gradients before updating weights.\n",
    "- `patience`: Patience for early stopping.\n",
    "- `weight_decay`: Adds L2 regularization to the optimizer, which helps with overfitting.\n",
    "- `save_path`: Directory path to save checkpoints and the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9fec2c",
   "metadata": {},
   "source": [
    "### CLEAN UP\n",
    "\n",
    "Step-by-Step Process\n",
    "1. Setup Checkpoint Saving\n",
    "If save_path is provided:\n",
    "\n",
    "Create the checkpoint directory if it doesn't exist.\n",
    "\n",
    "Define the path for saving the best model.\n",
    "\n",
    "2. Model Preparation\n",
    "Move the model to the specified device (cuda/cpu).\n",
    "\n",
    "Enable gradient checkpointing to reduce memory usage (useful for large transformer models).\n",
    "\n",
    "3. WandB Initialization (if enabled)\n",
    "If log_wandb is True:\n",
    "\n",
    "Import and initialize a WandB run with key hyperparameters and metadata.\n",
    "\n",
    "4. Optimizer, Scheduler, and Loss Function Setup\n",
    "Use AdamW as the optimizer.\n",
    "\n",
    "Set up a linear learning rate scheduler with warmup.\n",
    "\n",
    "Default warmup steps = number of steps in one epoch (if not provided).\n",
    "\n",
    "Use CrossEntropyLoss as the loss criterion.\n",
    "\n",
    "5. Training Loop (Epochs)\n",
    "For each epoch:\n",
    "a. Training Phase\n",
    "Set model to train() mode.\n",
    "\n",
    "Loop over train_dataloader:\n",
    "\n",
    "Move data to device.\n",
    "\n",
    "Forward pass.\n",
    "\n",
    "Compute loss.\n",
    "\n",
    "Calculate predictions and accuracy.\n",
    "\n",
    "Scale loss for gradient accumulation.\n",
    "\n",
    "Backpropagate the scaled loss.\n",
    "\n",
    "Every gradient_accumulation_steps:\n",
    "\n",
    "Clip gradients.\n",
    "\n",
    "Perform optimizer step and scheduler step.\n",
    "\n",
    "Zero gradients.\n",
    "\n",
    "Log current loss and update progress bar.\n",
    "\n",
    "Compute and store:\n",
    "\n",
    "Average training loss.\n",
    "\n",
    "Training accuracy.\n",
    "\n",
    "b. Validation Phase\n",
    "Set model to eval() mode.\n",
    "\n",
    "Disable gradients using torch.no_grad().\n",
    "\n",
    "Loop over val_dataloader:\n",
    "\n",
    "Move data to device.\n",
    "\n",
    "Forward pass.\n",
    "\n",
    "Compute loss and predictions.\n",
    "\n",
    "Accumulate correct predictions and total.\n",
    "\n",
    "Compute:\n",
    "\n",
    "Average validation loss.\n",
    "\n",
    "Validation accuracy.\n",
    "\n",
    "c. Logging\n",
    "Log metrics (loss, accuracy, learning rate) to WandB if enabled.\n",
    "\n",
    "d. Checkpointing\n",
    "If save_interval matches the current epoch:\n",
    "\n",
    "Save a checkpoint with model, optimizer, scheduler, and metadata.\n",
    "\n",
    "e. Best Model Saving\n",
    "If current validation accuracy is the best so far:\n",
    "\n",
    "Save the model and checkpoint.\n",
    "\n",
    "Reset early stopping counter.\n",
    "\n",
    "Else:\n",
    "\n",
    "Increment early stopping counter.\n",
    "\n",
    "Stop training if counter exceeds patience.\n",
    "\n",
    "6. Load Best Model (After Training)\n",
    "If a best model was saved, reload its state dict into the model.\n",
    "\n",
    "7. Finish WandB Run\n",
    "If WandB logging was enabled, finalize the run.\n",
    "\n",
    "**Return Values:**\n",
    "- `model`: The trained (and potentially early-stopped) transformer model.\n",
    "- `train_losses`: List of average training losses per epoch.\n",
    "- `val_accuracies`: List of validation accuracies per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c0e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformer(model, train_dataloader, val_dataloader, device, \n",
    "                      epochs=10, learning_rate=1e-4, warmup_steps=None,\n",
    "                      log_wandb=True, gradient_clip_val=5.0, save_interval=1,\n",
    "                      gradient_accumulation_steps=4, patience=3,\n",
    "                      weight_decay=0.001, save_path=None, existing_wandb_run=None):\n",
    "        \n",
    "    # Handle save path for checkpoints\n",
    "    if save_path:\n",
    "        # Make sure parent directory exists\n",
    "        checkpoint_dir = save_path\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "        # Define best model path inside the checkpoint directory\n",
    "        best_model_path = os.path.join(checkpoint_dir, \"best_transformer_model.pt\")\n",
    "    else:\n",
    "        print(\"Warning: No save_path provided. Model and checkpoints will not be saved.\")\n",
    "        checkpoint_dir = None\n",
    "        best_model_path = None\n",
    "    \n",
    "    # Move model to device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Enable gradient checkpointing for memory efficiency\n",
    "    model.gradient_checkpointing_enable()\n",
    "    \n",
    "    # Detect if the model is pretrained or randomly initialized\n",
    "    # Check if the model has a 'name_or_path' attribute that contains 'bert'\n",
    "    is_pretrained = hasattr(model.config, 'name_or_path') and 'bert' in model.config.name_or_path.lower()\n",
    "    \n",
    "    # Use this to determine the model type name\n",
    "    if is_pretrained:\n",
    "        model_type_name = \"pretrained_transformer\"\n",
    "    else:\n",
    "        model_type_name = \"random_transformer\"\n",
    "    \n",
    "    # Log to wandb\n",
    "    if log_wandb:\n",
    "        if existing_wandb_run is None:\n",
    "            import wandb\n",
    "            # Check if wandb is initialized, if not initialize it\n",
    "            if not wandb.run:\n",
    "                run_name = f\"{model_type_name}-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "                wandb.init(\n",
    "                    project=\"CommonsenseQA\",\n",
    "                    name=run_name,\n",
    "                    config={\n",
    "                        \"learning_rate\": learning_rate,\n",
    "                        \"epochs\": epochs,\n",
    "                        \"batch_size\": train_dataloader.batch_size,\n",
    "                        \"gradient_accumulation_steps\": gradient_accumulation_steps,\n",
    "                        \"effective_batch_size\": train_dataloader.batch_size * gradient_accumulation_steps,\n",
    "                        \"weight_decay\": weight_decay,\n",
    "                        \"warmup_steps\": warmup_steps,\n",
    "                        \"gradient_clip_val\": gradient_clip_val,\n",
    "                        \"model_type\": model_type_name,\n",
    "                    })\n",
    "                print(f\"Initialized new wandb run with name: {run_name}\")\n",
    "        else:\n",
    "            # Use the provided wandb run\n",
    "            wandb = existing_wandb_run\n",
    "            print(f\"Using existing wandb run: {wandb.run.name}\")\n",
    "    \n",
    "    # Initialize CrossEntropy Loss\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    # Calculate total training steps\n",
    "    total_steps = len(train_dataloader) * epochs // gradient_accumulation_steps\n",
    "    \n",
    "    # Set default warmup steps if not provided\n",
    "    if warmup_steps is None:\n",
    "        warmup_steps = len(train_dataloader)  # One epoch of warmup\n",
    "    \n",
    "    # Initialize scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=warmup_steps, \n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Lists to store metrics\n",
    "    train_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    # Variables to track best model\n",
    "    best_accuracy = 0.0\n",
    "    early_stopping_counter = 0\n",
    "    \n",
    "    # Print model type for debugging\n",
    "    print(f\"Training {model_type_name} model...\")\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        epoch_correct = 0\n",
    "        epoch_total = 0\n",
    "        progress_bar = tqdm(train_dataloader, desc=\"Training\")\n",
    "        optimizer.zero_grad()  # Zero gradients once at the beginning of epoch\n",
    "        \n",
    "        for i, batch in enumerate(progress_bar):\n",
    "            # Move batch to device\n",
    "            input_ids, attention_mask, token_type_ids, labels = [b.to(device) for b in batch]\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids\n",
    "            )\n",
    "            \n",
    "            # Use CrossEntropy Loss\n",
    "            logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            # Calculate training accuracy\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            epoch_correct += (preds == labels).sum().item()\n",
    "            epoch_total += labels.size(0)\n",
    "            \n",
    "            # Scale loss for gradient accumulation\n",
    "            loss_to_backward = loss / gradient_accumulation_steps\n",
    "            \n",
    "            # Backward pass\n",
    "            loss_to_backward.backward()\n",
    "            \n",
    "            # Update weights every gradient_accumulation_steps batches\n",
    "            if (i + 1) % gradient_accumulation_steps == 0 or (i + 1) == len(train_dataloader):\n",
    "                # Clip gradients using the provided gradient_clip_val parameter\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clip_val)\n",
    "                \n",
    "                # Update weights\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Log learning rate\n",
    "                if log_wandb and wandb.run:\n",
    "                    wandb.log({\"learning_rate\": scheduler.get_last_lr()[0]})\n",
    "            \n",
    "            # Update progress bar (use the unscaled loss for display)\n",
    "            progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "            \n",
    "            # Accumulate loss (use the unscaled loss for logging)\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        # Calculate average loss and accuracy for the epoch\n",
    "        avg_train_loss = epoch_loss / len(train_dataloader)\n",
    "        train_accuracy = epoch_correct / epoch_total\n",
    "        train_losses.append(avg_train_loss)\n",
    "        print(f\"Training loss: {avg_train_loss:.4f}, accuracy: {train_accuracy:.4f}\")\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        # No gradient computation for validation\n",
    "        with torch.no_grad():\n",
    "            progress_bar = tqdm(val_dataloader, desc=\"Validation\")\n",
    "            \n",
    "            for batch in progress_bar:\n",
    "                # Move batch to device\n",
    "                input_ids, attention_mask, token_type_ids, labels = [b.to(device) for b in batch]\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    token_type_ids=token_type_ids\n",
    "                )\n",
    "                logits = outputs.logits if hasattr(outputs, 'logits') else outputs\n",
    "                \n",
    "                loss = criterion(logits, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # Get predictions\n",
    "                _, preds = torch.max(logits, dim=1)\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                # Update progress bar\n",
    "                progress_bar.set_postfix({\"acc\": correct/total})\n",
    "            \n",
    "        # Calculate validation metrics\n",
    "        val_accuracy = correct / total\n",
    "        avg_val_loss = val_loss / len(val_dataloader)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        print(f\"Validation loss: {avg_val_loss:.4f}, accuracy: {val_accuracy:.4f}\")\n",
    "        \n",
    "        # Log metrics to wandb\n",
    "        if log_wandb and wandb.run:\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch,\n",
    "                \"train_loss\": avg_train_loss,\n",
    "                \"train_accuracy\": train_accuracy,\n",
    "                \"val_loss\": avg_val_loss,\n",
    "                \"val_accuracy\": val_accuracy,\n",
    "                \"learning_rate\": scheduler.get_last_lr()[0],\n",
    "                \"model_type\": model_type_name  # Log model type for easier filtering in wandb\n",
    "            })\n",
    "        \n",
    "        # Save checkpoint at specified interval\n",
    "        if checkpoint_dir and (epoch + 1) % save_interval == 0:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f\"{model_type_name}_checkpoint_epoch_{epoch+1}.pt\")\n",
    "            model_to_save = model.module if hasattr(model, 'module') else model\n",
    "            \n",
    "            # Create checkpoint with additional information\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model_to_save.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'best_accuracy': best_accuracy,\n",
    "                'train_losses': train_losses,\n",
    "                'val_accuracies': val_accuracies,\n",
    "                'model_type': model_type_name\n",
    "            }\n",
    "            torch.save(checkpoint, checkpoint_path)\n",
    "            print(f\"Checkpoint saved to {checkpoint_path}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if best_model_path and val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            # Save model\n",
    "            model_to_save = model.module if hasattr(model, 'module') else model\n",
    "            best_model_path_with_type = os.path.join(os.path.dirname(best_model_path), \n",
    "                                                   f\"best_{model_type_name}_model.pt\")\n",
    "            torch.save(model_to_save.state_dict(), best_model_path_with_type)\n",
    "            print(f\"Best model saved to {best_model_path_with_type}\")\n",
    "            \n",
    "            # Also save as checkpoint with additional metadata\n",
    "            best_checkpoint_path = os.path.join(checkpoint_dir, \n",
    "                                              f\"best_{model_type_name}_checkpoint_epoch_{epoch+1}.pt\")\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model_to_save.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'best_accuracy': best_accuracy,\n",
    "                'train_losses': train_losses,\n",
    "                'val_accuracies': val_accuracies,\n",
    "                'model_type': model_type_name\n",
    "            }\n",
    "            torch.save(checkpoint, best_checkpoint_path)\n",
    "            \n",
    "            # Log best model to wandb\n",
    "            if log_wandb and wandb.run:\n",
    "                wandb.run.summary[\"best_accuracy\"] = best_accuracy\n",
    "                wandb.run.summary[\"best_epoch\"] = epoch + 1\n",
    "                wandb.run.summary[\"model_type\"] = model_type_name\n",
    "            \n",
    "            # Reset early stopping counter\n",
    "            early_stopping_counter = 0\n",
    "        else:\n",
    "            # Increment early stopping counter\n",
    "            early_stopping_counter += 1\n",
    "            print(f\"No improvement for {early_stopping_counter} epochs\")\n",
    "            \n",
    "            # Check if we should stop early\n",
    "            if early_stopping_counter >= patience:\n",
    "                print(f\"Early stopping after {epoch+1} epochs\")\n",
    "                if log_wandb and wandb.run:\n",
    "                    wandb.run.summary[\"stopped_epoch\"] = epoch + 1\n",
    "                break\n",
    "    \n",
    "    # Load best model if it was saved\n",
    "    if best_model_path and os.path.exists(best_model_path_with_type):\n",
    "        model.load_state_dict(torch.load(best_model_path_with_type))\n",
    "        print(f\"Loaded best model from {best_model_path_with_type}\")\n",
    "    \n",
    "    # Don't finish wandb run as it was created outside this function\n",
    "    # if log_wandb:\n",
    "    #     wandb.finish()\n",
    "    \n",
    "    return model, train_losses, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137a50a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_random_bert_model, trained_random_bert_train_losses, trained_random_bert_val_accuracies = train_transformer(\n",
    "    random_bert_model, \n",
    "    train_dataloader, \n",
    "    val_dataloader, \n",
    "    device,\n",
    "    epochs=epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    warmup_steps=warmup_steps,\n",
    "    gradient_clip_val=gradient_clip_val,\n",
    "    save_interval=save_interval,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    patience=patience,\n",
    "    weight_decay=weight_decay,\n",
    "    save_path=f\"./checkpoints/random_transformer-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103eedf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_pretrained_bert_model, trained_pretrained_bert_train_losses, trained_pretrained_bert_val_accuracies = train_transformer(\n",
    "    pretrained_bert_model, \n",
    "    train_dataloader, \n",
    "    val_dataloader, \n",
    "    device,\n",
    "    epochs=epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    warmup_steps=warmup_steps,\n",
    "    gradient_clip_val=gradient_clip_val,\n",
    "    save_interval=save_interval,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    patience=patience,\n",
    "    weight_decay=weight_decay,\n",
    "    save_path=f\"./checkpoints/pretrained_transformer-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c158629d",
   "metadata": {},
   "source": [
    "### Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716b5d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function_pretrained(config=None):\n",
    "    \"\"\"Objective function for hyperparameter optimization of pretrained model\"\"\"\n",
    "    \n",
    "    with wandb.init(\n",
    "    project=\"CommonsenseQA\",\n",
    "    name=f\"pretrained_transformer-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "    ) as run:\n",
    "        config = wandb.config\n",
    "\n",
    "        # Always create a fresh model instance for each run\n",
    "        pretrained_bert_model = BertForMultipleChoice.from_pretrained('bert-base-cased')\n",
    "        \n",
    "        # Create dataloaders with the batch size from config\n",
    "        train_batch_size = config.batch_size\n",
    "        \n",
    "        train_dataloader = DataLoader(train_features,\n",
    "            batch_size=train_batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        val_dataloader = DataLoader(\n",
    "            val_features,\n",
    "            batch_size=train_batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        # Generate a unique save path for this run\n",
    "        unique_save_path = f\"./checkpoints/sweep-{wandb.run.id}-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "        \n",
    "        # Use the training function with model_pretrained and pass the existing wandb run\n",
    "        trained_model, train_losses, val_accuracies = train_transformer(\n",
    "            model=pretrained_bert_model,\n",
    "            train_dataloader=train_dataloader,\n",
    "            val_dataloader=val_dataloader,\n",
    "            device=device,\n",
    "            epochs=config.epochs,\n",
    "            learning_rate=config.learning_rate,\n",
    "            warmup_steps=config.warmup_ratio * len(train_dataloader),\n",
    "            gradient_clip_val=config.gradient_clip_val,\n",
    "            save_interval=1,\n",
    "            gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "            patience=config.patience,\n",
    "            weight_decay=config.weight_decay,\n",
    "            save_path=unique_save_path,\n",
    "            log_wandb=True,\n",
    "            existing_wandb_run=wandb  # Pass existing wandb run\n",
    "        )\n",
    "        \n",
    "        # Make sure to clean up properly\n",
    "        del trained_model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        # Return the best validation accuracy\n",
    "        best_val_accuracy = max(val_accuracies)\n",
    "        wandb.log({\"best_val_accuracy\": best_val_accuracy})\n",
    "        return best_val_accuracy\n",
    "\n",
    "def objective_function_random(config=None):\n",
    "    \"\"\"Objective function for hyperparameter optimization of random model\"\"\"\n",
    "    \n",
    "    with wandb.init(\n",
    "    project=\"CommonsenseQA\",\n",
    "    name=f\"random_transformer-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "    ) as run:\n",
    "        config = wandb.config\n",
    "\n",
    "        # Always create a fresh model instance for each run\n",
    "        config_bert = BertConfig.from_pretrained('bert-base-cased')\n",
    "        random_bert_model = BertForMultipleChoice(config_bert)\n",
    "        \n",
    "        # Create dataloaders with the batch size from config\n",
    "        train_batch_size = config.batch_size\n",
    "        \n",
    "        train_dataloader = DataLoader(train_features,\n",
    "            batch_size=train_batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        val_dataloader = DataLoader(\n",
    "            val_features,\n",
    "            batch_size=train_batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        # Generate a unique save path for this run\n",
    "        unique_save_path = f\"./checkpoints/sweep-{wandb.run.id}-{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "        \n",
    "        # Use the training function with model_random and pass the existing wandb run\n",
    "        trained_model, train_losses, val_accuracies = train_transformer(\n",
    "            model=random_bert_model,\n",
    "            train_dataloader=train_dataloader,\n",
    "            val_dataloader=val_dataloader,\n",
    "            device=device,\n",
    "            epochs=config.epochs,\n",
    "            learning_rate=config.learning_rate,\n",
    "            warmup_steps=config.warmup_ratio * len(train_dataloader),\n",
    "            gradient_clip_val=config.gradient_clip_val,\n",
    "            save_interval=1,\n",
    "            gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "            patience=config.patience,\n",
    "            weight_decay=config.weight_decay,\n",
    "            save_path=unique_save_path,\n",
    "            log_wandb=True,\n",
    "            existing_wandb_run=wandb  # Pass existing wandb run\n",
    "        )\n",
    "        \n",
    "        # Make sure to clean up properly\n",
    "        del trained_model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        # Return the best validation accuracy\n",
    "        best_val_accuracy = max(val_accuracies)\n",
    "        wandb.log({\"best_val_accuracy\": best_val_accuracy})\n",
    "        return best_val_accuracy\n",
    "\n",
    "def run_sweep_pretrained(count):\n",
    "    \"\"\"Run hyperparameter sweep for the pretrained model\"\"\"\n",
    "    # Define the parameter search space\n",
    "    sweep_config = {\n",
    "        'method': 'bayes',\n",
    "        'metric': {'name': 'val_accuracy', 'goal': 'maximize'},\n",
    "        'name': 'pretrained_model_sweep',\n",
    "        'parameters': {\n",
    "            'batch_size': {\n",
    "                'values': [16, 32, 64]\n",
    "            },\n",
    "            'learning_rate': {\n",
    "                'distribution': 'log_uniform_values',\n",
    "                'min': 1e-6,\n",
    "                'max': 1e-4\n",
    "            },\n",
    "            'weight_decay': {\n",
    "                'distribution': 'log_uniform_values',\n",
    "                'min': 1e-6,\n",
    "                'max': 1e-2\n",
    "            },\n",
    "            'gradient_clip_val': {\n",
    "                'distribution': 'uniform',\n",
    "                'min': 0.5,\n",
    "                'max': 2.0\n",
    "            },\n",
    "            'gradient_accumulation_steps': {\n",
    "                'values': [1, 2, 4]\n",
    "            },\n",
    "            'warmup_ratio': {\n",
    "                'values': [0.1]\n",
    "            },\n",
    "            'epochs': {\n",
    "                'values': [50]\n",
    "            },\n",
    "            'patience': {\n",
    "                'values': [5]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create the sweep\n",
    "    sweep_id = wandb.sweep(sweep_config, project=\"CommonsenseQA\")\n",
    "    \n",
    "    # Run the sweep\n",
    "    wandb.agent(sweep_id, function=objective_function_pretrained, count=count)\n",
    "\n",
    "def run_sweep_random(count):\n",
    "    \"\"\"Run hyperparameter sweep for the randomly initialized model\"\"\"\n",
    "    # Define the parameter search space\n",
    "    # For random initialization, we might want to explore different learning rates\n",
    "    sweep_config = {\n",
    "        'method': 'bayes',\n",
    "        'metric': {'name': 'val_accuracy', 'goal': 'maximize'},\n",
    "        'name': 'pretrained_model_sweep',\n",
    "        'parameters': {\n",
    "            'batch_size': {\n",
    "                'values': [16, 32, 64]\n",
    "            },\n",
    "            'learning_rate': {\n",
    "                'distribution': 'log_uniform_values',\n",
    "                'min': 1e-6,\n",
    "                'max': 1e-4\n",
    "            },\n",
    "            'weight_decay': {\n",
    "                'distribution': 'log_uniform_values',\n",
    "                'min': 1e-6,\n",
    "                'max': 1e-2\n",
    "            },\n",
    "            'gradient_clip_val': {\n",
    "                'distribution': 'uniform',\n",
    "                'min': 0.5,\n",
    "                'max': 2.0\n",
    "            },\n",
    "            'gradient_accumulation_steps': {\n",
    "                'values': [1, 2, 4]\n",
    "            },\n",
    "            'warmup_ratio': {\n",
    "                'values': [0.1]\n",
    "            },\n",
    "            'epochs': {\n",
    "                'values': [50]\n",
    "            },\n",
    "            'patience': {\n",
    "                'values': [5]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create the sweep\n",
    "    sweep_id = wandb.sweep(sweep_config, project=\"CommonsenseQA\")\n",
    "    \n",
    "    # Run the sweep\n",
    "    wandb.agent(sweep_id, function=objective_function_random, count=count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9909393c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting sweep for pretrained model...\")\n",
    "run_sweep_pretrained(count=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b90ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting sweep for randomly initialized model...\")\n",
    "run_sweep_random(count=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61866a81",
   "metadata": {},
   "source": [
    "# **Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8fe1f8",
   "metadata": {},
   "source": [
    "Important: Use test split for eval, not validation (& ofc no train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650d4be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    all_logits = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(dataloader, desc=\"Evaluation\")\n",
    "        \n",
    "        for batch in progress_bar:\n",
    "            # Move batch to device\n",
    "            input_ids, attention_mask, token_type_ids, labels = [b.to(device) for b in batch]\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids\n",
    "            )\n",
    "            \n",
    "            # Get predictions\n",
    "            logits = outputs.logits\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            \n",
    "            # Collect labels and predictions\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            predicted_labels.extend(preds.cpu().numpy())\n",
    "            all_logits.append(logits.cpu().numpy())\n",
    "    \n",
    "    # Combine all logits\n",
    "    all_logits = np.vstack(all_logits) if all_logits else np.array([])\n",
    "    \n",
    "    # Compute metrics\n",
    "    from sklearn.metrics import (\n",
    "        accuracy_score, \n",
    "        precision_score, \n",
    "        recall_score, \n",
    "        f1_score, \n",
    "        confusion_matrix,\n",
    "        classification_report\n",
    "    )\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    \n",
    "    # Only calculate these metrics if there are predictions for each class\n",
    "    try:\n",
    "        precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "        recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "        f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "    except:\n",
    "        print(\"Warning: Some classes may not have predictions. Using only accuracy.\")\n",
    "        precision = recall = f1 = None\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "    \n",
    "    # Class-wise report \n",
    "    class_report = classification_report(true_labels, predicted_labels, output_dict=True)\n",
    "    \n",
    "    # Create a list to map index to answer choice label (A-E)\n",
    "    idx_to_label = {i: chr(65 + i) for i in range(5)}  # 0->A, 1->B, etc.\n",
    "    \n",
    "    # Calculate per-class accuracy\n",
    "    class_accuracies = {}\n",
    "    for i in range(5):\n",
    "        class_indices = np.where(np.array(true_labels) == i)[0]\n",
    "        if len(class_indices) > 0:\n",
    "            class_correct = sum([predicted_labels[j] == i for j in class_indices])\n",
    "            class_accuracies[idx_to_label[i]] = class_correct / len(class_indices)\n",
    "        else:\n",
    "            class_accuracies[idx_to_label[i]] = 0\n",
    "    \n",
    "    results = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'confusion_matrix': cm,\n",
    "        'class_report': class_report,\n",
    "        'per_class_accuracy': class_accuracies,\n",
    "        'logits': all_logits\n",
    "    }\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Per-class accuracy:\")\n",
    "    for label, acc in class_accuracies.items():\n",
    "        print(f\"  Choice {label}: {acc:.4f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f76ca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_bert_model = BertForMultipleChoice.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e005aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model in theory\n",
    "best_model_path = \"./checkpoints/sweep-ui8fb374-2025-05-14_01-51-35/best_pretrained_transformer_model.pt\"\n",
    "pretrained_bert_model.load_state_dict(torch.load(best_model_path))\n",
    "pretrained_bert_model.to(device)\n",
    "pretrained_bert_model.eval()\n",
    "test_results = evaluate(pretrained_bert_model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953ac9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the confusion matrix\n",
    "cm = test_results['confusion_matrix']\n",
    "\n",
    "# Define class labels (A-E)\n",
    "labels = ['A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2b1c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_bert = BertConfig.from_pretrained('bert-base-cased')\n",
    "random_bert_model = BertForMultipleChoice(config_bert)\n",
    "\n",
    "random_model_results = evaluate(random_bert_model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2730b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1221\n"
     ]
    }
   ],
   "source": [
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "948de111",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating answers: 100%|██████████| 100/100 [08:28<00:00,  5.08s/it]\n"
     ]
    }
   ],
   "source": [
    "# For the validation set (1 example)\n",
    "results = process_commonsense_qa_for_deepseek(test, deepseek_model, tokenizer_deepseek, num_examples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5b95e68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?', 'What do people aim to do at work?', 'Where would you find magazines along side many other printed works?', 'Where are  you likely to find a hamburger?', 'James was looking for a good place to buy farmland.  Where might he look?', 'What island country is ferret popular?', 'In what Spanish speaking North American country can you get a great cup of coffee?', 'What do animals do when an enemy is approaching?', 'Reading newspaper one of many ways to practice your what?', 'What do people typically do while playing guitar?', 'What would vinyl be an odd thing to replace?', 'If you want harmony, what is something you should try to do with the world?', \"Where does a heifer's master live?\", 'Aside from water and nourishment what does your dog need?', 'Janet was watching the film because she liked what?', \"What are you waiting alongside with when you're in a reception area?\", 'When drinking booze what can you do to stay busy?', 'A fencing thrust with a sharp sword towards a person would result in what?', 'Unlike a spider and his many sight seers, people only have what?', 'Where do adults use glue sticks?', 'What could go on top of wood?', 'The artist was sitting quietly pondering, then suddenly he began to paint when what struck him?', \"Though the thin film seemed fragile, for it's intended purpose it was actually nearly what?\", 'Where could you find a toilet that only friends can use?', \"What is someone who isn't clever, bright, or competent called?\", 'When wildlife reproduce we often refer to what comes out as what?', 'The weasel was becoming a problem, it kept getting into the chicken eggs kept in the what?', 'Blue read material outside of his comfort zone because he wanted to gain what?', 'After he got hired he hoped for success at his what?', 'Committing perjury is a serious what?', 'If you are prone to postpone work what will you have to do in order to finish on time?', 'James wanted to find an old underground map from the 50s.  Where might he look for one?', 'Sean was in a rush to get home, but the light turned yellow and he was forced to do what?', 'Where would a person be doing when having to wait their turn?', 'She was always helping at the senior center, it brought her what?', 'The lock kept the steering wheel from moving, but the thief still took his chances and began to work on the what?', 'Who is a police officer likely to work for?', 'If you have leftover cake, where would you put it?', 'A human wants to submerge himself in water, what should he use?', 'Where is a doormat likely to be in front of?', 'Bob the lizard lives in a warm place with lots of water.  Where does he probably live?', \"August needed  money because he was afraid that he'd be kicked out of his house.  What did he need money to do?\", 'He needed more information to fix it, so he consulted the what?', \"Where can you put a picture frame when it's not hung vertically?\", \"James knew that he shouldn't have been buying beer for minors.  He didn't even get paid for it.  Why was this bad?\", 'What is the result of applying for  job?', 'What must someone do before they shop?', 'Because John was first violin, he had to bring something important to work ever day. What did he need to bring to work?', 'What is a place that usually does not have an elevator and that sometimes has a telephone book?', 'Who is likely to be excited about a crab?', \"Where can a human find clothes that aren't pants?\", \"If I was getting drunk, and people couldn't understand me, what might I be having?\", 'When a person is beginning work, what are they building?', 'A child wants to play, what would they likely want?', 'Talking to the same person about the same thing over and over again is something someone can what?', \"The teacher doesn't tolerate noise during a test in their what?\", 'The freeway had no traffic and few buildings, where is it?', 'Where would you go if you wanted to have fun with a few people?', 'If there is a place that is hot and arid, what could it be?', \"What is likely to satisfy someone's curiosity?\", 'If you are in a bar in a glove shaped state where are you?', 'Where would a computer user be using their own computer?', 'Crabs live in what sort of environment?', 'Where can you find a snake in tall grass?', 'What is a place that has a bench nestled in trees?', 'Where is a human likely to go as a result of being hungry?', 'He was beginning to regret taking the fight when he saw how what his opponent was?', 'Where would you find a single shower curtain being used?', 'Where is a good idea but not required to have a fire extinguisher?', 'What continent has the most castles?', 'If you have to read a book that is very dry and long you may become what?', 'Sally used a clipboard to hold her papers while she read off names at the beginning of the day.  Where might she work?', \"The kids didn't clean up after they had done what?\", 'Despite the name a pawn can be quite versatile, all the parts are important in a what?', 'What would not be true about a basketball if it had a hole in it but it did not lose its general shape?', 'If you are awaking multiple times throughout the night because a lot is on your mind, what is a likely cause?', 'Where does a wild bird usually live?', 'Where would you expect to find white mice?', 'John felt that his actions were fate.   Harry said that he could have always made a different what?', 'What could committing murder prevent someone from doing?', \"George didn't have a car, but he still had his two feet.   His socks were smelly and his soles were blistered, but that didn't matter.  He could still do what?\", 'A crane uses many a steel cable when working a what?', 'What is the main purpose of farmers?', 'Where can I put this penny to save for later?', 'Where would you put uncooked crab meat?', 'The man had a fear of illness, so he never visited friends who were a what?', 'Where would you put pans if you want to bring them with you?', \"If you're remembering something, it's because of your what of it to begin with?\", 'Which large land mass is home to the most monkeys?', \"Friday was James's 5th Anniversary.  They planned on going to bed early so that they could spend a long time doing what?\", 'The teens were trying to hide that they get drink, but when they walked in the door their what gave it away?', \"You'll find a landing at the top of what?\", 'Anybody could be hired in the kitchen, what was needed of them?', 'Where can you find a number of wind instruments together in public?', 'A mountie got off at a subway stop.  What city might he be in?', 'What do you want someone to do when you illustrate point?', 'Billy set aside a block of time for having fun after work. Why might he do this?', 'The man in the white suit was very lazy.  He did nothing useful.  Meanwhile, the ban in the blue had put in effort and was very what?', 'What would you be unable to do if you have too much greed?', 'It was a long trip from the farm, so he stayed in a hotel when he arrived at the what?']\n",
      "['Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?\\nConcept: revolving door\\nChoices: A. bank, B. library, C. department store, D. mall, E. new york\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: What do people aim to do at work?\\nConcept: people\\nChoices: A. complete job, B. learn from each other, C. kill animals, D. wear hats, E. talk to each other\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Where would you find magazines along side many other printed works?\\nConcept: magazines\\nChoices: A. doctor, B. bookstore, C. market, D. train station, E. mortuary\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Where are  you likely to find a hamburger?\\nConcept: hamburger\\nChoices: A. fast food restaurant, B. pizza, C. ground up dead cows, D. mouth, E. cow carcus\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: James was looking for a good place to buy farmland.  Where might he look?\\nConcept: farmland\\nChoices: A. midwest, B. countryside, C. estate, D. farming areas, E. illinois\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: What island country is ferret popular?\\nConcept: ferret\\nChoices: A. own home, B. north carolina, C. great britain, D. hutch, E. outdoors\\nAnswer:', \"Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: In what Spanish speaking North American country can you get a great cup of coffee?\\nConcept: cup of coffee\\nChoices: A. mildred's coffee shop, B. mexico, C. diner, D. kitchen, E. canteen\\nAnswer:\", 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: What do animals do when an enemy is approaching?\\nConcept: animals\\nChoices: A. feel pleasure, B. procreate, C. pass water, D. listen to each other, E. sing\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Reading newspaper one of many ways to practice your what?\\nConcept: reading newspaper\\nChoices: A. literacy, B. knowing how to read, C. money, D. buying, E. money bank\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: What do people typically do while playing guitar?\\nConcept: playing guitar\\nChoices: A. cry, B. hear sounds, C. singing, D. arthritis, E. making music\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: What would vinyl be an odd thing to replace?\\nConcept: vinyl\\nChoices: A. pants, B. record albums, C. record store, D. cheese, E. wallpaper\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: If you want harmony, what is something you should try to do with the world?\\nConcept: something you\\nChoices: A. take time, B. make noise, C. make war, D. make peace, E. make haste\\nAnswer:', \"Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Where does a heifer's master live?\\nConcept: heifer\\nChoices: A. farm house, B. barnyard, C. stockyard, D. slaughter house, E. eat cake\\nAnswer:\", 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Aside from water and nourishment what does your dog need?\\nConcept: dog\\nChoices: A. bone, B. charm, C. petted, D. lots of attention, E. walked\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Janet was watching the film because she liked what?\\nConcept: watching film\\nChoices: A. erection, B. laughter, C. being entertained, D. fear, E. bordem\\nAnswer:', \"Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: What are you waiting alongside with when you're in a reception area?\\nConcept: reception area\\nChoices: A. motel, B. chair, C. hospital, D. people, E. hotels\\nAnswer:\", 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: When drinking booze what can you do to stay busy?\\nConcept: booze\\nChoices: A. reach tentative agreement, B. stay in bed, C. stop bicycle, D. examine thing, E. suicide\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: A fencing thrust with a sharp sword towards a person would result in what?\\nConcept: fencing\\nChoices: A. injury, B. small cuts, C. fever, D. competition, E. puncture wound\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Unlike a spider and his many sight seers, people only have what?\\nConcept: people\\nChoices: A. tongues, B. names, C. brains, D. feelings, E. two eyes\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Where do adults use glue sticks?\\nConcept: glue stick\\nChoices: A. classroom, B. desk drawer, C. at school, D. office, E. kitchen drawer\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: What could go on top of wood?\\nConcept: wood\\nChoices: A. lumberyard, B. synagogue, C. floor, D. carpet, E. hardware store\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: The artist was sitting quietly pondering, then suddenly he began to paint when what struck him?\\nConcept: sitting quietly\\nChoices: A. sadness, B. anxiety, C. inspiration, D. discomfort, E. insights\\nAnswer:', \"Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Though the thin film seemed fragile, for it's intended purpose it was actually nearly what?\\nConcept: fragile\\nChoices: A. indestructible, B. durable, C. undestroyable, D. indestructible, E. unbreakable\\nAnswer:\", 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Where could you find a toilet that only friends can use?\\nConcept: toilet\\nChoices: A. rest area, B. school, C. stadium, D. apartment, E. hospital\\nAnswer:', \"Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: What is someone who isn't clever, bright, or competent called?\\nConcept: clever\\nChoices: A. clumsy, B. ineffectual, C. dull, D. clumsy, E. stupid\\nAnswer:\", 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: When wildlife reproduce we often refer to what comes out as what?\\nConcept: reproduce\\nChoices: A. raise children, B. have children, C. photo copy, D. offspring, E. accidently got pregnant somehow\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: The weasel was becoming a problem, it kept getting into the chicken eggs kept in the what?\\nConcept: weasel\\nChoices: A. forrest, B. barn, C. public office, D. out of doors, E. freezer\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Blue read material outside of his comfort zone because he wanted to gain what?\\nConcept: reading\\nChoices: A. new perspective, B. entertained, C. understanding, D. hunger, E. tired eyes\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: After he got hired he hoped for success at his what?\\nConcept: success\\nChoices: A. vocation, B. new job, C. michigan, D. working hard, E. manual\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Committing perjury is a serious what?\\nConcept: committing perjury\\nChoices: A. indictment, B. crime, C. violence, D. lie, E. go to jail\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: If you are prone to postpone work what will you have to do in order to finish on time?\\nConcept: postpone\\nChoices: A. eat, B. hasten, C. antedate, D. bring forward, E. advance\\nAnswer:', \"Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: James wanted to find an old underground map from the 50s.  Where might he look for one?\\nConcept: underground map\\nChoices: A. library, B. subway station, C. county engineer's office, D. super market, E. home\\nAnswer:\", 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Sean was in a rush to get home, but the light turned yellow and he was forced to do what?\\nConcept: rush\\nChoices: A. take time, B. dawdle, C. go slowly, D. ocean, E. slow down\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Where would a person be doing when having to wait their turn?\\nConcept: wait turn\\nChoices: A. have patience, B. get in line, C. sing, D. stand in line, E. turn left\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: She was always helping at the senior center, it brought her what?\\nConcept: helping\\nChoices: A. satisfaction, B. heart, C. feel better, D. pay, E. happiness\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: The lock kept the steering wheel from moving, but the thief still took his chances and began to work on the what?\\nConcept: lock\\nChoices: A. keep cloesd, B. train, C. ignition switch, D. drawer, E. firearm\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Who is a police officer likely to work for?\\nConcept: police officer\\nChoices: A. beat, B. direct traffic, C. city, D. street, E. president\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: If you have leftover cake, where would you put it?\\nConcept: cake\\nChoices: A. quandry, B. refrigerator, C. oven, D. night stand, E. bakery\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: A human wants to submerge himself in water, what should he use?\\nConcept: water\\nChoices: A. whirlpool bath, B. coffee cup, C. cup, D. soft drink, E. puddle\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Where is a doormat likely to be in front of?\\nConcept: doormat\\nChoices: A. facade, B. front door, C. doorway, D. entrance porch, E. hallway\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Bob the lizard lives in a warm place with lots of water.  Where does he probably live?\\nConcept: lizard\\nChoices: A. rock, B. tropical rainforest, C. jazz club, D. new mexico, E. rocky places\\nAnswer:', \"Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: August needed  money because he was afraid that he'd be kicked out of his house.  What did he need money to do?\\nConcept: money\\nChoices: A. control people, B. pay bills, C. hurt people, D. buy food, E. get things\\nAnswer:\", 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: He needed more information to fix it, so he consulted the what?\\nConcept: information\\nChoices: A. chickens, B. google, C. newspaper, D. online, E. manual\\nAnswer:', \"Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Where can you put a picture frame when it's not hung vertically?\\nConcept: picture\\nChoices: A. art show, B. wall, C. newspaper, D. car, E. table\\nAnswer:\", \"Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: James knew that he shouldn't have been buying beer for minors.  He didn't even get paid for it.  Why was this bad?\\nConcept: buying beer\\nChoices: A. lose money, B. fun, C. have no money, D. broken law, E. relaxation\\nAnswer:\", 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: What is the result of applying for  job?\\nConcept: applying for job\\nChoices: A. anxiety and fear, B. increased workload, C. praise, D. less sleep, E. being employed\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: What must someone do before they shop?\\nConcept: shop\\nChoices: A. get money, B. have money, C. bring cash, D. go to market, E. bring cash\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Because John was first violin, he had to bring something important to work ever day. What did he need to bring to work?\\nConcept: first violin\\nChoices: A. music store, B. obesity, C. symphony orchestra, D. ochestra, E. violin case\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: What is a place that usually does not have an elevator and that sometimes has a telephone book?\\nConcept: telephone book\\nChoices: A. at hotel, B. kitchen, C. library, D. telephone booth, E. house\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Who is likely to be excited about a crab?\\nConcept: crab\\nChoices: A. fish market, B. pet shop, C. fishmongers, D. intertidal zone, E. obesity\\nAnswer:', \"Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Where can a human find clothes that aren't pants?\\nConcept: human\\nChoices: A. pants shop, B. on planet earth, C. dress shop, D. school, E. train wreck\\nAnswer:\", \"Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: If I was getting drunk, and people couldn't understand me, what might I be having?\\nConcept: getting drunk\\nChoices: A. a seizure, B. slurred speech, C. death, D. forgetfulness, E. pass out\\nAnswer:\", 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: When a person is beginning work, what are they building?\\nConcept: beginning work\\nChoices: A. time, B. accomplishing, C. working, D. momentum, E. tiredness\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: A child wants to play, what would they likely want?\\nConcept: child\\nChoices: A. fall down, B. breathe, C. play tag, D. be dismembered by a chainsaw, E. become adult\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Talking to the same person about the same thing over and over again is something someone can what?\\nConcept: talking to\\nChoices: A. social life, B. friendship, C. eye contact, D. get tired of, E. learn lessons from\\nAnswer:', \"Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: The teacher doesn't tolerate noise during a test in their what?\\nConcept: noise\\nChoices: A. movie theatre, B. bowling alley, C. factory, D. store, E. classroom\\nAnswer:\", 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: The freeway had no traffic and few buildings, where is it?\\nConcept: freeway\\nChoices: A. california, B. countryside, C. big town, D. florida, E. america\\nAnswer:', \"Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Where would you go if you wanted to have fun with a few people?\\nConcept: fun\\nChoices: A. watching television, B. good, C. cinema, D. friend's house, E. fairgrounds\\nAnswer:\", 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: If there is a place that is hot and arid, what could it be?\\nConcept: hot\\nChoices: A. bland, B. lifeless, C. sandy, D. neutral, E. freezing\\nAnswer:', \"Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: What is likely to satisfy someone's curiosity?\\nConcept: curiosity\\nChoices: A. hear news, B. read book, C. see favorite show, D. comedy show, E. go somewhere\\nAnswer:\", 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: If you are in a bar in a glove shaped state where are you?\\nConcept: bar\\nChoices: A. in my pocket, B. michigan, C. new york city, D. restaurant, E. public house\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Where would a computer user be using their own computer?\\nConcept: computer user\\nChoices: A. hell, B. school, C. indoors, D. internet cafe, E. house\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Crabs live in what sort of environment?\\nConcept: crab\\nChoices: A. maritime, B. bodies of water, C. saltwater, D. galapagos, E. fish market\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Where can you find a snake in tall grass?\\nConcept: snake\\nChoices: A. tree, B. in a jar, C. pet shops, D. feild, E. tropical forest\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: What is a place that has a bench nestled in trees?\\nConcept: bench\\nChoices: A. state park, B. bus stop, C. bus depot, D. statue, E. train station\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Where is a human likely to go as a result of being hungry?\\nConcept: being hungry\\nChoices: A. eat in restaurant, B. make bread, C. have lunch, D. cook dinner, E. friends house\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: He was beginning to regret taking the fight when he saw how what his opponent was?\\nConcept: regret\\nChoices: A. fun, B. joy, C. satisfaction, D. confident, E. pride\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Where would you find a single shower curtain being used?\\nConcept: shower curtain\\nChoices: A. bathtub, B. washing area, C. hotel, D. shower stall, E. department store\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Where is a good idea but not required to have a fire extinguisher?\\nConcept: fire extinguisher\\nChoices: A. school bus, B. boat, C. house, D. hospital, E. school\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: What continent has the most castles?\\nConcept: castle\\nChoices: A. fairy tale, B. edinburgh, C. germany, D. europe, E. antarctica\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: If you have to read a book that is very dry and long you may become what?\\nConcept: read book\\nChoices: A. have time, B. boring, C. learn new, D. enjoyable, E. bored\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Sally used a clipboard to hold her papers while she read off names at the beginning of the day.  Where might she work?\\nConcept: clipboard\\nChoices: A. desk, B. windows 95, C. office supply store, D. see work, E. school\\nAnswer:', \"Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: The kids didn't clean up after they had done what?\\nConcept: kids\\nChoices: A. learn things, B. play games, C. disneyland, D. play with toys, E. talking\\nAnswer:\", 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Despite the name a pawn can be quite versatile, all the parts are important in a what?\\nConcept: pawn\\nChoices: A. chess game, B. scheme, C. chess set, D. checkers, E. north carolina\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: What would not be true about a basketball if it had a hole in it but it did not lose its general shape?\\nConcept: basketball\\nChoices: A. punctured, B. popular in america, C. full of air, D. gone, E. round\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: If you are awaking multiple times throughout the night because a lot is on your mind, what is a likely cause?\\nConcept: awaking\\nChoices: A. irritability, B. depression, C. getting out of bed, D. happiness, E. discomfort\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Where does a wild bird usually live?\\nConcept: bird\\nChoices: A. cage, B. sky, C. countryside, D. desert, E. windowsill\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Where would you expect to find white mice?\\nConcept: mice\\nChoices: A. bell cat, B. bush, C. attic, D. countryside, E. laboratory\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: John felt that his actions were fate.   Harry said that he could have always made a different what?\\nConcept: fate\\nChoices: A. free will, B. choice, C. will, D. alcohol, E. freedom\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: What could committing murder prevent someone from doing?\\nConcept: committing murder\\nChoices: A. go to jail, B. cry, C. find god, D. guilty conscience, E. problems\\nAnswer:', \"Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: George didn't have a car, but he still had his two feet.   His socks were smelly and his soles were blistered, but that didn't matter.  He could still do what?\\nConcept: feet\\nChoices: A. michigan, B. walk, C. stay still, D. stink, E. hands\\nAnswer:\", 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: A crane uses many a steel cable when working a what?\\nConcept: steel cable\\nChoices: A. abaft, B. ship, C. winch, D. construction site, E. building\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: What is the main purpose of farmers?\\nConcept: farmers\\nChoices: A. raise cattle, B. grow corn, C. farm land, D. drive tractors, E. supply food\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Where can I put this penny to save for later?\\nConcept: penny\\nChoices: A. piggy bank, B. wallet, C. toy, D. ground, E. pocket\\nAnswer:', \"Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Where would you put uncooked crab meat?\\nConcept: crab\\nChoices: A. wharf, B. red lobster, C. tidepools, D. boss's office, E. stew pot\\nAnswer:\", \"Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: The man had a fear of illness, so he never visited friends who were a what?\\nConcept: illness\\nChoices: A. sick person, B. hospital, C. elderly person, D. graveyard, E. doctor's office\\nAnswer:\", 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Where would you put pans if you want to bring them with you?\\nConcept: pans\\nChoices: A. cooking, B. cook food, C. kitchen, D. backpack, E. drawer\\nAnswer:', \"Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: If you're remembering something, it's because of your what of it to begin with?\\nConcept: remembering\\nChoices: A. knowledge, B. knowing, C. forgetful, D. pleasure, E. depression\\nAnswer:\", \"Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Which large land mass is home to the most monkeys?\\nConcept: monkey\\nChoices: A. amazon basin, B. friend's house, C. lift number 3, D. research laboratory, E. african continent\\nAnswer:\", \"Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Friday was James's 5th Anniversary.  They planned on going to bed early so that they could spend a long time doing what?\\nConcept: going to bed\\nChoices: A. rest, B. insomnia, C. making love, D. sleeping in, E. texting\\nAnswer:\", 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: The teens were trying to hide that they get drink, but when they walked in the door their what gave it away?\\nConcept: get drunk\\nChoices: A. health, B. fall down, C. stagger, D. get arrested, E. vomit\\nAnswer:', \"Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: You'll find a landing at the top of what?\\nConcept: landing\\nChoices: A. ocean, B. apartment building, C. stairwell, D. airport, E. room\\nAnswer:\", 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Anybody could be hired in the kitchen, what was needed of them?\\nConcept: anybody\\nChoices: A. forget, B. oil squeaky hinge, C. question authority, D. wash dishes, E. oik squeaky hinge\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Where can you find a number of wind instruments together in public?\\nConcept: wind instrument\\nChoices: A. music store, B. create music, C. zoo, D. music room, E. symphony\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: A mountie got off at a subway stop.  What city might he be in?\\nConcept: subway stop\\nChoices: A. urban area, B. metropolis, C. chicago, D. new york city, E. toronto\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: What do you want someone to do when you illustrate point?\\nConcept: illustrate point\\nChoices: A. did not understand, B. accepting, C. make clear, D. understood, E. understanding\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: Billy set aside a block of time for having fun after work. Why might he do this?\\nConcept: having fun\\nChoices: A. happiness, B. stress relief, C. pleasure, D. ocean, E. may laugh\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: The man in the white suit was very lazy.  He did nothing useful.  Meanwhile, the ban in the blue had put in effort and was very what?\\nConcept: lazy\\nChoices: A. restless, B. active, C. lazybutt, D. productive, E. hard work\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: What would you be unable to do if you have too much greed?\\nConcept: greed\\nChoices: A. keep things, B. make friends, C. play poker, D. conquer opponent, E. lie\\nAnswer:', 'Answer the following multiple choice question with only the correct letter (A, B, C, D, or E). Do not explain your answer.\\nQuestion: It was a long trip from the farm, so he stayed in a hotel when he arrived at the what?\\nConcept: hotel\\nChoices: A. bed away from home, B. wwii bunker, C. resort, D. las vegas, E. city\\nAnswer:']\n",
      "['C', 'B', 'B', 'C', 'D', 'C', 'B', 'A', 'B', 'B', 'B', 'D', 'B', 'D', 'C', 'B', 'B', 'B', 'C', 'A', 'C', 'C', 'B', 'A', 'E', 'D', 'B', 'C', 'B', 'B', 'D', 'B', 'C', 'D', 'E', 'C', 'A', 'B', 'C', 'B', 'B', 'B', 'D', 'B', 'D', 'A', 'B', 'E', 'A', 'B', 'B', 'B', 'C', 'C', 'D', 'E', 'B', 'C', 'C', 'C', 'B', 'B', 'C', 'A', 'A', 'E', 'E', 'B', 'B', 'C', 'B', 'C', 'C', 'A', 'A', 'C', 'B', 'E', 'A', 'A', 'B', 'C', 'C', 'A', 'C', 'A', 'A', 'A', 'E', 'C', 'C', 'D', 'E', 'C', 'E', 'C', 'B', 'B', 'B', 'A']\n",
      "['A', 'A', 'B', 'A', 'A', 'C', 'B', 'D', 'A', 'C', 'E', 'D', 'A', 'D', 'C', 'D', 'D', 'E', 'E', 'D', 'D', 'C', 'D', 'D', 'E', 'D', 'B', 'A', 'B', 'B', 'B', 'A', 'E', 'D', 'E', 'C', 'C', 'B', 'A', 'B', 'B', 'B', 'E', 'E', 'D', 'E', 'A', 'E', 'E', 'C', 'C', 'B', 'D', 'C', 'D', 'E', 'B', 'D', 'B', 'A', 'B', 'E', 'C', 'D', 'A', 'A', 'D', 'A', 'C', 'D', 'E', 'E', 'D', 'A', 'C', 'B', 'C', 'E', 'B', 'C', 'B', 'D', 'E', 'A', 'E', 'A', 'D', 'B', 'E', 'C', 'C', 'C', 'D', 'E', 'E', 'E', 'B', 'D', 'B', 'E']\n"
     ]
    }
   ],
   "source": [
    "print(results['questions'])\n",
    "print(results['prompts'])\n",
    "print(results['responses'])\n",
    "print(results['correct_answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "57bd0ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 40.00%\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for i in range(len(results['responses'])):\n",
    "    if results['correct_answers'][i] == results['responses'][i]:\n",
    "        count += 1\n",
    "print(f\"Accuracy: {count / len(results['responses']) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a83e495",
   "metadata": {},
   "source": [
    "# **Interpretation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7363fea4",
   "metadata": {},
   "source": [
    "# **Tools used**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0bf1a1",
   "metadata": {},
   "source": [
    "### **Adjust this section before submitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8479f8",
   "metadata": {},
   "source": [
    "1. **Programming Environment**\n",
    "   - Python 3.12.8\n",
    "   - Jupyter Notebook\n",
    "\n",
    "2. **Machine Learning and Deep Learning**\n",
    "   - PyTorch (neural network development)\n",
    "   - Hugging Face Datasets (data management)\n",
    "   - NLTK (natural language preprocessing)\n",
    "   - FastText (pre-trained word embeddings, 300-dimensional vectors)\n",
    "\n",
    "3. **Data Manipulation and Analysis**\n",
    "   - NumPy (numerical computing)\n",
    "   - Pandas (data structuring and manipulation)\n",
    "   - Scikit-learn (potential additional machine learning utilities)\n",
    "\n",
    "4. **Visualization and Tracking**\n",
    "   - Matplotlib (basic plotting)\n",
    "   - Seaborn (statistical data visualization)\n",
    "   - Weights & Biases (experiment tracking and logging)\n",
    "     * Tracked metrics: training loss, accuracy, learning rates\n",
    "     * Logged hyperparameter configurations\n",
    "     * Enabled comparative analysis across model runs\n",
    "\n",
    "5. **Computational Infrastructure**\n",
    "   - CUDA-enabled GPU acceleration\n",
    "   - GPU-optimized PyTorch operations\n",
    "   - Efficient parallel computing for model training\n",
    "\n",
    "6. **Dataset and Benchmarking**\n",
    "   - CommonsenseQA dataset (Hugging Face)\n",
    "   - Standard benchmark for commonsense reasoning tasks\n",
    "\n",
    "7. **Additional Libraries**\n",
    "   - Gensim (word vector processing)\n",
    "   - tqdm (progress bar visualization)\n",
    "   - datetime (experiment timestamping)\n",
    "\n",
    "8. **AI-Tools**\n",
    "   - Claude 3.5 Sonnet: Utilized as a coding assistant for debugging, optimization and documentation.\n",
    "   - GPT-4-turbo: Assisted in drafting and refining documentation, helping with structure and phrasing.\n",
    "   - Copilot: Used for quick inserts, when recommendation was suitable for what I was planning to do.\n",
    "\n",
    "9. **Sources**\n",
    "   - Transformer architecture: https://medium.com/data-science/build-your-own-transformer-from-scratch-using-pytorch-84c850470dcb\n",
    "   - Deepseek implementation: https://huggingface.co/deepseek-ai/DeepSeek-V2-Lite\n",
    "   - Medium blog for warmup steps: https://medium.com/better-ml/the-art-of-setting-learning-rate-eff11ac0a737"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
