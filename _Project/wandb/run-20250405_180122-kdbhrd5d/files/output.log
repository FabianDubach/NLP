Starting RNN model training...
Checking first batch...
Sequences shape: torch.Size([640, 41, 300])
Sequence lengths shape: torch.Size([640])
Indices shape: torch.Size([128, 5])
Answers shape: torch.Size([128])
Testing forward pass...
Forward pass successful! Output shape: torch.Size([128, 5])
Loss calculation successful: 1.611425757408142
Backward pass successful!
No NaN gradients detected
Debug checks passed!

Epoch 1/10
Training: 100%|██████████| 69/69 [00:21<00:00,  3.28it/s, loss=1.6078, acc=0.1971]
Validation: 100%|██████████| 4/4 [00:01<00:00,  2.22it/s]
Validation accuracy improved from 0.0000 to 0.2350
Training failed with error: save_checkpoint() takes 5 positional arguments but 7 were given
Traceback (most recent call last):
  File "C:\Users\fabia\AppData\Local\Temp\ipykernel_16576\782190209.py", line 23, in <module>
    trained_rnn_model, best_rnn_accuracy = train_rnn_model(
                                           ^^^^^^^^^^^^^^^^
  File "C:\Users\fabia\AppData\Local\Temp\ipykernel_16576\2396035417.py", line 141, in train_rnn_model
    save_checkpoint(model, optimizer, epoch, scheduler,
TypeError: save_checkpoint() takes 5 positional arguments but 7 were given
Model saved in emergency mode
Using device: cuda
QARNNModel(
  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)
  (classifier): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.2, inplace=False)
    (3): Linear(in_features=128, out_features=1, bias=True)
  )
)
