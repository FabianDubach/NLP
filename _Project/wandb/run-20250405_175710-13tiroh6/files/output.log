Starting RNN model training...
Checking first batch...
Sequences shape: torch.Size([640, 41, 300])
Sequence lengths shape: torch.Size([640])
Indices shape: torch.Size([128, 5])
Answers shape: torch.Size([128])
Testing forward pass...
Error during debugging: `lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.
Traceback (most recent call last):
  File "C:\Users\fabia\AppData\Local\Temp\ipykernel_16576\2396035417.py", line 30, in train_rnn_model
    outputs = model(padded_sequences.to(device), sequence_lengths.to(device), indices.to(device))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\fabia\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\fabia\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\fabia\AppData\Local\Temp\ipykernel_16576\3113084452.py", line 34, in forward
    packed = pack_padded_sequence(
             ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\fabia\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\nn\utils\rnn.py", line 341, in pack_padded_sequence
    data, batch_sizes = _VF._pack_padded_sequence(input, lengths, batch_first)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: `lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.
Training failed with error: `lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.
Traceback (most recent call last):
  File "C:\Users\fabia\AppData\Local\Temp\ipykernel_16576\782190209.py", line 23, in <module>
    trained_rnn_model, best_rnn_accuracy = train_rnn_model(
                                           ^^^^^^^^^^^^^^^^
  File "C:\Users\fabia\AppData\Local\Temp\ipykernel_16576\2396035417.py", line 57, in train_rnn_model
    raise e
  File "C:\Users\fabia\AppData\Local\Temp\ipykernel_16576\2396035417.py", line 30, in train_rnn_model
    outputs = model(padded_sequences.to(device), sequence_lengths.to(device), indices.to(device))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\fabia\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\fabia\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\fabia\AppData\Local\Temp\ipykernel_16576\3113084452.py", line 34, in forward
    packed = pack_padded_sequence(
             ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\fabia\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\nn\utils\rnn.py", line 341, in pack_padded_sequence
    data, batch_sizes = _VF._pack_padded_sequence(input, lengths, batch_first)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: `lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.
Model saved in emergency mode
Starting RNN model training...
Checking first batch...
Sequences shape: torch.Size([640, 47, 300])
Sequence lengths shape: torch.Size([640])
Indices shape: torch.Size([128, 5])
Answers shape: torch.Size([128])
Testing forward pass...
Error during debugging: `lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.
Traceback (most recent call last):
  File "C:\Users\fabia\AppData\Local\Temp\ipykernel_16576\2396035417.py", line 30, in train_rnn_model
    outputs = model(padded_sequences.to(device), sequence_lengths.to(device), indices.to(device))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\fabia\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\fabia\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\fabia\AppData\Local\Temp\ipykernel_16576\3113084452.py", line 34, in forward
    packed = pack_padded_sequence(
             ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\fabia\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\nn\utils\rnn.py", line 341, in pack_padded_sequence
    data, batch_sizes = _VF._pack_padded_sequence(input, lengths, batch_first)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: `lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.
Training failed with error: `lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.
Traceback (most recent call last):
  File "C:\Users\fabia\AppData\Local\Temp\ipykernel_16576\782190209.py", line 23, in <module>
    trained_rnn_model, best_rnn_accuracy = train_rnn_model(
                                           ^^^^^^^^^^^^^^^^
  File "C:\Users\fabia\AppData\Local\Temp\ipykernel_16576\2396035417.py", line 57, in train_rnn_model
    raise e
  File "C:\Users\fabia\AppData\Local\Temp\ipykernel_16576\2396035417.py", line 30, in train_rnn_model
    outputs = model(padded_sequences.to(device), sequence_lengths.to(device), indices.to(device))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\fabia\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\nn\modules\module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\fabia\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\nn\modules\module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\fabia\AppData\Local\Temp\ipykernel_16576\3113084452.py", line 34, in forward
    packed = pack_padded_sequence(
             ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\fabia\AppData\Local\Programs\Python\Python312\Lib\site-packages\torch\nn\utils\rnn.py", line 341, in pack_padded_sequence
    data, batch_sizes = _VF._pack_padded_sequence(input, lengths, batch_first)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: `lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.
Model saved in emergency mode
Train loader length: 69
Valid loader length: 4
Sample batch retrieved successfully
Batch components:
Component 0: <class 'torch.Tensor'>, Shape: torch.Size([640, 38, 300])
Component 1: <class 'torch.Tensor'>, Shape: torch.Size([640])
Component 2: <class 'torch.Tensor'>, Shape: torch.Size([128, 5])
Component 3: <class 'torch.Tensor'>, Shape: torch.Size([128])
Number of sequences: 5
Sequence 0 shape: torch.Size([26, 300])
Sequence 1 shape: torch.Size([26, 300])
Sequence 2 shape: torch.Size([26, 300])
Sequence 3 shape: torch.Size([27, 300])
Sequence 4 shape: torch.Size([26, 300])
Sequence lengths: tensor([26, 26, 26, 27, 26])
Correct answer: 0
[34m[1mwandb[0m: [33mWARNING[0m Calling wandb.login() after wandb.init() has no effect.
Using device: cuda
QARNNModel(
  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)
  (classifier): Sequential(
    (0): Linear(in_features=256, out_features=128, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.2, inplace=False)
    (3): Linear(in_features=128, out_features=1, bias=True)
  )
)
